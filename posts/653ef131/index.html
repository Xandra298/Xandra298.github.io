<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/firefox-panda-roux.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/firefox-panda-roux.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xandra298.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"width":300},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="运行环境： windows11 CPU 12th Gen Intel(R) Core(TM) i5-12500H 运行内存16G Gemma：轻量级LLM 基于langchain实现，可视化使用smith.langchain  Setup">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG with Gemma using wikipedia api">
<meta property="og:url" content="https://xandra298.github.io/posts/653ef131/index.html">
<meta property="og:site_name" content="Tiny Blog  &amp;  小窝">
<meta property="og:description" content="运行环境： windows11 CPU 12th Gen Intel(R) Core(TM) i5-12500H 运行内存16G Gemma：轻量级LLM 基于langchain实现，可视化使用smith.langchain  Setup">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xandra298.github.io/posts/653ef131/image-20240423161523525.png">
<meta property="og:image" content="https://xandra298.github.io/posts/653ef131/Untitled.png">
<meta property="og:image" content="https://xandra298.github.io/posts/653ef131/Untitled%201.png">
<meta property="og:image" content="https://xandra298.github.io/posts/653ef131/Untitled%202.png">
<meta property="article:published_time" content="2024-04-23T08:06:47.000Z">
<meta property="article:modified_time" content="2024-04-23T08:29:03.941Z">
<meta property="article:author" content="Xandra">
<meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xandra298.github.io/posts/653ef131/image-20240423161523525.png">


<link rel="canonical" href="https://xandra298.github.io/posts/653ef131/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://xandra298.github.io/posts/653ef131/","path":"posts/653ef131/","title":"RAG with Gemma using wikipedia api"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>RAG with Gemma using wikipedia api | Tiny Blog  &  小窝</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?d53b0bfc3463e2d8df2a44594ea3a8ab"></script>






<link rel="dns-prefetch" href="wvaline.xandrax.cafe">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tiny Blog  &  小窝</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Setup"><span class="nav-number">1.</span> <span class="nav-text">Setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.</span> <span class="nav-text">实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RAG-%E7%9A%84%E8%BF%87%E7%A8%8B%E6%A6%82%E8%A7%88"><span class="nav-number">2.1.</span> <span class="nav-text">RAG 的过程概览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.2.</span> <span class="nav-text">代码实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#smith-langchain%E6%9F%A5%E7%9C%8B%E8%BF%87%E7%A8%8B"><span class="nav-number">3.</span> <span class="nav-text">smith.langchain查看过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E9%98%B6"><span class="nav-number">4.</span> <span class="nav-text">进阶</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E%E5%BC%BARAG%E8%BF%87%E7%A8%8B%EF%BC%8C%E6%8F%90%E9%AB%98%E6%A3%80%E7%B4%A2%E6%9C%89%E6%95%88%E6%80%A7%E7%AD%89"><span class="nav-number">4.1.</span> <span class="nav-text">增强RAG过程，提高检索有效性等</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8RAG%E4%B8%BA%E5%85%B6%E4%BB%96%E4%BB%BB%E5%8A%A1%E8%B5%8B%E8%83%BD"><span class="nav-number">4.2.</span> <span class="nav-text">应用RAG为其他任务赋能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E8%B5%8B%E8%83%BD"><span class="nav-number">4.3.</span> <span class="nav-text">搜索引擎赋能</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">5.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xandra"
      src="/uploads/OIP-C.jfif">
  <p class="site-author-name" itemprop="name">Xandra</p>
  <div class="site-description" itemprop="description">记录，学习，成长。欢迎交流！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning-Tuning-Playbook/" rel="tag">Deep Learning Tuning Playbook</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Diffusion-Model/" rel="tag">Diffusion Model</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAT/" rel="tag">GAT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GNN/" rel="tag">GNN</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Open-vocabulary/" rel="tag">Open vocabulary</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyG/" rel="tag">PyG</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RAG/" rel="tag">RAG</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VAD/" rel="tag">VAD</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wandb/" rel="tag">wandb</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE/" rel="tag">图</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%B1%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">弱监督学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%A8%A1/" rel="tag">数模</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9A%B4%E5%8A%9B%E8%A7%86%E9%A2%91%E6%A3%80%E6%B5%8B/" rel="tag">暴力视频检测</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%90%86%E8%AE%BA%E8%AE%A4%E7%9F%A5/" rel="tag">理论认知</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" rel="tag">视频理解</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/" rel="tag">视频生成</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%85%8D%E7%BD%AE/" rel="tag">配置</a><span class="tag-list-count">1</span></li></ul>
        </canvas>
    </div>
</div>


        </div>
      </div>

    </div>

		      
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
          Links
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://fortunato-all.github.io/" title="https:&#x2F;&#x2F;fortunato-all.github.io&#x2F;" rel="noopener" target="_blank">fortunato</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://cyanm0un.github.io/" title="https:&#x2F;&#x2F;cyanm0un.github.io&#x2F;" rel="noopener" target="_blank">CyanM0un</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://nobodyyj.github.io/" title="https:&#x2F;&#x2F;nobodyyj.github.io&#x2F;" rel="noopener" target="_blank">Nobodyy</a>
            </li>
        </ul>
      </div>
    </div>
		<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=300 height=86 src="//music.163.com/outchain/player?type=2&id=2001320&auto=0&height=66"></iframe>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://xandra298.github.io/posts/653ef131/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/OIP-C.jfif">
      <meta itemprop="name" content="Xandra">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tiny Blog  &  小窝">
      <meta itemprop="description" content="记录，学习，成长。欢迎交流！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="RAG with Gemma using wikipedia api | Tiny Blog  &  小窝">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          RAG with Gemma using wikipedia api
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-04-23 16:06:47 / Modified: 16:29:03" itemprop="dateCreated datePublished" datetime="2024-04-23T16:06:47+08:00">2024-04-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline: </span>
  
    <a title="waline" href="/posts/653ef131/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/posts/653ef131/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>10 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <ul>
<li>运行环境： windows11 CPU 12th Gen Intel(R) Core(TM) i5-12500H 运行内存16G</li>
<li>Gemma：轻量级LLM</li>
<li>基于langchain实现，可视化使用<a target="_blank" rel="noopener" href="https://smith.langchain.com/">smith.langchain</a></li>
</ul>
<h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><span id="more"></span>
<ol>
<li><p>创建conda环境，安装依赖</p>
<ul>
<li>pytorch 2.1.2</li>
<li>scikit-learn 1.4.0</li>
<li>llama_cpp_python 0.2.52</li>
<li>langchain 0.1.8</li>
<li>langchain-community 0.0.21</li>
<li>langchain-experimental 0.0.52</li>
<li>tiktoken 0.6.0</li>
<li>sentence-transformers 2.3.1</li>
<li>numpy 1.26.4</li>
<li>pandas 2.1.4</li>
<li>wikipedia</li>
</ul>
</li>
<li><p>下载gemma模型</p>
<p>模型下载：<a target="_blank" rel="noopener" href="https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF/blob/main/gemma-2b-it-q4_k_m.gguf">gemma-2b-it-q4_k_m.gguf · lmstudio-ai/gemma-2b-it-GGUF at main (huggingface.co)</a></p>
</li>
</ol>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="RAG-的过程概览"><a href="#RAG-的过程概览" class="headerlink" title="RAG 的过程概览"></a>RAG 的过程概览</h3><p>详细参考上一篇博客与<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb">Langchain demo overview</a></p>
<p><img src="/posts/653ef131/image-20240423161523525.png" alt></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>使用Gemma，并基于wikipedia</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.retrievers <span class="keyword">import</span> WikipediaRetriever</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> LlamaCpp</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> hub</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> (</span><br><span class="line">    RunnablePassthrough,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span>  ChatPromptTemplate</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#uncomment this to visual the processs on smithlangchain</span></span><br><span class="line"><span class="comment"># os.environ[&#x27;LANGCHAIN_TRACING_V2&#x27;] = &#x27;true&#x27;</span></span><br><span class="line"><span class="comment"># os.environ[&#x27;LANGCHAIN_ENDPOINT&#x27;] = &#x27;https://api.smith.langchain.com&#x27;</span></span><br><span class="line"><span class="comment"># os.environ[&#x27;LANGCHAIN_API_KEY&#x27;] = &#x27;&#x27; #get this from https://api.smith.langchain.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># llm model</span></span><br><span class="line">model_path = <span class="string">&quot;model/gemma-2b-it-q4_k_m.gguf&quot;</span> <span class="comment">#path to the pretrained gemma model</span></span><br><span class="line">llm = LlamaCpp(</span><br><span class="line">    model_path=model_path,</span><br><span class="line">    streaming=<span class="literal">False</span>,</span><br><span class="line">    n_gpu_layers=<span class="number">30</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># retrieve from Wikipedia using the WikipediaRetriever</span></span><br><span class="line">wiki = WikipediaRetriever(top_k_results=<span class="number">2</span>, doc_content_chars_max=<span class="number">550</span>) <span class="comment">#参数限制了获取数量及其最大长度</span></span><br><span class="line"><span class="comment"># Post-processing</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_docs</span>(<span class="params">docs: <span class="type">List</span>[Document]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert Documents to a single string.:&quot;&quot;&quot;</span></span><br><span class="line">    formatted = [</span><br><span class="line">        <span class="string">f&quot;Article Title: <span class="subst">&#123;doc.metadata[<span class="string">&#x27;title&#x27;</span>]&#125;</span>\nArticle Snippet: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">for</span> doc <span class="keyword">in</span> docs</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;\n\n&quot;</span>.join(formatted)</span><br><span class="line"><span class="comment"># Prompt</span></span><br><span class="line">	<span class="comment">#from the langchainhub</span></span><br><span class="line">rag_prompt = hub.pull(<span class="string">&quot;rlm/rag-prompt&quot;</span>)</span><br><span class="line">	<span class="comment">#self-defined</span></span><br><span class="line"><span class="comment"># rag_prompt = ChatPromptTemplate.from_messages(</span></span><br><span class="line"><span class="comment">#         [</span></span><br><span class="line"><span class="comment">#             (</span></span><br><span class="line"><span class="comment">#                 &quot;system&quot;,</span></span><br><span class="line"><span class="comment">#                 &quot;You&#x27;re a helpful AI assistant. Given a user question and some Wikipedia article snippets, answer the user question. If none of the articles answer the question, just say you don&#x27;t know.\n\nHere are the Wikipedia articles:&#123;context&#125;&quot;,</span></span><br><span class="line"><span class="comment">#             ),</span></span><br><span class="line"><span class="comment">#             (&quot;human&quot;, &quot;&#123;question&#125;&quot;),</span></span><br><span class="line"><span class="comment">#         ]</span></span><br><span class="line"><span class="comment">#     )</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain</span></span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;<span class="string">&quot;context&quot;</span>: wiki | format_docs, <span class="string">&quot;question&quot;</span>:  RunnablePassthrough()&#125;</span><br><span class="line">    | rag_prompt</span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser()</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Question</span></span><br><span class="line"><span class="built_in">print</span>(rag_chain.invoke(<span class="string">&quot;How fast are cheetahs?&quot;</span>)) </span><br></pre></td></tr></table></figure>
<p>注：代码运行过程中，访问维基百科，某些ip会被拒绝</p>
<ul>
<li><p>运行输出</p>
<p>answer: The cheetah is capable of running at 93 to 104 km/h (58 to 65 mph).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">llama_model_loader: loaded meta data with 21 key-value pairs and 164 tensors from model/gemma-2b-it-q4_k_m.gguf (version GGUF V3 (latest))</span><br><span class="line">llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.</span><br><span class="line">llama_model_loader: - kv   0:                       general.architecture str              = gemma</span><br><span class="line">llama_model_loader: - kv   1:                               general.name str              = gemma-2b-it</span><br><span class="line">llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192</span><br><span class="line">llama_model_loader: - kv   3:                          gemma.block_count u32              = 18</span><br><span class="line">llama_model_loader: - kv   4:                     gemma.embedding_length u32              = 2048</span><br><span class="line">llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 16384</span><br><span class="line">llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 8</span><br><span class="line">llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 1</span><br><span class="line">llama_model_loader: - kv   8:                 gemma.attention.key_length u32              = 256</span><br><span class="line">llama_model_loader: - kv   9:               gemma.attention.value_length u32              = 256</span><br><span class="line">llama_model_loader: - kv  10:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001</span><br><span class="line">llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama</span><br><span class="line">llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 2</span><br><span class="line">llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 1</span><br><span class="line">llama_model_loader: - kv  14:            tokenizer.ggml.padding_token_id u32              = 0</span><br><span class="line">llama_model_loader: - kv  15:            tokenizer.ggml.unknown_token_id u32              = 3</span><br><span class="line">llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,256128]  = [&quot;&lt;pad&gt;&quot;, &quot;&lt;eos&gt;&quot;, &quot;&lt;bos&gt;&quot;, &quot;&lt;unk&gt;&quot;, ...</span><br><span class="line">llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,256128]  = [0.000000, 0.000000, 0.000000, 0.0000...</span><br><span class="line">llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,256128]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...</span><br><span class="line">llama_model_loader: - kv  19:               general.quantization_version u32              = 2</span><br><span class="line">llama_model_loader: - kv  20:                          general.file_type u32              = 15</span><br><span class="line">llama_model_loader: - type  f32:   37 tensors</span><br><span class="line">llama_model_loader: - type q4_K:  109 tensors</span><br><span class="line">llama_model_loader: - type q6_K:   18 tensors</span><br><span class="line">llm_load_vocab: mismatch in special tokens definition ( 544/256128 vs 388/256128 ).</span><br><span class="line">llm_load_print_meta: format           = GGUF V3 (latest)</span><br><span class="line">llm_load_print_meta: arch             = gemma</span><br><span class="line">llm_load_print_meta: vocab type       = SPM</span><br><span class="line">llm_load_print_meta: n_vocab          = 256128</span><br><span class="line">llm_load_print_meta: n_merges         = 0</span><br><span class="line">llm_load_print_meta: n_ctx_train      = 8192</span><br><span class="line">llm_load_print_meta: n_embd           = 2048</span><br><span class="line">llm_load_print_meta: n_head           = 8</span><br><span class="line">llm_load_print_meta: n_head_kv        = 1</span><br><span class="line">llm_load_print_meta: n_layer          = 18</span><br><span class="line">llm_load_print_meta: n_rot            = 256</span><br><span class="line">llm_load_print_meta: n_embd_head_k    = 256</span><br><span class="line">llm_load_print_meta: n_embd_head_v    = 256</span><br><span class="line">llm_load_print_meta: n_gqa            = 8</span><br><span class="line">llm_load_print_meta: n_embd_k_gqa     = 256</span><br><span class="line">llm_load_print_meta: n_embd_v_gqa     = 256</span><br><span class="line">llm_load_print_meta: f_norm_eps       = 0.0e+00</span><br><span class="line">llm_load_print_meta: f_norm_rms_eps   = 1.0e-06</span><br><span class="line">llm_load_print_meta: f_clamp_kqv      = 0.0e+00</span><br><span class="line">llm_load_print_meta: f_max_alibi_bias = 0.0e+00</span><br><span class="line">llm_load_print_meta: n_ff             = 16384</span><br><span class="line">llm_load_print_meta: n_expert         = 0</span><br><span class="line">llm_load_print_meta: n_expert_used    = 0</span><br><span class="line">llm_load_print_meta: pooling type     = 0</span><br><span class="line">llm_load_print_meta: rope type        = 2</span><br><span class="line">llm_load_print_meta: rope scaling     = linear</span><br><span class="line">llm_load_print_meta: freq_base_train  = 10000.0</span><br><span class="line">llm_load_print_meta: freq_scale_train = 1</span><br><span class="line">llm_load_print_meta: n_yarn_orig_ctx  = 8192</span><br><span class="line">llm_load_print_meta: rope_finetuned   = unknown</span><br><span class="line">llm_load_print_meta: model type       = 2B</span><br><span class="line">llm_load_print_meta: model ftype      = Q4_K - Medium</span><br><span class="line">llm_load_print_meta: model params     = 2.51 B</span><br><span class="line">llm_load_print_meta: model size       = 1.39 GiB (4.75 BPW) </span><br><span class="line">llm_load_print_meta: general.name     = gemma-2b-it</span><br><span class="line">llm_load_print_meta: BOS token        = 2 &#x27;&lt;bos&gt;&#x27;</span><br><span class="line">llm_load_print_meta: EOS token        = 1 &#x27;&lt;eos&gt;&#x27;</span><br><span class="line">llm_load_print_meta: UNK token        = 3 &#x27;&lt;unk&gt;&#x27;</span><br><span class="line">llm_load_print_meta: PAD token        = 0 &#x27;&lt;pad&gt;&#x27;</span><br><span class="line">llm_load_print_meta: LF token         = 227 &#x27;&lt;0x0A&gt;&#x27;</span><br><span class="line">llm_load_tensors: ggml ctx size =    0.06 MiB</span><br><span class="line">llm_load_tensors:        CPU buffer size =  1420.21 MiB</span><br><span class="line">............................................................</span><br><span class="line">llama_new_context_with_model: n_ctx      = 512</span><br><span class="line">llama_new_context_with_model: freq_base  = 10000.0</span><br><span class="line">llama_new_context_with_model: freq_scale = 1</span><br><span class="line">llama_kv_cache_init:        CPU KV buffer size =     9.00 MiB</span><br><span class="line">llama_new_context_with_model: KV self size  =    9.00 MiB, K (f16):    4.50 MiB, V (f16):    4.50 MiB</span><br><span class="line">llama_new_context_with_model:        CPU input buffer size   =     0.08 MiB</span><br><span class="line">llama_new_context_with_model:        CPU compute buffer size =     7.88 MiB</span><br><span class="line">llama_new_context_with_model: graph splits (measure): 1</span><br><span class="line">AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | </span><br><span class="line">Model metadata: &#123;&#x27;general.name&#x27;: &#x27;gemma-2b-it&#x27;, &#x27;general.architecture&#x27;: &#x27;gemma&#x27;, &#x27;gemma.context_length&#x27;: &#x27;8192&#x27;, &#x27;gemma.block_count&#x27;: &#x27;18&#x27;, &#x27;gemma.attention.head_count_kv&#x27;: &#x27;1&#x27;, &#x27;gemma.embedding_length&#x27;: &#x27;2048&#x27;, &#x27;gemma.feed_forward_length&#x27;: &#x27;16384&#x27;, &#x27;gemma.attention.head_count&#x27;: &#x27;8&#x27;, &#x27;gemma.attention.key_length&#x27;: &#x27;256&#x27;, &#x27;gemma.attention.value_length&#x27;: &#x27;256&#x27;, &#x27;gemma.attention.layer_norm_rms_epsilon&#x27;: &#x27;0.000001&#x27;, &#x27;tokenizer.ggml.model&#x27;: &#x27;llama&#x27;, &#x27;general.quantization_version&#x27;: &#x27;2&#x27;, &#x27;tokenizer.ggml.bos_token_id&#x27;: &#x27;2&#x27;, &#x27;general.file_type&#x27;: &#x27;15&#x27;, &#x27;tokenizer.ggml.eos_token_id&#x27;: &#x27;1&#x27;, &#x27;tokenizer.ggml.padding_token_id&#x27;: &#x27;0&#x27;, &#x27;tokenizer.ggml.unknown_token_id&#x27;: &#x27;3&#x27;&#125;</span><br><span class="line"> The cheetah is capable of running at 93 to 104 km/h (58 to 65 mph).</span><br><span class="line"></span><br><span class="line">llama_print_timings:        load time =     478.43 ms</span><br><span class="line">llama_print_timings:      sample time =      41.70 ms /    28 runs   (    1.49 ms per token,   671.48 tokens per second)</span><br><span class="line">llama_print_timings: prompt eval time =   13944.05 ms /   378 tokens (   36.89 ms per token,    27.11 tokens per second)</span><br><span class="line">llama_print_timings:        eval time =    1394.02 ms /    27 runs   (   51.63 ms per token,    19.37 tokens per second)</span><br><span class="line">llama_print_timings:       total time =   16688.10 ms /   405 tokens</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="smith-langchain查看过程"><a href="#smith-langchain查看过程" class="headerlink" title="smith.langchain查看过程"></a>smith.langchain查看过程</h2><ul>
<li><p>retriever获取documnment,如下为两个，对应</p>
<p>wiki = WikipediaRetriever(top_k_results=2, doc_content_chars_max=550)</p>
</li>
</ul>
<p><img src="/posts/653ef131/Untitled.png" alt></p>
<ul>
<li><p>format_docs</p>
<p><img src="/posts/653ef131/Untitled 1.png" alt></p>
</li>
<li><p>将检索内容集成的提问与回答</p>
<p><img src="/posts/653ef131/Untitled 2.png" alt></p>
</li>
</ul>
<h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><h3 id="增强RAG过程，提高检索有效性等"><a href="#增强RAG过程，提高检索有效性等" class="headerlink" title="增强RAG过程，提高检索有效性等"></a>增强RAG过程，提高检索有效性等</h3><ul>
<li><p>举例1</p>
<p>来源：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/use_cases/question_answering/citations/#retrieval-post-processing">Citations | 🦜️🔗 LangChain</a></p>
<p>对检索到的文档进行后处理以压缩内容，这样源内容已经足够少，我们就不需要模型来引用特定的来源或跨度。</p>
<p>修改后的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Retrieval_post_processing</span>():</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">     post-process our retrieved documents to compress the content, so that the source content is already minimal enough that we don’t need the model to cite specific sources or spans.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">from</span> langchain.retrievers.document_compressors <span class="keyword">import</span> EmbeddingsFilter</span><br><span class="line">    <span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> LlamaCppEmbeddings</span><br><span class="line">    <span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line">    wiki = WikipediaRetriever(top_k_results=<span class="number">3</span>, doc_content_chars_max=<span class="number">1000</span>)</span><br><span class="line">    rag_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">        [</span><br><span class="line">            (</span><br><span class="line">                <span class="string">&quot;system&quot;</span>,</span><br><span class="line">                <span class="string">&quot;You&#x27;re a helpful AI assistant. Given a user question and some Wikipedia article snippets, answer the user question. If none of the articles answer the question, just say you don&#x27;t know.\n\nHere are the Wikipedia articles:&#123;context&#125;&quot;</span>,</span><br><span class="line">            ),</span><br><span class="line">            (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;question&#125;&quot;</span>),</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">format_docs</span>(<span class="params">docs: <span class="type">List</span>[Document]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Convert Documents to a single string.:&quot;&quot;&quot;</span></span><br><span class="line">        formatted = [</span><br><span class="line">            <span class="string">f&quot;Article Title: <span class="subst">&#123;doc.metadata[<span class="string">&#x27;title&#x27;</span>]&#125;</span>\nArticle Snippet: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">for</span> doc <span class="keyword">in</span> docs</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;\n\n&quot;</span>.join(formatted)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">format</span> = itemgetter(<span class="string">&quot;docs&quot;</span>) | RunnableLambda(format_docs)</span><br><span class="line">    <span class="comment"># subchain for generating an answer once we&#x27;ve done retrieval</span></span><br><span class="line">    answer = rag_prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line">    splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        chunk_size=<span class="number">500</span>,</span><br><span class="line">        chunk_overlap=<span class="number">0</span>,</span><br><span class="line">        separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot;.&quot;</span>, <span class="string">&quot; &quot;</span>],</span><br><span class="line">        keep_separator=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    compressor = EmbeddingsFilter(embeddings=LlamaCppEmbeddings(model_path=model_path), k=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split_and_filter</span>(<span class="params"><span class="built_in">input</span></span>) -&gt; <span class="type">List</span>[Document]:</span><br><span class="line">        docs = <span class="built_in">input</span>[<span class="string">&quot;docs&quot;</span>]</span><br><span class="line">        question = <span class="built_in">input</span>[<span class="string">&quot;question&quot;</span>]</span><br><span class="line">        split_docs = splitter.split_documents(docs)</span><br><span class="line">        stateful_docs = compressor.compress_documents(split_docs, question)</span><br><span class="line">        <span class="keyword">return</span> [stateful_doc <span class="keyword">for</span> stateful_doc <span class="keyword">in</span> stateful_docs]</span><br><span class="line"></span><br><span class="line">    retrieve = (</span><br><span class="line">            RunnableParallel(question=RunnablePassthrough(), docs=wiki) | split_and_filter</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># docs = retrieve.invoke(&quot;How fast are cheetahs?&quot;)</span></span><br><span class="line">    <span class="comment"># for doc in docs:</span></span><br><span class="line">    <span class="comment">#     print(doc.page_content)</span></span><br><span class="line">    <span class="comment">#     print(&quot;\n\n&quot;)</span></span><br><span class="line">    chain_4 = (</span><br><span class="line">        RunnableParallel(question=RunnablePassthrough(), docs=retrieve)</span><br><span class="line">        .assign(context=<span class="built_in">format</span>)</span><br><span class="line">        .assign(answer=answer)</span><br><span class="line">        .pick([<span class="string">&quot;answer&quot;</span>, <span class="string">&quot;docs&quot;</span>])</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># Note the documents have an article &quot;summary&quot; in the metadata that is now much longer than the</span></span><br><span class="line">    <span class="comment"># actual document page content. This summary isn&#x27;t actually passed to the model.</span></span><br><span class="line">    <span class="built_in">print</span>(chain_4.invoke(<span class="string">&quot;How fast are cheetahs?&quot;</span>))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="应用RAG为其他任务赋能"><a href="#应用RAG为其他任务赋能" class="headerlink" title="应用RAG为其他任务赋能"></a>应用RAG为其他任务赋能</h3><p>如LLM+分类任务</p>
<h3 id="搜索引擎赋能"><a href="#搜索引擎赋能" class="headerlink" title="搜索引擎赋能"></a>搜索引擎赋能</h3><p><a target="_blank" rel="noopener" href="https://morphic.sh/">https://morphic.sh/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/miurla/morphic">https://github.com/miurla/morphic</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb">rag-from-scratch/rag_from_scratch_1_to_4.ipynb at main · langchain-ai/rag-from-scratch</a></p>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/use_cases/question_answering/citations/#setup">Citations | 🦜️🔗 LangChain</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/rllm-project/rllm/tree/main/examples/small_examples_with_LLM">rllm/examples/small_examples_with_LLM at main · rllm-project/rllm (github.com)</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Xandra
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://xandra298.github.io/posts/653ef131/" title="RAG with Gemma using wikipedia api">https://xandra298.github.io/posts/653ef131/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/RAG/" rel="tag"><i class="fa fa-tag"></i> RAG</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/91a389bb/" rel="prev" title="Retrieval Augmented Generation (RAG)">
                  <i class="fa fa-chevron-left"></i> Retrieval Augmented Generation (RAG)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/b63e64f2/" rel="next" title="视频生成实践">
                  视频生成实践 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xandra</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">130k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">1:58</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"wvaline.xandrax.cafe","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"placeholder":"请文明评论呀","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"visitor":false,"comment_count":true,"requiredFields":[],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","el":"#waline","comment":true,"path":"/posts/653ef131/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>


  <script async src="/js/cursor/fireworks.js"></script>




  <script src="/js/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>






<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
