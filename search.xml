<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Learning Multimodal Violence Detection under Weak Supervision</title>
    <url>/posts/undefined/</url>
    <content><![CDATA[<h1 id="Not-only-look-but-also-listen-Learning-multimodal-violence-detection-under-weak-supervision"><a href="#Not-only-look-but-also-listen-Learning-multimodal-violence-detection-under-weak-supervision" class="headerlink" title="Not only look, but also listen: Learning multimodal violence detection under weak supervision"></a>Not only look, but also listen: Learning multimodal violence detection under weak supervision</h1><p><a href="https://arxiv.org/pdf/2007.04687.pdf">paper</a> ï¼Œ<a href="https://roc-ng.github.io/XD-Violence/">code and dataset</a></p>
<p>æš´åŠ›è§†é¢‘æ£€æµ‹æ–¹å‘è®ºæ–‡</p>
<blockquote>
<p> ğŸ’¡ We introduce a HL-Net to simultaneously capture <strong>long-range relations</strong> and<br><strong>local distance relations</strong>, of which these two relations are based on similarity prior and proximity prior, respectively</p>
<p>ä¸‰ä¸ªå¹¶è¡Œçš„branchæ•æ‰è§†é¢‘ç‰‡æ®µå’Œé›†æˆçš„ç‰¹å¾ä¹‹é—´çš„ä¸åŒè”ç³»:</p>
<ul>
<li>holistic branch captures long-range dependencies using similarity prior,</li>
<li>localized branch captures local positional relation using proximity prior,</li>
<li>score branch dynamically captures the closeness of predicted score.</li>
</ul>
</blockquote>
<span id="more"></span>
<p>ç›¸å…³å·¥ä½œï¼Œå…¶ä¸­attentionéƒ¨åˆ†å¯ä»¥åé¢çœ‹ä¸‹ï¼›</p>
<p>ä¸€äº›å·¥ä½œå°†å›¾ç¥ç»ç½‘ç»œ(GCNs)[20,39]åœ¨å›¾ä¸Šå»ºç«‹ä¸åŒèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»æ¨¡å‹ï¼Œå¹¶å­¦ä¹ è®¡ç®—æœºè§†è§‰çš„å¼ºå¤§è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼ŒGCNè¢«ç”¨äºæ—¶é—´æ€§åŠ¨ä½œå®šä½[50]ã€è§†é¢‘åˆ†ç±»[37,41]ã€å¼‚å¸¸æ£€æµ‹[51]ã€‚åŸºäºéª¨æ¶çš„åŠ¨ä½œè¯†åˆ«[33,45]ï¼Œç‚¹äº‘è¯­ä¹‰åˆ†å‰²[21]ï¼Œå›¾åƒè¯´æ˜[46]ç­‰ç­‰ã€‚é™¤äº†GCNï¼Œæ—¶é—´å…³ç³»ç½‘ç»œ[52]ï¼Œæ—¨åœ¨å­¦ä¹ å’Œæ¨ç†è§†é¢‘å¸§ä¹‹é—´çš„æ—¶é—´ä¾èµ–å…³ç³»ï¼Œè¢«æå‡ºæ¥ç”¨äºè§£å†³è§†é¢‘åˆ†ç±»ã€‚æœ€è¿‘ï¼Œè‡ªæˆ‘æ³¨æ„ç½‘ç»œ[40,47,5,18]å·²è¢«æˆåŠŸåº”ç”¨äºè§†è§‰é—®é¢˜ã€‚æ³¨æ„åŠ›æ“ä½œå¯ä»¥é€šè¿‡èšåˆä¸€ç»„å…ƒç´ çš„ä¿¡æ¯æ¥å½±å“å•ä¸ªå…ƒç´ ï¼Œå…¶ä¸­èšåˆçš„æƒé‡æ˜¯è‡ªåŠ¨å­¦ä¹ çš„ã€‚</p>
<h1 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h1><h2 id="æ€»ä½“æ¡†æ¶å›¾"><a href="#æ€»ä½“æ¡†æ¶å›¾" class="headerlink" title="æ€»ä½“æ¡†æ¶å›¾"></a>æ€»ä½“æ¡†æ¶å›¾</h2><p><img src="/posts/undefined/Untitled.png" alt></p>
<ul>
<li><p>ç‰¹å¾æå–ï¼šusing the sliding window mechanism æå– è§†é¢‘ç‰¹å¾å’Œå£°éŸ³ç‰¹å¾ï¼Œåˆå¹¶æˆèåˆç‰¹å¾ï¼ˆèåˆéƒ¨åˆ†ä¸äºˆå…³æ³¨ã€‚æ»‘åŠ¨çª—å£æœºåˆ¶å¾…çœ‹ï¼‰</p>
<blockquote>
<p>Visual features: utilize two mainstream networks-C3D and I3D networks. we extract fc6 features from C3D that is pretrained on the Sports-1M dataset, and extract global_pool features from I3D pre-trained on Kinetics-200 dataset.</p>
</blockquote>
</li>
</ul>
<h2 id="Holistic-and-Localized-Networks"><a href="#Holistic-and-Localized-Networks" class="headerlink" title="Holistic and Localized Networks"></a>Holistic and Localized Networks</h2><h3 id="Holistic-ç‰¹å¾ç›¸ä¼¼æ€§"><a href="#Holistic-ç‰¹å¾ç›¸ä¼¼æ€§" class="headerlink" title="Holistic - ç‰¹å¾ç›¸ä¼¼æ€§"></a><strong>Holistic - ç‰¹å¾ç›¸ä¼¼æ€§</strong></h3><hr>
<p>é€šç”¨çš„å›¾å·ç§¯è¡¨ç¤ºå¯ä»¥çœ‹ä¸ºï¼š</p>
<script type="math/tex; mode=display">
X_l+1 = Update(Aggregate(X_l,W_l^{agg},W_l^{update}))</script><ul>
<li><strong>GCNèŒƒå¼ï¼š</strong><script type="math/tex; mode=display">
X^H_{l+1} = Dropout(ReLU(A^HX^H_lW^H_l))</script></li>
</ul>
<p>æ³¨ï¼š$X^H_0 = X^S_0 = X^L_0 = X^F$</p>
<p><strong>ç‰¹å¾ç›¸ä¼¼æ€§çš„é‚»æ¥çŸ©é˜µè¡¨ç¤º:</strong></p>
<script type="math/tex; mode=display">
A^H_{ij} = g(f(x_i,x_j))</script><p>$A^H_{ij}$è¡¡é‡ç¬¬iä¸ªå’Œç¬¬jä¸ªç‰¹å¾çš„ç‰¹å¾ç›¸ä¼¼æ€§ï¼›gæ˜¯å½’ä¸€åŒ–å‡½æ•°ï¼Œfå‡½æ•°è®¡ç®—ä¸€å¯¹ç‰¹å¾çš„ç›¸ä¼¼æ€§ï¼›é™„å½•éƒ¨åˆ†è¿˜è®¨è®ºäº†ä¸€ä¸‹å…¶ä»–ç‰ˆæœ¬çš„ã€‚æœ¬æ–‡å®šä¹‰å¦‚ä¸‹</p>
<ul>
<li>f å®šä¹‰ä¸ºï¼š</li>
</ul>
<script type="math/tex; mode=display">
f(x_i,x_j) = \frac{x_i^Tx_j}{||x_i||_{2} \\ . \\ ||x_j||_2}</script><ul>
<li>thresholdingæ“ä½œï¼ˆ$\tau$æ˜¯threshodï¼Œfå°†ç›¸ä¼¼æ€§é™åˆ¶åœ¨ï¼ˆ0,1]ä¹‹é—´ï¼‰ï¼š</li>
</ul>
<script type="math/tex; mode=display">
f(x_i,x_j) = \begin{cases} f(x_i,x_j)  & f(x_i,x_j) > \tau \\ 0 & f(x_i,x_j)\leq \tau\end{cases}</script><ul>
<li><p>ä½¿ç”¨softmaxä½œä¸ºå½’ä¸€åŒ–å‡½æ•°gï¼Œä½¿å¾—Açš„æ¯ä¸€è¡Œçš„å’Œéƒ½ä¸º1ã€‚</p>
<script type="math/tex; mode=display">
A^H_{ij} = \frac{exp(A^H_{ij})}{\sum ^{T'}_{k=1} exp(A^H_{ij})}</script></li>
</ul>
<h3 id="localized-branch-proximity-prior-å’Œæ—¶é—´ä¸€è‡´æ€§ç±»ä¼¼ï¼‰"><a href="#localized-branch-proximity-prior-å’Œæ—¶é—´ä¸€è‡´æ€§ç±»ä¼¼ï¼‰" class="headerlink" title="localized branch -proximity prior (å’Œæ—¶é—´ä¸€è‡´æ€§ç±»ä¼¼ï¼‰"></a><strong>localized branch -proximity prior (å’Œæ—¶é—´ä¸€è‡´æ€§ç±»ä¼¼ï¼‰</strong></h3><hr>
<script type="math/tex; mode=display">
A^L_{ij} = exp(\frac{-|i-j|^r}{\sigma })</script><h2 id="Online-detection-amp-score-branch"><a href="#Online-detection-amp-score-branch" class="headerlink" title="Online detection &amp; score branch"></a>Online detection &amp; score branch</h2><p>æ­£å¦‚æˆ‘ä»¬æåˆ°çš„ï¼Œæš´åŠ›æ£€æµ‹ç³»ç»Ÿä¸ä»…é€‚ç”¨äºç¦»çº¿æ£€æµ‹ï¼ˆäº’è”ç½‘å½•åƒæœºï¼‰ï¼Œä¹Ÿé€‚ç”¨äºåœ¨çº¿æ£€æµ‹ï¼ˆç›‘æ§ç³»ç»Ÿï¼‰ã€‚ç„¶è€Œï¼Œ<strong>ä¸Šè¿°HL-Net</strong>çš„åœ¨çº¿æ£€æµ‹å—åˆ°äº†ä¸€ä¸ªä¸»è¦éšœç¢çš„é˜»ç¢ï¼š<strong>HL-Netéœ€è¦æ•´ä¸ªè§†é¢‘æ¥è·å¾—é•¿è·ç¦»çš„ä¾èµ–å…³ç³»</strong>ã€‚ä¸ºäº†è·³å‡ºè¿™ä¸ªå›°å¢ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªHLCè¿‘ä¼¼å™¨ï¼ŒåªæŠŠä»¥å‰çš„è§†é¢‘ç‰‡æ®µä½œä¸ºè¾“å…¥ï¼Œåœ¨HL-Netçš„æŒ‡å¯¼ä¸‹äº§ç”Ÿç²¾ç¡®çš„é¢„æµ‹ã€‚ä¸¤ä¸ªå †å çš„FCå±‚å’ŒReLUä»¥åŠä¸€ä¸ªä¸€ç»´å› æœå·ç§¯å±‚æ„æˆäº†HLCè¿‘ä¼¼å™¨ã€‚ä¸€ç»´å› æœå·ç§¯å±‚çš„æ ¸å¤§å°ä¸º5ï¼Œè·¨åº¦ä¸º1ï¼Œåœ¨æ—¶é—´ä¸Šæ»‘åŠ¨å·ç§¯æ»¤æ³¢å™¨ã€‚ä¸€ç»´å› æœå·ç§¯å±‚ä¹Ÿå……å½“åˆ†ç±»å™¨ï¼Œå…¶è¾“å‡ºæ˜¯å½¢çŠ¶ä¸º Tâ€™ çš„æš´åŠ›æ¿€æ´»è¡¨ç¤ºä¸º$C^S$ã€‚æ›´å¦™çš„æ˜¯ï¼Œè¿™ä¸ªæ“ä½œå¼•å…¥äº†ä¸€ä¸ªé¢å¤–çš„åˆ†æ”¯ï¼Œåä¸º<strong>åŠ¨æ€å¾—åˆ†åˆ†æ”¯(dynamic score branch)</strong>ï¼Œä»¥æ‰©å±•HL-Netï¼Œå®ƒå–å†³äº$C^S$ã€‚</p>
<h3 id="score-branch"><a href="#score-branch" class="headerlink" title="score branch"></a>score branch</h3><p>ç”¨äºonline detection, è§£å†³éœ€è¦å°†æ•´ä¸ªè§†é¢‘ä½œä¸ºè¾“å…¥ï¼ˆä»¥è·å¾—é•¿è·ç¦»ä¾èµ–ï¼‰çš„é—®é¢˜ã€‚</p>
<p>è¯¥åˆ†æ”¯çš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªä½ç½®çš„å“åº”è®¡ç®—ä¸ºæ‰€æœ‰ä½ç½®ç‰¹å¾çš„åŠ æƒå’Œï¼Œå…¶ä¸­æƒé‡å–å†³äºåˆ†æ•°çš„æ¥è¿‘ç¨‹åº¦ã€‚ä¸æ•´ä½“å’Œå±€éƒ¨åˆ†æ”¯çš„å…³ç³»çŸ©é˜µä¸åŒï¼Œåˆ†æ•°åˆ†æ”¯çš„å…³ç³»çŸ©é˜µåœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½ä¼šæ›´æ–°ï¼Œå¹¶ä¸”å–å†³äºé¢„æµ‹çš„åˆ†æ•°è€Œä¸æ˜¯å…ˆéªŒã€‚ä»å½¢å¼ä¸Šçœ‹ï¼Œåˆ†æ•°åˆ†æ”¯çš„å…³ç³»çŸ©é˜µè®¾è®¡å¦‚ä¸‹ï¼š</p>
<script type="math/tex; mode=display">
A^S_{ij} = \rho(1 - |s(C^S_i) - s(C^S_j)|)</script><p>sæ˜¯ sigmoid, å‡½æ•°Ïç”¨äºåŠ å¼ºï¼ˆå’Œå‰Šå¼±ï¼‰å¾—åˆ†æ¥è¿‘åº¦å¤§äºï¼ˆå’Œå°äºï¼‰0.5çš„é…å¯¹å…³ç³»ï¼Œsoftmaxä¹Ÿç”¨äºå½’ä¸€åŒ–ã€‚</p>
<script type="math/tex; mode=display">
\rho (x) = \frac{1}{1+exp(-\frac{x-0.5}{0.1})}</script><h2 id="training-based-on-MIL"><a href="#training-based-on-MIL" class="headerlink" title="training based on MIL"></a>training based on MIL</h2><script type="math/tex; mode=display">
C^P = (X^H||X^L||X^S)W</script><p>æ‰€æœ‰è¾“å‡º($C^P å’Œ C^S$)åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„K-maxå–å¹³å‡ä½œä¸ºè¾“å‡ºï¼Œä»¥å¾—åˆ°$y^P$ å’Œ$y^S$ã€‚Kå®šä¹‰ä¸ºTâ€˜ é™¤ä»¥qåŠ ä¸€åå‘ä¸‹å–æ•´ã€‚</p>
<p>è¡¥å……ï¼š top-kç­–ç•¥ï¼ˆWeakly-supervised video anomaly detection with robust temporal feature magnitude learningï¼‰</p>
<ul>
<li>lossç»“åˆä¸‰ä¸ªbranch</li>
</ul>
<blockquote>
<p>The instances corresponding to the K-max activation in the positive bag is most likely to be true positive instances (violence). The instances corresponding to the K-max activation in the negative bag is hard instances. We expect these two types of instances to be as far as possible.</p>
</blockquote>
<p>L_BCEï¼ˆbinary crossentropy) å’ŒL_BCE2åˆ†åˆ«å¯¹åº”ä¸º$y^p å’Œ y^s$ ä¸ ground truth yä¹‹é—´çš„lossã€‚L_DISTILLä¸ºçŸ¥è¯†è’¸é¦æŸå¤±ã€‚</p>
<script type="math/tex; mode=display">
L_{TOTAL}  = L_{BCE} + L_{BCE2} +\lambda L_{DISTILL}</script><script type="math/tex; mode=display">
L_{DISTILL} = \sum \limits^N_{j=1} (- \sum \limits_i s(C^P_i) log (s(C_i^S)))</script><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>æ–¹æ³•æ”¯æŒçº¿ä¸Šå’Œç¦»çº¿çš„æ£€æµ‹ã€‚sigmoidå‡½æ•°ä½œä¸º$C^P$å’Œ$C^S$çš„æ¿€æ´»å‡½æ•°ï¼Œå¹¶æœ€åç”Ÿæˆåœ¨[0,1]ä¹‹é—´çš„æš´åŠ›ç½®ä¿¡å¾—åˆ†ã€‚æ³¨ï¼šåœ¨çº¿ä¸Šé¢„æµ‹ä¸­ï¼Œåªæœ‰HLCè¿‘ä¼¼å™¨å·¥ä½œï¼ŒHL-NETå¯ä»¥ç§»é™¤ã€‚</p>
<h1 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h1><h2 id="è¯„ä¼°æ ‡å‡†"><a href="#è¯„ä¼°æ ‡å‡†" class="headerlink" title="è¯„ä¼°æ ‡å‡†"></a>è¯„ä¼°æ ‡å‡†</h2><p>we utilize the frame-level <strong>precision-recall curve</strong> (PRC) and corresponding area under the curve <strong>(average precision, AP)</strong> [30] rather than receiver operating characteristic curve (ROC) and corresponding area under the curve (AUC) [44,43]<br><strong>since AUC usually shows an optimistic result when dealing with class-imbalanced data, and PRC and AP focus on positive samples (violence)</strong></p>
<ul>
<li>Precision and Recall (PRæ›²çº¿)ï¼šç”¨äºç¨€æœ‰äº‹ä»¶æ£€æµ‹ï¼Œå¦‚ç›®æ ‡æ£€æµ‹ã€ä¿¡æ¯æ£€ç´¢ã€æ¨èç³»ç»Ÿã€‚è´Ÿæ ·æœ¬å¾ˆå¤šçš„æ—¶å€™ï¼Œ??? = FPâ„(FP+TNï¼‰å¾ˆå°ï¼Œæ¯”è¾ƒTPRå’ŒFPRæ²¡æœ‰å¤ªå¤§æ„ä¹‰ï¼ˆROCï¼‰</li>
</ul>
<h2 id="æ€§èƒ½è¡¨ç°"><a href="#æ€§èƒ½è¡¨ç°" class="headerlink" title="æ€§èƒ½è¡¨ç°"></a>æ€§èƒ½è¡¨ç°</h2><p><img src="/posts/undefined/Untitled 1.png" alt></p>
<p>ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆ20å¹´çš„æ–‡ç« ï¼‰</p>
<p>æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåœ¨æˆ‘ä»¬çš„æš´åŠ›æ£€æµ‹ä»»åŠ¡ä¸­ï¼ŒC3Dæ¯”I3Då·®äº†å¾ˆå¤§ä¸€æˆªã€‚</p>
<h2 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h2><ul>
<li>äº”ç§æ¨¡æ€APå¯¹æ¯”</li>
</ul>
<p><img src="/posts/undefined/Untitled 2.png" alt="Untitled"></p>
<p>ï¼ˆè¯¥æ–‡è¯æ˜å£°éŸ³å’Œè§†è§‰çš„èåˆæ£€æµ‹æ•ˆæœæ›´å¥½ï¼Œä¸”è§†è§‰æ¨¡æ€çš„ä½œç”¨ä¼˜äºå£°éŸ³ï¼‰</p>
<ul>
<li><p>ä¸‰ä¸ªåˆ†æ”¯çš„å¯¹æ¯”ï¼ˆholistic, localized and score branchesï¼‰</p>
<ul>
<li>ä¸‰ä¸ªåˆ†æ”¯å•ç‹¬çš„æƒ…å†µè¡¨ç°ç›¸ä¼¼</li>
<li>ç§»é™¤ä»»ä½•ä¸€ä¸ªåˆ†æ”¯éƒ½ä¼šä½¿å¾—è¡¨ç°å˜å·®</li>
<li>HL-NETåœ¨è¿™ä¸‰ä¸ªåˆ†æ”¯ä¸€èµ·ä½œç”¨çš„æ—¶å€™è¡¨ç°æœ€å¥½ï¼Œå› æ­¤è¯æ˜ä¸‰ä¸ªåˆ†æ”¯éƒ½ä¸å¯æ›¿ä»£ã€‚</li>
</ul>
<p><img src="/posts/undefined/Untitled 3.png" alt></p>
</li>
<li><p>online vs offline</p>
<p><img src="/posts/undefined/Untitled 4.png" alt></p>
</li>
</ul>
<h1 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h1><h3 id="å…‰æµ"><a href="#å…‰æµ" class="headerlink" title="å…‰æµ"></a>å…‰æµ</h3><blockquote>
<p>å…‰æµï¼ˆoptical flowï¼‰æ˜¯ç©ºé—´è¿åŠ¨ç‰©ä½“åœ¨è§‚å¯Ÿæˆåƒå¹³é¢ä¸Šçš„åƒç´ è¿åŠ¨çš„ç¬æ—¶é€Ÿåº¦ã€‚<br>å…‰æµæ³•æ˜¯åˆ©ç”¨å›¾åƒåºåˆ—ä¸­åƒç´ åœ¨æ—¶é—´åŸŸä¸Šçš„å˜åŒ–ä»¥åŠç›¸é‚»å¸§ä¹‹é—´çš„ç›¸å…³æ€§æ¥æ‰¾åˆ°ä¸Šä¸€å¸§è·Ÿå½“å‰å¸§ä¹‹é—´å­˜åœ¨çš„å¯¹åº”å…³ç³»ï¼Œä»è€Œè®¡ç®—å‡ºç›¸é‚»å¸§ä¹‹é—´ç‰©ä½“çš„è¿åŠ¨ä¿¡æ¯çš„ä¸€ç§æ–¹æ³•ã€‚<br>é€šå¸¸å°†äºŒç»´å›¾åƒå¹³é¢ç‰¹å®šåæ ‡ç‚¹ä¸Šçš„ç°åº¦ç¬æ—¶å˜åŒ–ç‡å®šä¹‰ä¸ºå…‰æµçŸ¢é‡ã€‚</p>
</blockquote>
<p>ä½œè€…åœ¨ã€ŠOn the Integration of Optical Flow and Action Recognitionã€‹è¿™ç¯‡æ–‡ç« [1]ä¸­æ·±å…¥è®¨è®ºäº†å…‰æµä¸è¡Œä¸ºè¯†åˆ«çš„ç»“åˆï¼Œå¹¶é€šè¿‡å®éªŒè§‚å¯Ÿåˆ°å¦‚ä¸‹ç»“è®ºï¼š<br>ï¼ˆ1ï¼‰å…‰æµå¯¹äºè¡Œä¸ºè¯†åˆ«æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒçš„å¤–è§‚ä¸å˜æ€§ï¼›<br>ï¼ˆ2ï¼‰å…‰æµæ³•é‡‡ç”¨æœ€å°åŒ–ç«¯ç‚¹è¯¯å·®ï¼ˆEPEï¼Œend-point-errorï¼‰æ¥ä¼˜åŒ–ï¼Œä½†æ˜¯å½“å‰EPEæ–¹æ³•ä¸åŠ¨ä½œè¯†åˆ«æ€§èƒ½æ²¡æœ‰å¾ˆå¥½çš„ç›¸å…³æ€§ï¼›<br>ï¼ˆ3ï¼‰å¯¹äºæµ‹è¯•è¿‡çš„å…‰æµæ–¹æ³•ï¼Œåœ¨è¾¹ç•Œä¸Šå’Œå°ä½ç§»ä¸Šçš„ç²¾åº¦ä¸åŠ¨ä½œè¯†åˆ«æ€§èƒ½æœ€ç›¸å…³ï¼›<br>ï¼ˆ4ï¼‰é‡‡ç”¨æœ€å°åŒ–åˆ†ç±»è¯¯å·®ï¼ˆè€ŒéEPEï¼‰æ¥è®­ç»ƒå…‰æµå¯ä»¥æé«˜è¯†åˆ«æ€§èƒ½ï¼›<br>ï¼ˆ5ï¼‰ç”¨äºè¡Œä¸ºè¯†åˆ«ä»»åŠ¡çš„å…‰æµä¸åŒäºä¼ ç»Ÿçš„å…‰æµï¼Œç‰¹åˆ«æ˜¯åœ¨äººä½“å†…éƒ¨å’Œèº«ä½“è¾¹ç•Œå¤„ã€‚<br>åŸæ–‡é“¾æ¥ï¼š<a href="https://blog.csdn.net/zhang_can/article/details/80259946">https://blog.csdn.net/zhang_can/article/details/80259946</a></p>
]]></content>
      <categories>
        <category>è§†é¢‘æ£€æµ‹</category>
      </categories>
      <tags>
        <tag>æ·±åº¦è§†é¢‘æ£€æµ‹</tag>
        <tag>æš´åŠ›è§†é¢‘æ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo Hello World</title>
    <url>/posts/1e44dbaf/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>hexoé…ç½®</category>
      </categories>
  </entry>
  <entry>
    <title>pytorchlearning</title>
    <url>/posts/643f7c73/</url>
    <content><![CDATA[<h1 id="pytorch-å­¦ä¹ è®°å½•"><a href="#pytorch-å­¦ä¹ è®°å½•" class="headerlink" title="pytorch å­¦ä¹ è®°å½•"></a>pytorch å­¦ä¹ è®°å½•</h1><span id="more"></span>
<p>è§†é¢‘å­¦ä¹ ç¬”è®°githubå­˜å‚¨ä»“åº“ï¼šï¼ˆ@ljhï¼‰</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning">Xandra298/Pytorchlearning (github.com)</a></p>
<ul>
<li><p>torchåŸºç¡€æ“ä½œ</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning/blob/all/3.pytorchåŸºç¡€æ“ä½œ.ipynb">Pytorchlearning/3.pytorchåŸºç¡€æ“ä½œ.ipynb at all Â· Xandra298/Pytorchlearning (github.com)</a></p>
</li>
<li><p>è‡ªå®šä¹‰æ•°æ®é›†é¢„å¤„ç†ä¸åŠ è½½</p>
<p><a href="https://xandra298.github.io/posts/a0ca199b/">ã€pytorch learningã€‘(ä¸€)è‡ªå®šä¹‰æ•°æ®é›†é¢„å¤„ç†å’ŒåŠ è½½</a></p>
</li>
<li><p>å®Œæ•´æ¨¡å‹æ­å»ºã€è®­ç»ƒã€æµ‹è¯•</p>
<p><a href="https://xandra298.github.io/posts/13fc6476/">ã€pytorch-learningã€‘(äºŒ) æ¨¡å‹æ­å»º-è®­ç»ƒ-æµ‹è¯• </a></p>
</li>
<li><p>å¯è§†åŒ–</p>
<p><a href="https://xandra298.github.io/posts/f19419c5/">ã€pytorch-learningã€‘(ä¸‰) å¯è§†åŒ– </a></p>
</li>
<li><p>ã€ç†è®ºã€‘éšæœºæ¢¯åº¦ä¸‹é™</p>
<p>åŒ…æ‹¬æŸå¤±å‡½æ•°ç­‰:  <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/4.éšæœºæ¢¯åº¦ä¸‹é™.ipynb">ç¬”è®°</a></p>
</li>
<li><p>è¿‡æ‹ŸåˆåŠä¼˜åŒ–trick</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning/blob/all/7. è¿‡æ‹ŸåˆåŠä¼˜åŒ–trick.ipynb">Pytorchlearning/è¿‡æ‹ŸåˆåŠä¼˜åŒ–trick</a></p>
</li>
<li><p>å·ç§¯ç¥ç»ç½‘ç»œ: <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/8.å·ç§¯ç¥ç»ç½‘ç»œ.ipynb">ç¬”è®°</a></p>
</li>
<li><p>å¾ªç¯ç¥ç»ç½‘ç»œ: <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/9.å¾ªç¯ç¥ç»ç½‘ç»œ.ipynb">ç¬”è®°</a></p>
</li>
<li><p>è‡ªç¼–ç å™¨: <a href="https://github.com/Xandra298/Pytorchlearning/blob/master/10.è‡ªç¼–ç å™¨.ipynb">ç¬”è®°</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>æ·±åº¦å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>ã€pytorch learningã€‘(ä¸€)è‡ªå®šä¹‰æ•°æ®é›†é¢„å¤„ç†å’ŒåŠ è½½</title>
    <url>/posts/a0ca199b/</url>
    <content><![CDATA[<h1 id="é€šç”¨å®ç°"><a href="#é€šç”¨å®ç°" class="headerlink" title="é€šç”¨å®ç°"></a>é€šç”¨å®ç°</h1><p>å…³é”®åº“ï¼šDatasetå’Œ DataLoader</p>
<p><code>from torch.utils.data import  Dataset,DataLoader</code></p>
<p>ä»£ç ä½¿ç”¨æ•°æ®é›†ï¼š<a href="https://github.com/Xandra298/Pytorchlearning/tree/master/pokeman">å®å¯æ¢¦</a></p>
<span id="more"></span>
<p>è¯¥æ•°æ®é›†ç›®å½•æ ¼å¼ä¸ºï¼š</p>
<p> root dir:</p>
<ul>
<li>dir1(name is the class)<ul>
<li>pic1</li>
<li>pic2</li>
<li>â€¦</li>
</ul>
</li>
<li>dir2(name is the class)<ul>
<li>â€¦</li>
</ul>
</li>
</ul>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>ç»§æ‰¿Datasetç±»çš„å®ç°</p>
<p>éœ€è¦é‡è½½æ–¹æ³•ï¼š</p>
<ul>
<li>__len__:è¿”å›æ•°æ®é›†é•¿åº¦ï¼ˆæ•°æ®æ•°é‡ï¼‰</li>
<li>__get_item__ï¼šè·å–æ•°æ®é›†çš„item</li>
</ul>
<p>å…³é”®æ€è·¯ï¼šå…·ä½“è§ä»£ç åŠä»£ç æ³¨é‡Š</p>
<p>è‡ªå®šä¹‰æ–¹æ³•load_csv:</p>
<ol>
<li>éå†ç›®å½•ï¼Œå°†image_path-labelå­˜å‚¨åˆ°csvæ–‡ä»¶ä¸­ï¼š</li>
</ol>
<ul>
<li>ç”¨<code>glob.glob</code>è·å–å…·ä½“è·¯å¾„çš„æ•°æ®è·¯å¾„</li>
<li><code>csv.writer(f)</code>å°†image_path,labelå†™å…¥csvæ–‡ä»¶</li>
</ul>
<ol>
<li>è¯»å–csvæ–‡ä»¶ï¼Œè·å¾—image_path-label</li>
</ol>
<ul>
<li>reader = <code>csv.reader(f)</code>ï¼Œfor row in reader:â€¦</li>
</ul>
<p>lenæ–¹æ³•ï¼š</p>
<ul>
<li>è¿”å›æ•°æ®é›†é•¿åº¦</li>
</ul>
<p>get_itemæ–¹æ³•ï¼š</p>
<ul>
<li><p>ä¼ å…¥index,ä»æˆ‘ä»¬å…¨å±€çš„åˆ—è¡¨ä¸­è·å¾—å¯¹åº”çš„æ•°æ®</p>
</li>
<li><p>é€šè¿‡è¯»å–csvæ–‡ä»¶ï¼Œä¼ å…¥index, å¯ä»¥è·å¾—å¯¹åº”çš„image_path - labelå¯¹ã€‚</p>
<p>ç›®æ ‡ï¼šè½½å…¥image_pathï¼Œå¤„ç†å›¾ç‰‡ï¼Œè¿”å›ç¬¦åˆè¦æ±‚çš„å›¾ç‰‡æ•°æ®å’Œlabelå¯¹</p>
</li>
<li><p>å¤„ç†ä»è·¯å¾„ä¸Šè¯»å–çš„æ•°æ®ï¼Œè¿”å›æŒ‡å®šæ ¼å¼ã€‚å¦‚ä½¿ç”¨<code>torchvision.transform</code>ï¼Œæœ€åå¤„ç†å®Œçš„æ ¼å¼æ˜¯tensor</p>
</li>
<li><p>è¿”å›æ•°æ®å’Œlabelå¯¹</p>
</li>
</ul>
<p>å…³äºmodeï¼Œå¯ä»¥é€šè¿‡åˆ¤æ–­éœ€è¦è®­ç»ƒé›†æˆ–è€…æµ‹è¯•é›†è¿™æ ·å­ï¼Œè¿”å›åˆ‡åˆ†åçš„æ•°æ®é›†</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os,glob</span><br><span class="line"><span class="keyword">import</span> random,csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pokemen</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root,resize,mode</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param root: root dir of dataset</span></span><br><span class="line"><span class="string">                    root dir:</span></span><br><span class="line"><span class="string">                        - dir1(name is the class)</span></span><br><span class="line"><span class="string">                            - pic1</span></span><br><span class="line"><span class="string">                            - pic2</span></span><br><span class="line"><span class="string">                            - ...</span></span><br><span class="line"><span class="string">                        - dir2(name is the class)</span></span><br><span class="line"><span class="string">                        - ...</span></span><br><span class="line"><span class="string">        :param resize:</span></span><br><span class="line"><span class="string">        :param mode: train\test\val</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Pokemen, self).__init__()</span><br><span class="line">        self.root = root</span><br><span class="line">        self.resize = resize</span><br><span class="line"></span><br><span class="line">        self.name2label = &#123;&#125;<span class="comment">#  save the dict &#123;name:int&#125; </span></span><br><span class="line">        <span class="comment">#list the dir name under the root dir</span></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(os.path.join(root))): <span class="comment"># sorted to ensure every time to be the same</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root,name)):</span><br><span class="line">                <span class="comment"># not a dir</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># get the name:int following the order</span></span><br><span class="line">            self.name2label[name] = <span class="built_in">len</span>(self.name2label.keys())</span><br><span class="line">        <span class="built_in">print</span>(self.name2label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># read from csv: image_path-labelï¼›</span></span><br><span class="line">        <span class="comment"># function load_csvï¼šsave the image_path-label to csv and then read from csv</span></span><br><span class="line">        self.images,self.labels = self.load_csv(<span class="string">&quot;image.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#split dataset</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>: <span class="comment">#60%</span></span><br><span class="line">            self.images = self.images[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;val&#x27;</span>: <span class="comment">#20%</span></span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.images)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.labels)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.images)):]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.labels)):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_csv</span>(<span class="params">self,filename</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        save image_path-label to csv(if csv exits,just read from it) ï¼Œand then read from it</span></span><br><span class="line"><span class="string">        :param filename: filepath of the csv to save and read</span></span><br><span class="line"><span class="string">        :return: images,labels==&gt; images_path,labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        savepath = os.path.join(self.root,filename)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">            images = []</span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> self.name2label.keys():</span><br><span class="line">                <span class="comment">#grop the pic, save to list</span></span><br><span class="line">                images += glob.glob(os.path.join(self.root,name,<span class="string">&#x27;*.png&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.gif&#x27;</span>))</span><br><span class="line">            <span class="comment">#print(images)</span></span><br><span class="line">            <span class="comment">#&#x27;./pokeman/squirtle\\00000073.png&#x27;</span></span><br><span class="line">            random.shuffle(images) <span class="comment">#shuffle</span></span><br><span class="line">            <span class="comment">#write into csv</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(savepath,mode=<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                writer = csv.writer(f)</span><br><span class="line">                <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">                    name = img.split(os.sep)[-<span class="number">2</span>]</span><br><span class="line">                    label = self.name2label[name]</span><br><span class="line">                    writer.writerow([img,label])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;written into csv file:&#x27;</span>,savepath)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#read from csv</span></span><br><span class="line">        images,labels = [],[]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(savepath) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">                img,label = row</span><br><span class="line">                label = <span class="built_in">int</span>(label)</span><br><span class="line">                images.append(img)</span><br><span class="line">                labels.append(label)</span><br><span class="line">        <span class="keyword">assert</span>  <span class="built_in">len</span>(images) == <span class="built_in">len</span>(labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  images,labels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :return: len of dataset</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param item: range in [0,len(images)]</span></span><br><span class="line"><span class="string">        :return: self.images,self.labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        img,label = self.images[item],self.labels[item]</span><br><span class="line"></span><br><span class="line">        tf = transforms.Compose(</span><br><span class="line">            [<span class="keyword">lambda</span> x:Image.<span class="built_in">open</span>(x).convert(<span class="string">&#x27;RGB&#x27;</span>), <span class="comment"># open image and convert to RGB</span></span><br><span class="line">             transforms.Resize((<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>),<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>))), <span class="comment"># resize</span></span><br><span class="line">             transforms.RandomRotation(<span class="number">15</span>), <span class="comment"># rotate</span></span><br><span class="line">             transforms.CenterCrop(self.resize), <span class="comment">#center crop</span></span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>]),<span class="comment">#values computed from ImageNetï¼Œwe could use it in other dataset</span></span><br><span class="line"></span><br><span class="line">             ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        img = tf(img)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">denormalize</span>(<span class="params">self,x_hat</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        x_hat = (x - mean)/std</span></span><br><span class="line"><span class="string">        x = x_hat * std + mean</span></span><br><span class="line"><span class="string">        :param x_hat: shape[3,self.resize,self.resize]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">        std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        mean = torch.tensor(mean).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        std = torch.tensor(std).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = x_hat*std+mean</span><br><span class="line">        <span class="keyword">return</span>  x</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># dataset</span></span><br><span class="line">    db_train = Pokemen(root=<span class="string">&#x27;pokeman&#x27;</span>,resize=<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    <span class="comment"># dataloader</span></span><br><span class="line">    dl_train = DataLoader(dataset=db_train,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line">    x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(dl_train))</span><br><span class="line">    <span class="built_in">print</span>(x.shape,y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;.ipynb_checkpoints&#39;: 0, &#39;bulbasaur&#39;: 1, &#39;charmander&#39;: 2, &#39;mewtwo&#39;: 3, &#39;pikachu&#39;: 4, &#39;squirtle&#39;: 5&#125;
written into csv file: pokeman\image.csv
torch.Size([32, 3, 224, 224]) torch.Size([32])
</code></pre><h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p>ä¼ å…¥æ•°æ®é›†ï¼Œå¤„ç†ä¸ºbatchã€‚ä¸»è¦å‚æ•°ï¼šbatch_size</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dl_train = DataLoader(dataset=db_train,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>å…¶ä»–å¸¸ç”¨å‚æ•°ï¼š</p>
<ul>
<li>num_workers ( int, optional): how many subprocesses to use for data loading. <code>0</code> means that the data will be loaded in the main process. (default: <code>0</code>)</li>
<li>drop_last (bool, optional): set to <code>True</code> to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If <code>False</code> and  the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: <code>False</code>)</li>
</ul>
<p>å®˜æ–¹æ–‡æ¡£ï¼š<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">torch.utils.data â€” PyTorch 1.13 documentation</a></p>
<p>dl_trainè¿”å›çš„å‚æ•°å¯¹åº”dataset get_itemçš„return å‚æ•°</p>
<ul>
<li><p><code>x,y = next(iter(dataset))</code></p>
</li>
<li><p><code>X,Y = next(iter(dataloader))</code></p>
</li>
</ul>
<p>X.shape == (batchsize,x.shape)</p>
<p><strong>è¿›è¡Œè®­ç»ƒæ—¶çš„ä¸€èˆ¬æ¨¡å¼ï¼š</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> idx,(x,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_train):</span><br><span class="line">	x,label = x.to(device),y.to(device)</span><br><span class="line">	pred = model(x)</span><br><span class="line">	loss = lossFunction(pred,label)</span><br><span class="line">	optimizer.zero_grad()</span><br><span class="line">	loss.backward()</span><br><span class="line">	loss.step()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="ç‰¹æ®Šä¾¿æ·æ–¹å¼æ•°æ®é›†åŠ è½½"><a href="#ç‰¹æ®Šä¾¿æ·æ–¹å¼æ•°æ®é›†åŠ è½½" class="headerlink" title="ç‰¹æ®Šä¾¿æ·æ–¹å¼æ•°æ®é›†åŠ è½½"></a>ç‰¹æ®Šä¾¿æ·æ–¹å¼æ•°æ®é›†åŠ è½½</h1><p>ä½¿ç”¨å‡½æ•°<code>datasets.ImageFolder</code> </p>
<p>ä½¿ç”¨åœºæ™¯ï¼šé€‚ç”¨äºå°†æ•°æ®é›†åˆ†æ–‡ä»¶å¤¹å­˜å‚¨ï¼Œæ–‡ä»¶å¤¹åç§°ä¸ºå¯¹åº”çš„label</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf  = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>,<span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"><span class="comment">##é€‚ç”¨äºå°†æ•°æ®é›†åˆ†æ–‡ä»¶å¤¹å­˜å‚¨ï¼Œæ–‡ä»¶å¤¹åç§°ä¸ºå¯¹åº”çš„label</span></span><br><span class="line">db = torchvision.datasets.ImageFolder(root=<span class="string">&#x27;./pokeman/&#x27;</span>,transform=tf)</span><br><span class="line">loader = DataLoader(db,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(db.class_to_idx)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>æ·±åº¦å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>ã€pytorch-learningã€‘(ä¸‰) å¯è§†åŒ–</title>
    <url>/posts/f19419c5/</url>
    <content><![CDATA[<h1 id="tensorboardçš„ä½¿ç”¨"><a href="#tensorboardçš„ä½¿ç”¨" class="headerlink" title="tensorboardçš„ä½¿ç”¨"></a>tensorboardçš„ä½¿ç”¨</h1><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install tensorboard</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="ä½¿ç”¨"><a href="#ä½¿ç”¨" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h2><h3 id="add-scalar"><a href="#add-scalar" class="headerlink" title="add_scalar"></a>add_scalar</h3><h4 id="è¿è¡Œä»£ç "><a href="#è¿è¡Œä»£ç " class="headerlink" title="è¿è¡Œä»£ç "></a><strong>è¿è¡Œä»£ç </strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span>  SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)<span class="comment"># ä¿å­˜logçš„æ–‡ä»¶å¤¾</span></span><br><span class="line"><span class="comment">##y=x</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>,<span class="number">2</span>*i,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<h4 id="å‘½ä»¤è¡Œè¿è¡Œï¼šæ‰“å¼€äº‹ä»¶æ–‡ä»¶"><a href="#å‘½ä»¤è¡Œè¿è¡Œï¼šæ‰“å¼€äº‹ä»¶æ–‡ä»¶" class="headerlink" title="å‘½ä»¤è¡Œè¿è¡Œï¼šæ‰“å¼€äº‹ä»¶æ–‡ä»¶"></a><strong>å‘½ä»¤è¡Œè¿è¡Œï¼šæ‰“å¼€äº‹ä»¶æ–‡ä»¶</strong></h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=logs --port=6007</span><br></pre></td></tr></table></figure>
<p>tensorboardå‚æ•°ï¼š â€”logdir=æ–‡ä»¶å¤¹åç§° â€”port=ç«¯å£å· å¯ä»¥ä¸è®¾ç½®ç«¯å£å·å°±æ˜¯é»˜è®¤ï¼Œä¸ºäº†é¿å…å†²çªå¯ä»¥è®¾ç½®</p>
<p>ç”±äºå¤šæ¬¡æ·»åŠ ï¼Œå¯¼è‡´logæ–‡ä»¶ä¸­æœ‰å„ç§ï¼Œå¯èƒ½å¯¼è‡´tensorboardæ˜¾ç¤ºæ›²çº¿çš„ä¸€äº›æ‹Ÿåˆç­‰ã€‚</p>
<p>è§£å†³ï¼š</p>
<ul>
<li>åˆ é™¤logsæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ï¼Œé‡æ–°è¿è¡Œç¨‹åºã€‚</li>
<li>å¯¹åº”æ¯ä¸ªä»»åŠ¡æ¯æ¬¡éƒ½è®¾ç«‹å­æ–‡ä»¶å¤¹ã€‚</li>
</ul>
<h4 id="æµè§ˆå™¨æŸ¥çœ‹"><a href="#æµè§ˆå™¨æŸ¥çœ‹" class="headerlink" title="æµè§ˆå™¨æŸ¥çœ‹"></a><strong>æµè§ˆå™¨æŸ¥çœ‹</strong></h4><p>ç½‘å€åœ¨å‘½ä»¤è¡Œæœ‰æ˜¾ç¤ºã€‚å‰é¢ç¤ºä¾‹çš„ä¸º localhost:6007ã€‚</p>
<h3 id="add-image"><a href="#add-image" class="headerlink" title="add_image"></a>add_image</h3><p>å›¾ç‰‡</p>
<p>æ•°æ®ç±»å‹éœ€è¦tensoræˆ–è€…numpy array</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span>  SummaryWriter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">img_path = <span class="string">&quot;./hymenoptera_data/hymenoptera_data/train/ants/0013035.jpg&quot;</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">img_array = np.array(img_PIL)</span><br><span class="line"><span class="built_in">print</span>(img_array.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(img_array))</span><br><span class="line">writer.add_image(<span class="string">&quot;test&quot;</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">&quot;HWC&quot;</span>)<span class="comment">##é»˜è®¤æ˜¯CHW,å¦‚æœä¸æ˜¯éœ€è¦è¿›è¡Œè®¾ç½®</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<h3 id="add-graph"><a href="#add-graph" class="headerlink" title="add_graph"></a>add_graph</h3><p>å¯è§†åŒ–æ¨¡å‹</p>
<ul>
<li>ä»£ç ä¸­ä½¿ç”¨tensorboardçš„add_graphå°†æ¨¡å‹åŠ å…¥ï¼Œæ³¨æ„ä¼ å‚éœ€è¦ä¼ å…¥æ¨¡å‹è¾“å…¥ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">model = Model()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs_seq&quot;</span>)</span><br><span class="line">writer.add_graph(model,<span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>å‘½ä»¤è¡Œè¿è¡Œå‘½ä»¤æ‰“å¼€äº‹ä»¶æ–‡ä»¶</p>
</li>
<li><p>æµè§ˆå™¨æŸ¥çœ‹æ¨¡å‹ï¼Œå¯ä»¥ç‚¹å‡»æ”¾å¤§ï¼Œçœ‹æ¨¡å‹å…·ä½“å±‚</p>
</li>
</ul>
<p><img src="/posts/f19419c5/æ¨¡å‹.png" alt="tensorboardæŸ¥çœ‹"></p>
<h1 id="Visdomå¯è§†åŒ–"><a href="#Visdomå¯è§†åŒ–" class="headerlink" title="Visdomå¯è§†åŒ–"></a>Visdomå¯è§†åŒ–</h1><p>çª—å£è§†å›¾ï¼Œç•Œé¢å‹å¥½</p>
<h2 id="å®‰è£…-1"><a href="#å®‰è£…-1" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><ul>
<li>æ–¹å¼ä¸€</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install visdom</span><br></pre></td></tr></table></figure>
<p>å‘½ä»¤è¡Œè¿è¡Œ</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m visdom.server</span><br></pre></td></tr></table></figure>
<p>å¦‚æœæŠ¥é”™æ‰¾ä¸åˆ°è·¯å¾„ï¼Œè§£å†³æ–¹å¼ï¼šåœ¨è¯¥ç›®å½•ä¸‹è‡ªå·±åˆ›å»ºè¯¥æ–‡ä»¶å¤¹</p>
<ul>
<li>å®‰è£…æ–¹å¼2ï¼šé¿å…downloadé—®é¢˜</li>
</ul>
<ol>
<li>pip uninstall visdom</li>
<li>ä»githubä¸‹è½½visdomæ–‡ä»¶</li>
<li>cd è¯¥ç›®å½•ä¸‹ï¼Œpip install -e .</li>
<li>åœ¨é¡¹ç›®è·¯å¾„ä¸‹ python -m visdom.serveræˆåŠŸå¯åŠ¨</li>
</ol>
<h2 id="ä½¿ç”¨-1"><a href="#ä½¿ç”¨-1" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h2><p>visdomçš„ä¸€äº›å…·ä½“ä½¿ç”¨ï¼š<a href="https://blog.csdn.net/weixin_41010198/article/details/117853358">https://blog.csdn.net/weixin_41010198/article/details/117853358</a></p>
<h4 id="ä¸€ä¸ªä½¿ç”¨å®ä¾‹"><a href="#ä¸€ä¸ªä½¿ç”¨å®ä¾‹" class="headerlink" title="ä¸€ä¸ªä½¿ç”¨å®ä¾‹"></a><strong>ä¸€ä¸ªä½¿ç”¨å®ä¾‹</strong></h4><ol>
<li>å‘½ä»¤è¡Œè¿è¡Œ<code>python -m visdom.server</code>æˆåŠŸå¯åŠ¨</li>
<li>è¿è¡Œä»£ç </li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">loss = torch.rand(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">global_step = torch.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">viz = Visdom()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">viz.line([<span class="number">0.</span>],[<span class="number">0.</span>],win=<span class="string">&#x27;train_loss&#x27;</span>,opts = <span class="built_in">dict</span>(title=<span class="string">&#x27;train_loss&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx,lossi <span class="keyword">in</span> <span class="built_in">enumerate</span>(loss):</span><br><span class="line">   </span><br><span class="line">    viz.line([lossi.item()],[idx],win = <span class="string">&#x27;train_loss&#x27;</span>,update=<span class="string">&#x27;append&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ol>
<li>æµè§ˆå™¨æŸ¥çœ‹</li>
</ol>
<p><img src="/posts/f19419c5/image-20221124200104212.png" alt="æµè§ˆå™¨è§†å›¾" style="zoom:67%;"></p>
<h4 id="å®Œæ•´æ¨¡å‹è®­ç»ƒæµ‹è¯•è¿‡ç¨‹ä¸­ä½¿ç”¨visdomå¯è§†åŒ–"><a href="#å®Œæ•´æ¨¡å‹è®­ç»ƒæµ‹è¯•è¿‡ç¨‹ä¸­ä½¿ç”¨visdomå¯è§†åŒ–" class="headerlink" title="å®Œæ•´æ¨¡å‹è®­ç»ƒæµ‹è¯•è¿‡ç¨‹ä¸­ä½¿ç”¨visdomå¯è§†åŒ–"></a>å®Œæ•´æ¨¡å‹è®­ç»ƒæµ‹è¯•è¿‡ç¨‹ä¸­ä½¿ç”¨visdomå¯è§†åŒ–</h4><p><a href="https://github.com/Xandra298/Pytorchlearning/tree/master/mnist data/MNIST">æ‰‹å†™æ•°å­—è¯†åˆ«æ•°æ®é›†</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">import</span>  torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span>  torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span>  torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span>    torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./mnist data/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       <span class="comment"># transforms.Normalize((0.1307,), (0.3081,))</span></span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./mnist data/&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># transforms.Normalize((0.1307,), (0.3081,))</span></span><br><span class="line">    ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">200</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">200</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">10</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">net = MLP().to(device)</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=learning_rate)</span><br><span class="line">criteon = nn.CrossEntropyLoss().to(device)</span><br><span class="line"></span><br><span class="line">viz = Visdom()</span><br><span class="line"></span><br><span class="line">viz.line([<span class="number">0.</span>], [<span class="number">0.</span>], win=<span class="string">&#x27;train_loss&#x27;</span>, opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;train loss&#x27;</span>))</span><br><span class="line">viz.line([[<span class="number">0.0</span>, <span class="number">0.0</span>]], [<span class="number">0.</span>], win=<span class="string">&#x27;test&#x27;</span>, opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;test loss&amp;acc.&#x27;</span>,</span><br><span class="line">                                                   legend=[<span class="string">&#x27;loss&#x27;</span>, <span class="string">&#x27;acc.&#x27;</span>]))</span><br><span class="line">global_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">        logits = net(data)</span><br><span class="line">        loss = criteon(logits, target)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># print(w1.grad.norm(), w2.grad.norm())</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        global_step += <span class="number">1</span></span><br><span class="line">        viz.line([loss.item()], [global_step], win=<span class="string">&#x27;train_loss&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        data, target = data.to(device), target.cuda()</span><br><span class="line">        logits = net(data)</span><br><span class="line">        test_loss += criteon(logits, target).item()</span><br><span class="line"></span><br><span class="line">        pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct += pred.eq(target).<span class="built_in">float</span>().<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    viz.line([[test_loss, correct / <span class="built_in">len</span>(test_loader.dataset)]],</span><br><span class="line">             [global_step], win=<span class="string">&#x27;test&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    viz.images(data.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), win=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    viz.text(<span class="built_in">str</span>(pred.detach().cpu().numpy()), win=<span class="string">&#x27;pred&#x27;</span>,</span><br><span class="line">             opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;pred&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>è§†å›¾</li>
</ul>
<p>â€‹        <img src="/posts/f19419c5/image-20221124201948485.png" alt="image-20221124201948485"></p>
<h2 id="ç«¯å£å ç”¨å¤„ç†"><a href="#ç«¯å£å ç”¨å¤„ç†" class="headerlink" title="ç«¯å£å ç”¨å¤„ç†"></a>ç«¯å£å ç”¨å¤„ç†</h2><p>windowsä¸Š</p>
<ul>
<li>æŸ¥æ‰¾æœ¬ç«¯å£å½“å‰ä½¿ç”¨æƒ…å†µ</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">netstat -ano |findstr &quot;8097&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TCP    0.0.0.0:8097           0.0.0.0:0              LISTENING       12236</span><br><span class="line">  TCP    [::]:8097              [::]:0                 LISTENING       12236</span><br></pre></td></tr></table></figure>
<ul>
<li>æŸ¥è¯¢å½“å‰ç«¯å£PIDçš„è¿›ç¨‹ï¼Œå‰ä¸€æ­¥çœ‹åˆ°ä¸º12236</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tasklist | findstr 12236</span><br></pre></td></tr></table></figure>
<ul>
<li>ç»ˆæ­¢è¿›ç¨‹</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">taskkill /f /t /im &quot;12236&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">æˆåŠŸ: å·²ç»ˆæ­¢ PID 12236 (å±äº PID 7560 å­è¿›ç¨‹)çš„è¿›ç¨‹ã€‚</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>æ·±åº¦å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>å›¾åŸºæœ¬çŸ¥è¯†</title>
    <url>/posts/5f3db67/</url>
    <content><![CDATA[<h1 id="å›¾çš„è¡¨ç¤º"><a href="#å›¾çš„è¡¨ç¤º" class="headerlink" title="å›¾çš„è¡¨ç¤º"></a>å›¾çš„è¡¨ç¤º</h1><p>ç‚¹å’Œè¾¹æ„æˆçš„æ•°æ®ç»“æ„</p>
<p>æ—¥å¸¸ç”Ÿæ´»ä¸­æ— å¤„ä¸åœ¨ï¼šå›¾åƒï¼šåƒç´ å’Œåƒç´ ä¹‹é—´çš„è¿æ¥æ„æˆçš„å›¾; ç½‘é¡µï¼š ç½‘é¡µä¹‹é—´çš„è·³è½¬;</p>
<span id="more"></span>
<h2 id="åˆ†ç±»"><a href="#åˆ†ç±»" class="headerlink" title="åˆ†ç±»"></a>åˆ†ç±»</h2><p><strong>æ— å‘å›¾å’Œæœ‰å‘å›¾</strong></p>
<h2 id="è¡¨ç¤º"><a href="#è¡¨ç¤º" class="headerlink" title="è¡¨ç¤º"></a>è¡¨ç¤º</h2><ul>
<li>é‚»æ¥çŸ©é˜µ</li>
</ul>
<h1 id="å›¾çš„æ€§è´¨"><a href="#å›¾çš„æ€§è´¨" class="headerlink" title="å›¾çš„æ€§è´¨"></a>å›¾çš„æ€§è´¨</h1><h2 id="åº¦"><a href="#åº¦" class="headerlink" title="åº¦"></a>åº¦</h2><ul>
<li>æ— å‘å›¾çš„åº¦==è¯¥èŠ‚ç‚¹è¿æ¥çš„è¾¹çš„æ•°é‡</li>
<li>æœ‰å‘å›¾çš„åº¦<ul>
<li>å‡ºåº¦ï¼šä»è¯¥èŠ‚ç‚¹æŒ‡å‘çš„è¾¹çš„æ•°é‡</li>
<li>å…¥åº¦ï¼šæŒ‡å‘è¯¥èŠ‚ç‚¹çš„è¾¹çš„æ•°é‡</li>
</ul>
</li>
</ul>
<h2 id="å­å›¾"><a href="#å­å›¾" class="headerlink" title="å­å›¾"></a>å­å›¾</h2><p>â€‹    å­å›¾æ‰€æœ‰çš„èŠ‚ç‚¹éƒ½åŒ…å«åœ¨å¤§å›¾é‡Œé¢ï¼›</p>
<p>â€‹    å­å›¾çš„è¾¹éƒ½æ˜¯å¤§å›¾çš„è¾¹çš„å­é›†ï¼›</p>
<h2 id="è¿é€šå›¾å’Œè¿é€šåˆ†é‡"><a href="#è¿é€šå›¾å’Œè¿é€šåˆ†é‡" class="headerlink" title="è¿é€šå›¾å’Œè¿é€šåˆ†é‡"></a>è¿é€šå›¾å’Œè¿é€šåˆ†é‡</h2><p>æ— å‘å›¾</p>
<ul>
<li><p>è¿é€šå›¾ï¼š</p>
<p>ä»»æ„èŠ‚ç‚¹ièƒ½å¤Ÿé€šè¿‡ä¸€äº›è¾¹åˆ°è¾¾èŠ‚ç‚¹jï¼Œåˆ™ç§°ä¹‹ä¸ºè¿é€šå›¾ï¼›åä¹‹éè¿é€šå›¾ã€‚</p>
<p>å¯¹äºä¸€ä¸ªæ— å‘å›¾ï¼šæ²¡æœ‰å­¤ç«‹çš„èŠ‚ç‚¹å…¶å®éƒ½èƒ½è¿é€š</p>
</li>
<li><p>è¿é€šåˆ†é‡ï¼š<br>æ— å‘å›¾Gçš„ä¸€ä¸ªæå¤§è¿é€šå­å›¾ç§°ä¸ºGçš„ä¸€ä¸ªè¿é€šåˆ†é‡ï¼ˆæˆ–è¿é€šåˆ†æ”¯ï¼‰ã€‚</p>
<p>è¿é€šå›¾åªæœ‰ä¸€ä¸ªè¿é€šåˆ†é‡ï¼šä»–æœ¬èº«ï¼›éè¿é€šå›¾æœ‰å¤šä¸ªè¿é€šåˆ†é‡ã€‚</p>
</li>
</ul>
<p>æœ‰å‘å›¾çš„è¿é€šæ€§</p>
<ul>
<li>å¼ºè¿é€šå›¾ï¼šç»™å®šå›¾Gçš„ä»»æ„ä¸¤ä¸ªç»“ç‚¹u,vå¯äº’ç›¸åˆ°è¾¾ã€‚</li>
<li>å¼±è¿é€šå›¾ï¼šè‡³å°‘æœ‰ä¸€å¯¹ç»“ç‚¹ä¸æ»¡è¶³å•å‘è¿é€šï¼Œä½†å»æ‰è¾¹çš„æ–¹å‘ä¹‹åä»æ— å‘å›¾çš„è§‚ç‚¹çœ‹æ˜¯è¿é€šå›¾ã€‚</li>
</ul>
<h2 id="æœ€çŸ­è·¯å¾„å’Œå›¾ç›´å¾„"><a href="#æœ€çŸ­è·¯å¾„å’Œå›¾ç›´å¾„" class="headerlink" title="æœ€çŸ­è·¯å¾„å’Œå›¾ç›´å¾„"></a>æœ€çŸ­è·¯å¾„å’Œå›¾ç›´å¾„</h2><p>ä¸¤ç»“ç‚¹çš„æœ€çŸ­åˆ°è¾¾è·¯å¾„å°±æ˜¯æœ€çŸ­è·¯å¾„</p>
<p>ä¸¤ä¸¤ç»“ç‚¹çš„æœ€çŸ­è·¯å¾„ä¸­çš„é•¿åº¦æœ€å¤§å€¼æ˜¯å›¾ç›´å¾„ã€‚</p>
<h2 id="åº¦ä¸­å¿ƒæ€§"><a href="#åº¦ä¸­å¿ƒæ€§" class="headerlink" title="åº¦ä¸­å¿ƒæ€§"></a>åº¦ä¸­å¿ƒæ€§</h2><script type="math/tex; mode=display">
åº¦ä¸­å¿ƒæ€§ = \frac{N_{degree}}{n-1}</script><p>$N_{degree}$è¡¨ç¤ºè¯¥èŠ‚ç‚¹çš„åº¦ï¼Œnä¸ºè¯¥èŠ‚ç‚¹æ‰€åœ¨å›¾çš„èŠ‚ç‚¹æ€»æ•°ã€‚</p>
<h2 id="ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§Eigenvector-Centrality"><a href="#ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§Eigenvector-Centrality" class="headerlink" title="ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§Eigenvector Centrality"></a>ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§Eigenvector Centrality</h2><p>æœ€å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ä½œä¸ºç‰¹å¾å‘é‡ä¸­å¿ƒæ€§çš„å¯¹æ¯”æŒ‡æ ‡ã€‚</p>
<p>Aä¸ºé‚»æ¥çŸ©é˜µï¼›</p>
<p>å¦‚å›¾ï¼Œæœ€å¤§çš„ç‰¹å¾å€¼æ˜¯ç¬¬ä¸€ä¸ªï¼Œæ‰€ä»¥ç‰¹å¾å‘é‡å¯¹åº”ç¬¬ä¸€åˆ—ã€‚</p>
<p>ï¼ˆç‰¹å¾å‘é‡ä¸­å¿ƒæ€§å°†ç‰¹å¾å‘é‡çš„è´Ÿå€¼å˜æˆæ­£è¿›è¡Œç»Ÿä¸€å¯¹æ¯”ï¼‰</p>
<p><img src="/posts/5f3db67/image-20221126140426649.png" style="zoom: 67%;"></p>
<p>ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ä¸ä»…è€ƒè™‘äº†è‡ªå·±èŠ‚ç‚¹çš„åº¦ï¼Œè¿˜è€ƒè™‘äº†å’Œä»–å‘é‡èŠ‚ç‚¹çš„åº¦çš„æƒ…å†µã€‚å¦‚v4çš„å€¼ä¼šæ¯”v2å’Œv3å¤§æ˜¯å› ä¸ºå®ƒè™½ç„¶åº¦å’Œv2\v3ä¸€æ ·å¤§ï¼Œä½†æ˜¯ç›¸è¿çš„æ˜¯v1å’Œv5ï¼Œæ¯”v2/v3å‘é‡çš„èŠ‚ç‚¹çš„åº¦æ€»ä½“è¦å¤§ã€‚</p>
<p><strong>conclu:ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§æ¯”åº¦ä¸­å¿ƒæ€§å¯ä»¥æ›´å¥½çš„è¡¨ç¤ºèŠ‚ç‚¹åœ¨å›¾ä¸­æ‰€å¤„çš„ä½ç½®ã€‚</strong></p>
<h2 id="ä¸­ä»‹ä¸­å¿ƒæ€§-Betweenness-Centrality"><a href="#ä¸­ä»‹ä¸­å¿ƒæ€§-Betweenness-Centrality" class="headerlink" title="ä¸­ä»‹ä¸­å¿ƒæ€§ Betweenness Centrality"></a>ä¸­ä»‹ä¸­å¿ƒæ€§ Betweenness Centrality</h2><script type="math/tex; mode=display">
Betweenness  = \frac{ç»è¿‡è¯¥èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„}{å…¶ä½™ä¸¤ä¸¤èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„}</script><h2 id="è¿æ¥ä¸­å¿ƒæ€§-Closeness"><a href="#è¿æ¥ä¸­å¿ƒæ€§-Closeness" class="headerlink" title="è¿æ¥ä¸­å¿ƒæ€§ Closeness"></a>è¿æ¥ä¸­å¿ƒæ€§ Closeness</h2><script type="math/tex; mode=display">
Closeness = \frac{n-1}{è¯¥èŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹æœ€çŸ­è·¯å¾„ä¹‹å’Œ}</script><p>â€‹    nä¸ºèŠ‚ç‚¹æ€»æ•°ï¼›</p>
<h2 id="ç½‘é¡µæ’åºç®—æ³•"><a href="#ç½‘é¡µæ’åºç®—æ³•" class="headerlink" title="ç½‘é¡µæ’åºç®—æ³•"></a>ç½‘é¡µæ’åºç®—æ³•</h2><h3 id="pagerank"><a href="#pagerank" class="headerlink" title="pagerank"></a>pagerank</h3><p>è¾¹çš„pagerankå€¼ä¸ºèŠ‚ç‚¹å‘å¤–æŒ‡å‘æ—¶å¹³åˆ†çš„ç»“æœã€‚å¦‚èŠ‚ç‚¹2å‘å¤–æŒ‡å‘çš„è¾¹æœ‰ä¸¤æ¡ï¼Œå› æ­¤ç°åœ¨é‚£ä¸¤æ¡è¾¹çš„pagerankå€¼éƒ½ä¸ºpagerank2/2ã€‚</p>
<p>èŠ‚ç‚¹çš„pagerankå€¼å³ä¸ºæŒ‡å‘å®ƒçš„è¾¹çš„å€¼çš„å’Œã€‚</p>
<p><img src="/posts/5f3db67/image-20221126142317310.png" style="zoom:67%;"></p>
<p>ä¸æ–­çš„è¿­ä»£ï¼Œæœ€åæ¯ä¸ªèŠ‚ç‚¹çš„pagerankå€¼è¾¾åˆ°ç¨³æ€    ã€‚</p>
<p>é˜»å°¼ç³»æ•°ï¼šå¦‚èŠ‚ç‚¹3åˆ°èŠ‚ç‚¹4çš„æ¦‚ç‡æœ‰0.15ã€‚</p>
<h3 id="HITS"><a href="#HITS" class="headerlink" title="HITS"></a>HITS</h3><p><img src="/posts/5f3db67/image-20221126142814847.png" style="zoom: 67%;"></p>
<p>æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰authorityå€¼å’Œhubå€¼</p>
<h1 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">lis =<span class="keyword">lambda</span> x:random.randint(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">edges  = pd.DataFrame()</span><br><span class="line">edges[<span class="string">&#x27;sources&#x27;</span>] = [lis(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line">edges[<span class="string">&#x27;targets&#x27;</span>] = [lis(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line">edges[<span class="string">&#x27;weights&#x27;</span>] = [<span class="number">1</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line"></span><br><span class="line">G = nx.from_pandas_edgelist(edges,source=<span class="string">&#x27;sources&#x27;</span>,target=<span class="string">&#x27;targets&#x27;</span>,edge_attr=<span class="string">&#x27;weights&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;G:&quot;</span>,G)</span><br><span class="line"><span class="built_in">print</span>(nx.__version__)</span><br><span class="line"><span class="built_in">print</span>(nx.adjacency_matrix(G))</span><br><span class="line"><span class="comment">#åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;degree:&quot;</span>,nx.degree(G))</span><br><span class="line"><span class="comment"># è¿é€šåˆ†é‡</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;connected_components&quot;</span>,<span class="built_in">list</span>(nx.connected_components(G)))</span><br><span class="line"><span class="comment">#å›¾ç›´å¾„</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;diameter:&quot;</span>,nx.diameter(G))</span><br><span class="line"><span class="comment"># åº¦ä¸­å¿ƒæ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;degree_centrality:&quot;</span>,nx.degree_centrality(G))</span><br><span class="line"><span class="comment">#ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;eigenvector:&quot;</span>,nx.eigenvector_centrality(G))</span><br><span class="line"><span class="comment"># betweenness ä¸­ä»‹ä¸­å¿ƒæ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;betweenness:&quot;</span>,nx.betweenness_centrality(G))</span><br><span class="line"><span class="comment"># closeness è¿æ¥ä¸­å¿ƒæ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;closenesss:&quot;</span>,nx.closeness_centrality(G))</span><br><span class="line"><span class="comment">#pagerank</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pagerank:&quot;</span>,nx.pagerank(G))</span><br><span class="line"><span class="comment">#hits</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hits:&quot;</span>,nx.hits(G))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.</span><br><span class="line">  print(nx.adjacency_matrix(G))</span><br><span class="line">G: Graph with 6 nodes and 8 edges</span><br><span class="line">2.8.4</span><br><span class="line">  (0, 0)	1</span><br><span class="line">  (0, 2)	1</span><br><span class="line">  (0, 3)	1</span><br><span class="line">  (0, 4)	1</span><br><span class="line">  (1, 1)	1</span><br><span class="line">  (1, 4)	1</span><br><span class="line">  (1, 5)	1</span><br><span class="line">  (2, 0)	1</span><br><span class="line">  (2, 3)	1</span><br><span class="line">  (3, 0)	1</span><br><span class="line">  (3, 2)	1</span><br><span class="line">  (4, 0)	1</span><br><span class="line">  (4, 1)	1</span><br><span class="line">  (5, 1)	1</span><br><span class="line">degree: [(3, 5), (1, 4), (4, 2), (2, 2), (5, 2), (6, 1)]</span><br><span class="line">connected_components [&#123;1, 2, 3, 4, 5, 6&#125;]</span><br><span class="line">diameter: 4</span><br><span class="line">degree_centrality: &#123;3: 1.0, 1: 0.8, 4: 0.4, 2: 0.4, 5: 0.4, 6: 0.2&#125;</span><br><span class="line">eigenvector: &#123;3: 0.6845438993664699, 1: 0.2664667519552274, 4: 0.4038050904760662, 2: 0.4038050904760662, 5: 0.3528502881437044, 6: 0.09886704157967073&#125;</span><br><span class="line">betweenness: &#123;3: 0.6000000000000001, 1: 0.4, 4: 0.0, 2: 0.0, 5: 0.6000000000000001, 6: 0.0&#125;</span><br><span class="line">closenesss: &#123;3: 0.625, 1: 0.5, 4: 0.45454545454545453, 2: 0.45454545454545453, 5: 0.625, 6: 0.35714285714285715&#125;</span><br><span class="line">pagerank: &#123;3: 0.26059842893288254, 1: 0.22624644367910318, 4: 0.1397855189975688, 2: 0.1397855189975688, 5: 0.1444805278346477, 6: 0.08910356155822868&#125;</span><br><span class="line">hits: (&#123;3: 0.3097026575730737, 1: 0.1205522404859372, 4: 0.18269069072963665, 2: 0.18269069072963665, 5: 0.1596357156065535, 6: 0.04472800487516233&#125;, &#123;3: 0.30970265757307375, 1: 0.1205522404859372, 4: 0.1826906907296366, 2: 0.18269069072963656, 5: 0.1596357156065534, 6: 0.04472800487516234&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>è§†é¢‘æ¥æºï¼š<a href="https://www.bilibili.com/video/BV1aB4y1Q7RL">https://www.bilibili.com/video/BV1aB4y1Q7RL</a></p>
]]></content>
      <categories>
        <category>å›¾ç¥ç»ç½‘ç»œ</category>
      </categories>
      <tags>
        <tag>å›¾</tag>
      </tags>
  </entry>
  <entry>
    <title>ç¬¬ä¸€æ¬¡æ­å»ºhexoåšå®¢</title>
    <url>/posts/83682157/</url>
    <content><![CDATA[<h2 id="hexo-deploy-åˆ°githubå¤±è´¥"><a href="#hexo-deploy-åˆ°githubå¤±è´¥" class="headerlink" title="hexo deploy åˆ°githubå¤±è´¥"></a>hexo deploy åˆ°githubå¤±è´¥</h2><p>ä½¿ç”¨deployä¹‹åè¦æ±‚è¾“å…¥è´¦æˆ·å’Œå¯†ç ï¼Œå¯†ç æ­£ç¡®ä½†æ˜¯æ˜¾ç¤ºéªŒè¯å¤±è´¥ã€‚</p>
<span id="more"></span>
<ul>
<li><p>å¤±è´¥åŸå› ï¼š</p>
<p>github 21å¹´å–æ¶ˆäº†å¯†ç éªŒè¯</p>
<p><img src="/posts/83682157/image-20221117162546351.png" alt></p>
</li>
</ul>
<ul>
<li><p>è§£å†³æ–¹å¼</p>
<p>åœ¨_config.ymlçš„deployä¸­ï¼Œrepoå¯¹åº”çš„å¡«å†™ä¸ºgithubä»“åº“çš„sshåœ°å€ï¼Œå¯ä»¥é¿å…è¿›è¡Œå¯†ç éªŒè¯ï¼ˆå‰æï¼šgité…ç½®å®Œæˆï¼Œgithubä¸Šæœ‰è®¾ç½®å…¬é’¥ï¼‰</p>
</li>
</ul>
<h2 id="å®Œæˆçš„é…ç½®"><a href="#å®Œæˆçš„é…ç½®" class="headerlink" title="å®Œæˆçš„é…ç½®"></a>å®Œæˆçš„é…ç½®</h2><ul>
<li><p>ä½¿ç”¨hexoä¸»é¢˜</p>
<p><a href="https://github.com/probberechts/hexo-theme-cactus">hexo-theme-cactus</a></p>
<ul>
<li><a href="https://github.com/theme-next/hexo-theme-next">theme-next/hexo-theme-next: Elegant and powerful theme for Hexo. (github.com)</a></li>
</ul>
</li>
<li><p>ä¸»é¢˜é…ç½® tags å’Œ categories</p>
</li>
<li><p>é…ç½®baidu_analytics</p>
</li>
<li><p>comment</p>
<ul>
<li>ä½¿ç”¨utterancesè®¾ç½®comment</li>
<li>æ¥å¿…åŠ›</li>
</ul>
</li>
<li><p>ä¸è’œå­ç»Ÿè®¡</p>
</li>
<li><p>ä½¿ç”¨ä¸»é¢˜çš„search</p>
<ul>
<li>ä¸æˆåŠŸ-&gt;è§£å†³ï¼šå‘ç°æ˜¯npm installçš„æ—¶å€™æ²¡æœ‰åœ¨åšå®¢æ ¹ç›®å½•å¯¼è‡´çš„é—®é¢˜</li>
</ul>
</li>
<li><p>è§£å†³å›¾ç‰‡è·¯å¾„é—®é¢˜</p>
<ul>
<li><p>sources/imagesç›®å½•ä¸‹å­˜å¼•å›¾ç‰‡</p>
</li>
<li><p>setupé‚£ç¯‡postä½¿ç”¨post_asset_folder: trueçš„æ–¹å¼ï¼ˆéœ€è¦å®‰è£…hexoæ’ä»¶ï¼‰ï¼Œå°†èµ„æºæ”¾åœ¨å¯¹åº”ç›®å½•ä¸‹</p>
<ul>
<li><p>æœ¬åœ°æˆåŠŸä½†æ˜¯æœåŠ¡å™¨æ˜¾ç¤ºæ— æ•ˆï¼Œé‡æ–°å®‰è£…æ’ä»¶æˆåŠŸï¼š</p>
<p><code>npm install https://github.com/7ym0n/hexo-asset-image --save</code></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>hexo new postå¤±è´¥</p>
<ul>
<li>ä½¿ç”¨ hexo new â€˜[post]â€™ â€œpostnameâ€</li>
</ul>
</li>
<li><p>æ•°å­¦å…¬å¼æ¸²æŸ“</p>
<ul>
<li><a href="https://blog.csdn.net/qq_38496329/article/details/104065659">https://blog.csdn.net/qq_38496329/article/details/104065659</a></li>
<li>æ³¨æ„åœ¨æ–‡ç« ä¸­front éƒ¨åˆ†è®¾ç½®mathjax: true</li>
</ul>
</li>
</ul>
<h3 id="éŸ³ä¹"><a href="#éŸ³ä¹" class="headerlink" title="éŸ³ä¹"></a>éŸ³ä¹</h3><ul>
<li><strong>è·å–ç½‘æ˜“äº‘å¤–é“¾çš„iframeä»£ç </strong></li>
</ul>
<p>æ‰“å¼€ç½‘æ˜“äº‘<a href="https://music.163.com/">å®˜ç½‘</a>ï¼Œé€‰æ‹©å–œæ¬¢çš„æ­Œå•æˆ–è€…æ­Œæ›²ï¼Œå¯ä»¥è‡ªå·±åˆ›å»ºæ­Œå•ã€‚</p>
<p>é™åˆ¶ï¼šæœ‰äº›æ­Œæ›²æœ‰ç‰ˆæƒä¿æŠ¤ï¼Œæ— æ³•ç”Ÿæˆå¤–é“¾</p>
<p><img src="\ç¬¬ä¸€æ¬¡æ­å»ºhexoåšå®¢\image-20221125133318434.png" alt="image-20221125133318434" style="zoom:50%;"></p>
<p><img src="\ç¬¬ä¸€æ¬¡æ­å»ºhexoåšå®¢\image-20221125133225148.png" alt="image-20221125133225148" style="zoom: 50%;"></p>
<p>[åšå®¢æ ¹ç›®å½•]\themes\next\layout_macro\sidebar.swigï¼Œåœ¨classä¸ºsiderbar-innerçš„divå†…æ·»åŠ iframe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% macro render(display_toc) %&#125;</span><br><span class="line">  &lt;div class=&quot;toggle sidebar-toggle&quot;&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-first&quot;&gt;&lt;/span&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-middle&quot;&gt;&lt;/span&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-last&quot;&gt;&lt;/span&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">  &lt;aside class=&quot;sidebar&quot;&gt;</span><br><span class="line">    &lt;div class=&quot;sidebar-inner&quot;&gt;</span><br></pre></td></tr></table></figure>
<h3 id="å›¾æ ‡"><a href="#å›¾æ ‡" class="headerlink" title="å›¾æ ‡"></a>å›¾æ ‡</h3><p>ã€nextä¸»é¢˜ä¸‹ã€‘</p>
<ul>
<li>å…è´¹å›¾æ ‡ä¸‹è½½ç½‘ç«™ï¼š</li>
</ul>
<p><a href="https://icons8.com/">https://icons8.com/</a></p>
<p><a href="https://findicons.com/icon/558960/cursor">Cursor icon PNG, ICO or ICNS | Free vector icons (findicons.com)</a></p>
<ul>
<li>ç«™ç‚¹å›¾æ ‡</li>
</ul>
<p>nextä¸»é¢˜é»˜è®¤æ˜¯é»‘è‰²çš„N</p>
<p>ä¿®æ”¹ï¼š nextä¸»é¢˜çš„é…ç½®æ–‡ä»¶ä¸­æœ‰ä¸€é¡¹é…ç½® faviconï¼Œå°†é…ç½®ä¸‹çš„å›¾ç‰‡ç›®å½•æ›´æ”¹ä¸ºæƒ³æ¢çš„å›¾ç‰‡å³å¯</p>
<ul>
<li><p>é¼ æ ‡çƒŸèŠ±ç‰¹æ•ˆ</p>
<p><a href="https://siriusq.top/Nextå‡çº§-Macè¿ç§».html#é¼ æ ‡ç‚¹å‡»ç‰¹æ•ˆ">Next å‡çº§ + Mac è¿ç§» | Sirius (siriusq.top)</a></p>
</li>
</ul>
<p>â€‹                æ³¨æ„å°†ä¸»é¢˜é…ç½®æ–‡ä»¶ä¸­å°†body-end.swigå¯¹åº”çš„éƒ¨åˆ†ç§»é™¤æ³¨é‡Š</p>
<ul>
<li><p>é¼ æ ‡æ ·å¼ä¿®æ”¹</p>
<p>hexo\source_data\styles.stylä¸­æ·»åŠ </p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// é¼ æ ‡æ ·å¼</span><br><span class="line">  * &#123;</span><br><span class="line">      <span class="attribute">cursor</span>: <span class="built_in">url</span>(<span class="string">&quot;image url&quot;</span>),auto<span class="meta">!important</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-pseudo">:active</span> &#123;</span><br><span class="line">      <span class="attribute">cursor</span>: <span class="built_in">url</span>(<span class="string">&quot;image url&quot;</span>),auto<span class="meta">!important</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ä¸»é¢˜é…ç½®æ–‡ä»¶ä¸­custom_file_path: style: source/_data/styles.stylç§»é™¤æ³¨é‡Š</p>
</li>
</ul>
]]></content>
      <categories>
        <category>hexoé…ç½®</category>
      </categories>
  </entry>
  <entry>
    <title>ã€pytorch-learningã€‘(äºŒ) æ¨¡å‹æ­å»º-è®­ç»ƒ-æµ‹è¯•</title>
    <url>/posts/13fc6476/</url>
    <content><![CDATA[<h1 id="æ¨¡å‹æ­å»º"><a href="#æ¨¡å‹æ­å»º" class="headerlink" title="æ¨¡å‹æ­å»º"></a>æ¨¡å‹æ­å»º</h1><h2 id="è‡ªå®šä¹‰æ¨¡å‹"><a href="#è‡ªå®šä¹‰æ¨¡å‹" class="headerlink" title="è‡ªå®šä¹‰æ¨¡å‹"></a>è‡ªå®šä¹‰æ¨¡å‹</h2><p>åŸºæœ¬éª¨æ¶ä¸º <code>torch.nn.Module</code></p>
<span id="more"></span>
<p>å®ç°ä¸€ä¸ªç»§æ‰¿è‡ªModuleçš„ç±»ï¼Œè¯¥ç±»ä¸­ä¸»è¦åŒ…å«initå’Œforwardæ–¹æ³•ã€‚</p>
<p>é€šè¿‡forwardæ–¹æ³•å®Œæˆç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚</p>
<p>è¯¦ç»†è®²è§£è§æˆ‘è®°çš„Bç«™å°åœŸå †çš„ç¬”è®°ï¼š<a href="https://github.com/Xandra298/Pytorchlearning/blob/master/å°åœŸå †/1.2pytorchä½¿ç”¨_ç¥ç»ç½‘ç»œæ­å»º.ipynb">ç¥ç»ç½‘ç»œæ­å»º</a></p>
<p>ä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;dataset/&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download= <span class="literal">True</span>)</span><br><span class="line">dataloader  = DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model_conv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model_conv, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">3</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span>  x</span><br><span class="line"></span><br><span class="line">model = Model_conv()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,target = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>torch.nn.Sequential</code>ä½¿ç”¨ç¤ºä¾‹</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Linear, Sequential</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">model = Model()</span><br></pre></td></tr></table></figure>
<h2 id="è¿ç§»å­¦ä¹ "><a href="#è¿ç§»å­¦ä¹ " class="headerlink" title="è¿ç§»å­¦ä¹ "></a>è¿ç§»å­¦ä¹ </h2><p>ä¿®æ”¹å·²æœ‰ç½‘ç»œæ¨¡å‹ç”¨äºè‡ªå·±çš„ä»»åŠ¡</p>
<h3 id="å®ä¾‹ä¸€ï¼šå°†VGG16ç”¨äºæ•°æ®é›†CIFAR10çš„åˆ†ç±»"><a href="#å®ä¾‹ä¸€ï¼šå°†VGG16ç”¨äºæ•°æ®é›†CIFAR10çš„åˆ†ç±»" class="headerlink" title="å®ä¾‹ä¸€ï¼šå°†VGG16ç”¨äºæ•°æ®é›†CIFAR10çš„åˆ†ç±»"></a>å®ä¾‹ä¸€ï¼šå°†VGG16ç”¨äºæ•°æ®é›†CIFAR10çš„åˆ†ç±»</h3><p>VGG16<a href="https://pytorch.org/vision/0.9/models.html">æ¨¡å‹</a> çš„datasetæ˜¯<a href="https://pytorch.org/vision/0.8/datasets.html#imagenet">ImagNet</a></p>
<p>é€šè¿‡torchvision.models.vgg16(pretained=True)(pretained=Trueä¼šå°†å…¶æƒé‡ä¹Ÿä¸‹è½½ä¸‹æ¥ï¼‰å°†æ¨¡å‹ä¸‹è½½ä¸‹æ¥ä¹‹åï¼Œé»˜è®¤ä¿å­˜è·¯å¾„æ˜¯<code>C:\Users\[usename].cache\torch\hub\checkpoints</code></p>
<p>VGG16ç”¨äº1000åˆ†ç±»ï¼ˆæœ€åå…¨è¿æ¥å±‚çš„è¾“å‡ºæ˜¯1000ï¼‰ï¼Œä½¿ç”¨æ•°æ®é›†CIFAR10æ˜¯éœ€è¦10åˆ†ç±»çš„ã€‚å› æ­¤éš¾ç‚¹åœ¨äºå¦‚ä½•ä½¿ç”¨è¯¥VGGæ¨¡å‹è¿›è¡Œè¿ç§»ã€‚ ä¸‹æ–‡ä»£ç å±•ç°äº†ä¸¤ç§ä¸»è¦æ–¹å¼</p>
<h4 id="æ–¹å¼ä¸€"><a href="#æ–¹å¼ä¸€" class="headerlink" title="æ–¹å¼ä¸€"></a>æ–¹å¼ä¸€</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="comment"># vgg16_false = torchvision.models.vgg16(pretrained=False)</span></span><br><span class="line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">##traindataæ˜¯10åˆ†ç±»ï¼Œè€Œvgg16æ˜¯1000åˆ†ç±»</span></span><br><span class="line"></span><br><span class="line">vgg16_true.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16_true)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>VGGæ¨¡å‹æ·»åŠ äº†ä¸€å±‚ä¹‹åçš„ç»“æ„</p>
<p>å¤šäº†ä¸€å±‚æ·»åŠ çš„ï¼š</p>
<p><code>(add_linear): Linear(in_features=1000, out_features=10, bias=True)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU(inplace=True)</span><br><span class="line">    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU(inplace=True)</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (6): ReLU(inplace=True)</span><br><span class="line">    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (8): ReLU(inplace=True)</span><br><span class="line">    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (11): ReLU(inplace=True)</span><br><span class="line">    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (13): ReLU(inplace=True)</span><br><span class="line">    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (15): ReLU(inplace=True)</span><br><span class="line">    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (18): ReLU(inplace=True)</span><br><span class="line">    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (20): ReLU(inplace=True)</span><br><span class="line">    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (22): ReLU(inplace=True)</span><br><span class="line">    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (25): ReLU(inplace=True)</span><br><span class="line">    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (27): ReLU(inplace=True)</span><br><span class="line">    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (29): ReLU(inplace=True)</span><br><span class="line">    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=4096, bias=True)</span><br><span class="line">    (1): ReLU(inplace=True)</span><br><span class="line">    (2): Dropout(p=0.5, inplace=False)</span><br><span class="line">    (3): Linear(in_features=4096, out_features=4096, bias=True)</span><br><span class="line">    (4): ReLU(inplace=True)</span><br><span class="line">    (5): Dropout(p=0.5, inplace=False)</span><br><span class="line">    (6): Linear(in_features=4096, out_features=1000, bias=True)</span><br><span class="line">  )</span><br><span class="line">  (add_linear): Linear(in_features=1000, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="æ–¹å¼äºŒ"><a href="#æ–¹å¼äºŒ" class="headerlink" title="æ–¹å¼äºŒ"></a>æ–¹å¼äºŒ</h4><p>æƒ³è¦åŠ åˆ°å…¶ä¸­çš„classifieré‡Œé¢</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vgg16_true.classifier.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h3 id="å®ä¾‹äºŒï¼šresnet18"><a href="#å®ä¾‹äºŒï¼šresnet18" class="headerlink" title="å®ä¾‹äºŒï¼šresnet18"></a>å®ä¾‹äºŒï¼šresnet18</h3><p>è·å–ç½‘ç»œä¸­çš„æ¨¡å‹ï¼Œé€šè¿‡Sequentialå®Œæˆæ–°æ¨¡å‹çš„ç»„å»º</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18 <span class="comment">##ä»ç½‘ç»œè·å–æ¨¡å‹</span></span><br><span class="line">trained_model = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">                <span class="comment">#*ç”¨äºè¿­ä»£å–å‡ºlistä¸­çš„å†…å®¹</span></span><br><span class="line">model = nn.Sequential(*<span class="built_in">list</span>(trained_model.children())[:-<span class="number">1</span>],<span class="comment">#[b,512,1,1]</span></span><br><span class="line">                          nn.Flatten(),<span class="comment">#[b,512,1,1]=&gt;[b,512]</span></span><br><span class="line">                          nn.Linear(<span class="number">512</span>,<span class="number">5</span>)</span><br><span class="line">                          ).to(device)</span><br></pre></td></tr></table></figure>
<h1 id="æ¨¡å‹ä¿å­˜å’Œè¯»å–"><a href="#æ¨¡å‹ä¿å­˜å’Œè¯»å–" class="headerlink" title="æ¨¡å‹ä¿å­˜å’Œè¯»å–"></a>æ¨¡å‹ä¿å­˜å’Œè¯»å–</h1><h2 id="æ–¹å¼ä¸€-1"><a href="#æ–¹å¼ä¸€-1" class="headerlink" title="æ–¹å¼ä¸€"></a>æ–¹å¼ä¸€</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ¨¡å‹</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ##ä¿å­˜æ–¹å¼1 æ¨¡å‹ç»“æ„+æ¨¡å‹å‚æ•°</span></span><br><span class="line"><span class="comment"># ### å‚æ•°ï¼šæ¨¡å‹ï¼Œè·¯å¾„</span></span><br><span class="line"></span><br><span class="line">torch.save(vgg16,<span class="string">&quot;vgg16_modelsave_1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">###è¯»å–æ–¹å¼1&gt;&gt;ä¿å­˜æ–¹å¼1</span></span><br><span class="line"><span class="comment">##å‚æ•°ï¼šè·¯å¾„</span></span><br><span class="line">model = torch.load(<span class="string">&quot;vgg16_modelsave_1.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>
<h2 id="æ–¹å¼äºŒï¼ˆæ¨èï¼‰"><a href="#æ–¹å¼äºŒï¼ˆæ¨èï¼‰" class="headerlink" title="æ–¹å¼äºŒï¼ˆæ¨èï¼‰"></a>æ–¹å¼äºŒï¼ˆæ¨èï¼‰</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ¨¡å‹</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#ä¿å­˜æ–¹å¼2 æ¨¡å‹å‚æ•°ï¼ˆå®˜æ–¹æ¨èï¼‰</span></span><br><span class="line"><span class="comment">##å‚æ•°ï¼šæ¨¡å‹.state_dict(),è·¯å¾„</span></span><br><span class="line"><span class="comment">##527M</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg16_modelsave_2.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##è¯»å–æ–¹å¼2&gt;&gt;ä¿å­˜æ–¹å¼2</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg16_modelsave_2.pth&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br></pre></td></tr></table></figure>
<h2 id="æ–¹å¼ä¸€çš„æŠ¥é”™å®ä¾‹"><a href="#æ–¹å¼ä¸€çš„æŠ¥é”™å®ä¾‹" class="headerlink" title="æ–¹å¼ä¸€çš„æŠ¥é”™å®ä¾‹"></a>æ–¹å¼ä¸€çš„æŠ¥é”™å®ä¾‹</h2><p>æŠ¥é”™è¿‡ç¨‹ï¼š</p>
<ol>
<li><p>a.pyä¸­åˆ›å»ºæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨toch.save(model,â€model pathâ€)</p>
</li>
<li><p>b.pyä¸­åŠ è½½è¯¥æ¨¡å‹ï¼šmodel = torch.load(â€œmodel pathâ€)</p>
</li>
</ol>
<p>è§£å†³æ–¹æ¡ˆï¼šè¦è®©è¯¥æ–‡ä»¶èƒ½è®¿é—®åˆ°è¯¥æ¨¡å‹çš„å®šä¹‰ã€‚</p>
<ul>
<li><p>åœ¨ç›´æ¥åŠ è½½å‰é‡æ–°å®šä¹‰ä¸€ä¸‹è¯¥æ¨¡å‹</p>
</li>
<li><p>æˆ–è€… <code>from model_save import *</code> å³åœ¨å¤´æ–‡ä»¶importä¸€ä¸‹è¯¥æ¨¡å‹å®šä¹‰æ–‡ä»¶</p>
</li>
</ul>
<h1 id="æ¨¡å‹è®­ç»ƒ"><a href="#æ¨¡å‹è®­ç»ƒ" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h1><h2 id="éšæœºæ¢¯åº¦ä¸‹é™"><a href="#éšæœºæ¢¯åº¦ä¸‹é™" class="headerlink" title="éšæœºæ¢¯åº¦ä¸‹é™"></a>éšæœºæ¢¯åº¦ä¸‹é™</h2><p><a href="https://github.com/Xandra298/Pytorchlearning/blob/master/4.éšæœºæ¢¯åº¦ä¸‹é™.ipynb">è¯¦ç»†ç†è®º</a>)</p>
<h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>é€šè¿‡æŸå¤±å‡½æ•°è®¡ç®—ç»è¿‡è®­ç»ƒçš„æ¨¡å‹å…¶é¢„æµ‹ç»“æœä¸çœŸå®å€¼çš„è¯¯å·®ï¼Œlossè¶Šå°è¯´æ˜äºŒè€…è¶Šæ¥è¿‘ã€‚</p>
<p>é€šè¿‡æ¢¯åº¦ä¸‹é™æœç´¢æå€¼ç‚¹ã€‚è®¡ç®—lossï¼Œé€šè¿‡loss.backward()åå‘ä¼ æ’­è¿›è¡Œè‡ªåŠ¨æ±‚å¯¼è·å¾—æ¢¯åº¦ã€‚</p>
<p>å¯¹äºæ¨¡å‹è€Œè¨€ï¼Œå˜åŒ–çš„æ˜¯å„ä¸ªæƒé‡å‚æ•°wã€‚</p>
<p><a href="https://pytorch.org/docs/1.8.1/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">CrossEntropyLoss</a></p>
<p>ä½¿ç”¨å®ä¾‹</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line">x = torch.tensor([<span class="number">0.1</span>,<span class="number">0.8</span>,<span class="number">0.1</span>])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">x = x.reshape(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">loss_cross = nn.CrossEntropyLoss()</span><br><span class="line">result_cross = loss_cross(x,y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>
<h3 id="ä¼˜åŒ–å™¨"><a href="#ä¼˜åŒ–å™¨" class="headerlink" title="ä¼˜åŒ–å™¨"></a>ä¼˜åŒ–å™¨</h3><p>å†³å®šæ¢¯åº¦ä¸‹é™çš„æ–¹å¼ã€‚</p>
<p>ä½¿ç”¨ä¸»è¦å…³è”å››è¡Œä»£ç ï¼š</p>
<ul>
<li><code>optim = torch.optim.SGD(model.parameters(),lr=0.01)</code>  ï¼ˆSGDä¸ºä¸€ç§ä¼˜åŒ–å™¨ï¼‰</li>
</ul>
<p>epoch å†…</p>
<ul>
<li><code>optim.zero_grad()</code> ##å°†ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é›¶ï¼Œæ¯ä¸€æ¬¡å¾ªç¯æ³¨æ„æ¸…é›¶</li>
<li><code>result_loss.backward()</code></li>
<li><code>optim.step()</code></li>
</ul>
<h2 id="è®­ç»ƒæ¨¡å‹"><a href="#è®­ç»ƒæ¨¡å‹" class="headerlink" title="è®­ç»ƒæ¨¡å‹"></a>è®­ç»ƒæ¨¡å‹</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;----epoch &#123;&#125; starting----&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment">##è®­ç»ƒæ­¥éª¤å¼€å§‹</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        outputs = model(imgs)</span><br><span class="line">        loss = loss_fn(outputs,targets)</span><br><span class="line"></span><br><span class="line">        <span class="comment">##ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&quot;batch &#123;&#125;---loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step,loss.item()))</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="æ¨¡å‹æµ‹è¯•è¯„ä¼°"><a href="#æ¨¡å‹æµ‹è¯•è¯„ä¼°" class="headerlink" title="æ¨¡å‹æµ‹è¯•è¯„ä¼°"></a>æ¨¡å‹æµ‹è¯•è¯„ä¼°</h1><p>å°†æµ‹è¯•é›†ä¼ å…¥è®­ç»ƒå¥½çš„æ¨¡å‹å¾—åˆ°é¢„æµ‹è¾“å‡ºã€‚</p>
<p>å°†é¢„æµ‹è¾“å‡ºå’Œæµ‹è¯•é›†çš„labelè¿›è¡Œæ¯”è¾ƒä»¥è¯„ä¼°è¯¥æ¨¡å‹ã€‚</p>
<p>æœ‰æ ‡ç­¾çš„è¯„ä¼°æŒ‡æ ‡æœ‰ï¼š</p>
<ul>
<li>å‡†ç¡®ç‡</li>
<li>å¬å›ç‡</li>
<li>ç²¾ç¡®ç‡</li>
<li>F1-score</li>
<li>â€¦</li>
</ul>
<p>å¦å¤–ï¼Œå¦‚ROCæ›²çº¿ï¼ŒAUCï¼ŒAPç­‰ä¹Ÿæ˜¯å¸¸è§çš„è¯„ä¼°</p>
<h1 id="è‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜"><a href="#è‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜" class="headerlink" title="è‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜"></a>è‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜</h1><h2 id="æ•°æ®é¢„å¤„ç†ä¸åŠ è½½"><a href="#æ•°æ®é¢„å¤„ç†ä¸åŠ è½½" class="headerlink" title="æ•°æ®é¢„å¤„ç†ä¸åŠ è½½"></a>æ•°æ®é¢„å¤„ç†ä¸åŠ è½½</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os,glob</span><br><span class="line"><span class="keyword">import</span> random,csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pokemen</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root,resize,mode</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param root: æ•°æ®é›†æ ¹ç›®å½•ï¼›</span></span><br><span class="line"><span class="string">                    è¿™æ¬¡çš„å­˜å‚¨å½¢å¼æ˜¯æ ¹ç›®å½•ä¸‹æœ‰æ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹ä¸‹æ˜¯æ•°æ®é›†å›¾ç‰‡ï¼Œæ–‡ä»¶å¤¹åç§°æ˜¯å¯¹åº”çš„ç±»åˆ«</span></span><br><span class="line"><span class="string">        :param resize:</span></span><br><span class="line"><span class="string">        :param mode: train\test\val</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Pokemen, self).__init__()</span><br><span class="line">        self.root = root</span><br><span class="line">        self.resize = resize</span><br><span class="line"></span><br><span class="line">        self.name2label = &#123;&#125;<span class="comment"># å­˜å‚¨nameå¯¹åº”ç¼–ç çš„å­—å…¸</span></span><br><span class="line">        <span class="comment">#éå†æ ¹ç›®å½•ä¸‹æ–‡ä»¶å¤¹åç§°</span></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(os.path.join(root))):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root,name)):</span><br><span class="line">                <span class="comment"># not a dir</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># æŒ‰ç…§å…ˆåé¡ºåºè·å¾—ç¼–ç </span></span><br><span class="line">            self.name2label[name] = <span class="built_in">len</span>(self.name2label.keys())</span><br><span class="line">        <span class="built_in">print</span>(self.name2label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ä»csvæ–‡ä»¶ä¸­è¯»å– image_path-labelï¼›</span></span><br><span class="line">        <span class="comment"># load_csvæ–¹æ³•å®ç°å°†æ•°æ®é›†æ¡ç›®ï¼šimage_path-label æ•´ç†åˆ°csvæ–‡ä»¶ä¸­</span></span><br><span class="line">        self.images,self.labels = self.load_csv(<span class="string">&quot;image.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#åˆ’åˆ†æ•°æ®é›†</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>: <span class="comment">#60%</span></span><br><span class="line">            self.images = self.images[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;val&#x27;</span>: <span class="comment">#20%</span></span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.images)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.labels)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.images)):]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.labels)):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_csv</span>(<span class="params">self,filename</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        å°†æ•°æ®é›†çš„image_path-labelå­˜å‚¨åˆ°csvæ–‡ä»¶ä¸­ï¼Œå¹¶ä»csvæ–‡ä»¶åŠ è½½</span></span><br><span class="line"><span class="string">        :param filename: å­˜å‚¨csvçš„æ–‡ä»¶è·¯å¾„</span></span><br><span class="line"><span class="string">        :return: images,labels==&gt; images_path,labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        savepath = os.path.join(self.root,filename)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">            images = []</span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> self.name2label.keys():</span><br><span class="line">                <span class="comment">#è·å–å¯¹åº”æ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡æ–‡ä»¶,å­˜å‚¨åˆ°list(images)å†…</span></span><br><span class="line">                images += glob.glob(os.path.join(self.root,name,<span class="string">&#x27;*.png&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.gif&#x27;</span>))</span><br><span class="line">            <span class="comment">#print(images)</span></span><br><span class="line">            <span class="comment">#&#x27;./pokeman/squirtle\\00000073.png&#x27;</span></span><br><span class="line">            random.shuffle(images) <span class="comment">#shuffle</span></span><br><span class="line">            <span class="comment">#å†™å…¥csv</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(savepath,mode=<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                writer = csv.writer(f)</span><br><span class="line">                <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">                    name = img.split(os.sep)[-<span class="number">2</span>]</span><br><span class="line">                    label = self.name2label[name]</span><br><span class="line">                    writer.writerow([img,label])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;written into csv file:&#x27;</span>,savepath)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ä»csvæ–‡ä»¶è¯»å–</span></span><br><span class="line">        images,labels = [],[]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(savepath) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">                img,label = row</span><br><span class="line">                label = <span class="built_in">int</span>(label)</span><br><span class="line">                images.append(img)</span><br><span class="line">                labels.append(label)</span><br><span class="line">        <span class="keyword">assert</span>  <span class="built_in">len</span>(images) == <span class="built_in">len</span>(labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span>  images,labels</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :return: æ•°æ®é›†é•¿åº¦</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :param item: range in [0,len(images)]</span></span><br><span class="line"><span class="string">        :return: self.images,self.labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        img,label = self.images[item],self.labels[item]</span><br><span class="line">        </span><br><span class="line">        tf = transforms.Compose(</span><br><span class="line">            [<span class="keyword">lambda</span> x:Image.<span class="built_in">open</span>(x).convert(<span class="string">&#x27;RGB&#x27;</span>), <span class="comment"># open image and convert to RGB</span></span><br><span class="line">             transforms.Resize((<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>),<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>))),</span><br><span class="line">             transforms.RandomRotation(<span class="number">15</span>),</span><br><span class="line">             transforms.CenterCrop(self.resize),</span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>]),<span class="comment">#values computed from ImageNetï¼Œwe could use it in other dataset   </span></span><br><span class="line">             </span><br><span class="line">             ]  </span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        img = tf(img)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line">db = Pokemon(<span class="string">&#x27;./pokeman&#x27;</span>, <span class="number">224</span>, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(x.shape,y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;.ipynb_checkpoints&#39;: 0, &#39;bulbasaur&#39;: 1, &#39;charmander&#39;: 2, &#39;mewtwo&#39;: 3, &#39;pikachu&#39;: 4, &#39;squirtle&#39;: 5&#125;
written into csv file:  ./pokeman\image.csv
torch.Size([3, 224, 224]) torch.Size([])
</code></pre><h3 id="æ•°æ®é›†åŠ è½½ï¼šDataLoader"><a href="#æ•°æ®é›†åŠ è½½ï¼šDataLoader" class="headerlink" title="æ•°æ®é›†åŠ è½½ï¼šDataLoader"></a>æ•°æ®é›†åŠ è½½ï¼šDataLoader</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  visdom</span><br><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">db = Pokemon(<span class="string">&#x27;./pokeman&#x27;</span>, <span class="number">224</span>, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(x.shape,y.shape)</span><br><span class="line">loader = DataLoader(db,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="ç½‘ç»œåˆ›å»º"><a href="#ç½‘ç»œåˆ›å»º" class="headerlink" title="ç½‘ç»œåˆ›å»º"></a>ç½‘ç»œåˆ›å»º</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Resnet.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span>  torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResBlk</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    resnet block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,ch_in,ch_out,stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param ch_in:[b,ch,h,w]</span></span><br><span class="line"><span class="string">        :param ch_out:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ResBlk, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=<span class="number">3</span>,stride=stride,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(ch_out)</span><br><span class="line">        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(ch_out)</span><br><span class="line"></span><br><span class="line">        self.extra = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ch_out!=ch_in:</span><br><span class="line">            self.extra = nn.Sequential(</span><br><span class="line">                nn.Conv2d(ch_in,ch_out,kernel_size=<span class="number">1</span>,stride=stride),</span><br><span class="line">                nn.BatchNorm2d(ch_out)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out =  F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.bn2(self.conv2(out))</span><br><span class="line"></span><br><span class="line">        <span class="comment">##short cut</span></span><br><span class="line">        <span class="comment">#extra module:[b,ch_in,h,w]=&gt;[b,ch_out,h,w]</span></span><br><span class="line">        <span class="comment">#element-wise add</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        out = self.extra(x) +out</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet18</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_class</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet18, self).__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">3</span>,padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#followed 4 blocks</span></span><br><span class="line">        <span class="comment">#[b,16,h,w]=&gt;[b,32,h,w]</span></span><br><span class="line">        self.blk1 =ResBlk(<span class="number">16</span>,<span class="number">32</span>,stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># [b,32,h,w]=&gt;[b,64,h,w]</span></span><br><span class="line">        self.blk2 = ResBlk(<span class="number">32</span>,<span class="number">64</span>,stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment">#[b,64,h,w]=&gt;[b,128,h,w]</span></span><br><span class="line">        self.blk3 = ResBlk(<span class="number">64</span>,<span class="number">128</span>,stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># [b,128,h,w]=&gt;[b,256,h,w]</span></span><br><span class="line">        self.blk4 = ResBlk(<span class="number">128</span>,<span class="number">256</span>,stride=<span class="number">2</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.outlayer = nn.Linear(<span class="number">256</span>*<span class="number">3</span>*<span class="number">3</span>,num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="comment">#[b,64,h,w]=&gt;[b,1024,h,w]</span></span><br><span class="line">        x = self.blk1(x)</span><br><span class="line">        x = self.blk2(x)</span><br><span class="line">        x = self.blk3(x)</span><br><span class="line">        x = self.blk4(x)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;after conv:&quot;</span>,x.shape)</span><br><span class="line">        <span class="comment"># x = F.adaptive_max_pool2d(x,[1,1])</span></span><br><span class="line">        <span class="comment"># print(&quot;after pool,&quot;,x.shape)</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.outlayer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    blk = ResBlk(<span class="number">64</span>,<span class="number">128</span>)</span><br><span class="line">    tmp = torch.rand(<span class="number">2</span>,<span class="number">64</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    out = blk(tmp)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;block&#x27;</span>,out.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    x  = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    model = ResNet18(<span class="number">5</span>)</span><br><span class="line">    out = model(x)</span><br><span class="line">    <span class="built_in">print</span>(out.shape)</span><br><span class="line"></span><br><span class="line">    p = <span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span>  p:p.numel(),model.parameters()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;parameters size:&#x27;</span>,p)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Train-and-test"><a href="#Train-and-test" class="headerlink" title="Train and test"></a>Train and test</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    train(train_db)</span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        val_acc = evaluate(val_db)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> val_loss <span class="keyword">is</span> the best:</span><br><span class="line">            save_ckpt()</span><br><span class="line">        <span class="keyword">if</span> out_of_patience():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">load_ckpt()<span class="comment"># checkpoint model</span></span><br><span class="line">test_acc = evaluate(test_db)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#train_scratch.py</span></span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim,nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pokeman <span class="keyword">import</span> Pokemon</span><br><span class="line"><span class="keyword">from</span> Resnet <span class="keyword">import</span> ResNet18</span><br><span class="line"></span><br><span class="line">batchsz = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1234</span>)<span class="comment">##éšæœºç§å­</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">val_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">test_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(train_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>)</span><br><span class="line">val_loader = DataLoader(val_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">test_loader = DataLoader(test_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model,loader</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">len</span>(loader.dataset)</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> loader:</span><br><span class="line">        x,y = x.to(device),y.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(x)</span><br><span class="line">            pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct += torch.eq(pred,y).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">    <span class="keyword">return</span> correct/total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    model = ResNet18(<span class="number">5</span>).to(device)</span><br><span class="line">    optimizer = optim.Adam(model.parameters(),lr=lr)</span><br><span class="line">    criteon = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    best_acc,best_epoch=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    global_step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> step,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># x:[b,3,224,224], y:[5]</span></span><br><span class="line">            img,label = img.to(device),label.to(device)</span><br><span class="line"></span><br><span class="line">            logits = model(img)</span><br><span class="line">            loss = criteon(logits,label)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">          </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            val_acc = evaluate(model,val_loader)</span><br><span class="line">            <span class="keyword">if</span> val_acc&gt;best_acc:</span><br><span class="line">                best_epoch = epoch</span><br><span class="line">                best_acc = val_acc</span><br><span class="line"></span><br><span class="line">                torch.save(model.state_dict(),<span class="string">&#x27;best.mdl&#x27;</span>)</span><br><span class="line">            viz.line([val_acc], [epoch], win=<span class="string">&#x27;val_acc&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;best acc:&#x27;</span>,best_acc,<span class="string">&#x27;best epoch&#x27;</span>,best_epoch)</span><br><span class="line"></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;best.mdl&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;loaded from checkpoint!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    test_acc = evaluate(model,test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;test acc&#x27;</span>,test_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>best acc: 0.8583690987124464 best epoch 5</p>
<p>test acc 0.8497854077253219</p>
<h1 id="optional-è¿ç§»å­¦ä¹ "><a href="#optional-è¿ç§»å­¦ä¹ " class="headerlink" title="optional: è¿ç§»å­¦ä¹ "></a>optional: è¿ç§»å­¦ä¹ </h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim,nn</span><br><span class="line"><span class="keyword">import</span>  visdom</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pokeman <span class="keyword">import</span> Pokemon</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18 <span class="comment">##ä»ç½‘ç»œè·å–æ¨¡å‹</span></span><br><span class="line"></span><br><span class="line">batchsz = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1234</span>)<span class="comment">##éšæœºç§å­</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">val_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">test_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(train_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>)</span><br><span class="line">val_loader = DataLoader(val_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">test_loader = DataLoader(test_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">viz = visdom.Visdom()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model,loader</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">len</span>(loader.dataset)</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> loader:</span><br><span class="line">        x,y = x.to(device),y.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(x)</span><br><span class="line">            pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct = torch.eq(pred,y).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">    <span class="keyword">return</span> correct/total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># model = ResNet18(5).to(device)</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------------------------</span></span><br><span class="line">    trained_model = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">                <span class="comment">#*ç”¨äºè¿­ä»£å–å‡ºlistä¸­çš„å†…å®¹</span></span><br><span class="line">    model = nn.Sequential(*<span class="built_in">list</span>(trained_model.children())[:-<span class="number">1</span>],<span class="comment">#[b,512,1,1]</span></span><br><span class="line">                          nn.Flatten(),<span class="comment">#[b,512,1,1]=&gt;[b,512]</span></span><br><span class="line">                          nn.Linear(<span class="number">512</span>,<span class="number">5</span>)</span><br><span class="line">                          ).to(device)</span><br><span class="line">    <span class="comment"># x = torch.rand(2,3,224,224)</span></span><br><span class="line">    <span class="comment"># print(model(x).shape)</span></span><br><span class="line">    <span class="comment">#---------------------------------------------------------------------------------------</span></span><br><span class="line">    optimizer = optim.Adam(model.parameters(),lr=lr)</span><br><span class="line">    criteon = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    best_acc,best_epoch=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    viz.line([<span class="number">0</span>],[-<span class="number">1</span>],win=<span class="string">&#x27;loss&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;loss&#x27;</span>))</span><br><span class="line">    viz.line([<span class="number">0</span>],[-<span class="number">1</span>],win=<span class="string">&#x27;val_acc&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;val_acc&#x27;</span>))</span><br><span class="line">    global_step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> step,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># x:[b,3,224,224], y:[5]</span></span><br><span class="line">            img,label = img.to(device),label.to(device)</span><br><span class="line"></span><br><span class="line">            logits = model(img)</span><br><span class="line">            loss = criteon(logits,label)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            viz.line([loss.item()], [global_step], win=<span class="string">&#x27;loss&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">            global_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            val_acc = evaluate(model,val_loader)</span><br><span class="line">            <span class="keyword">if</span> val_acc&gt;best_acc:</span><br><span class="line">                best_epoch = epoch</span><br><span class="line">                best_acc = val_acc</span><br><span class="line"></span><br><span class="line">                torch.save(model.state_dict(),<span class="string">&#x27;best.mdl&#x27;</span>)</span><br><span class="line">            viz.line([val_acc], [epochs], win=<span class="string">&#x27;val_acc&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;best acc:&#x27;</span>,best_acc,<span class="string">&#x27;best epoch&#x27;</span>,best_epoch)</span><br><span class="line"></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;best.mdl&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;loaded from checkpoint!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    test_acc = evaluate(model,test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;test acc&#x27;</span>,test_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>best acc: 0.8412017167381974 best epoch 8</p>
<p>test acc 0.8025751072961373</p>
]]></content>
      <categories>
        <category>æ·±åº¦å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>é‚»æ¥çŸ©é˜µè¡¨ç¤ºæˆPyGéœ€è¦çš„edge_indexå¹¶è¿›è¡Œå¸¦è¾¹æƒçš„ç½‘ç»œæ„å»º</title>
    <url>/posts/35a1541/</url>
    <content><![CDATA[<h1 id="é‚»æ¥çŸ©é˜µ-to-pygéœ€è¦çš„edge-indexæ ¼å¼"><a href="#é‚»æ¥çŸ©é˜µ-to-pygéœ€è¦çš„edge-indexæ ¼å¼" class="headerlink" title="é‚»æ¥çŸ©é˜µ to pygéœ€è¦çš„edge_indexæ ¼å¼"></a>é‚»æ¥çŸ©é˜µ to pygéœ€è¦çš„edge_indexæ ¼å¼</h1><span id="more"></span>
<h2 id="scipy"><a href="#scipy" class="headerlink" title="scipy"></a>scipy</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">A = torch.rand([<span class="number">10</span>,<span class="number">10</span>]) <span class="comment"># 10*10çš„é‚»æ¥çŸ©é˜µAï¼Œå¸¦æœ‰æƒå€¼ï¼Œè€Œé0/1</span></span><br><span class="line">A</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.8253, 0.2458, 0.9340, 0.4631, 0.5114, 0.3248, 0.8528, 0.6354, 0.2988,
         0.1087],
        [0.0190, 0.5693, 0.4843, 0.9588, 0.6011, 0.5755, 0.4621, 0.7694, 0.0637,
         0.9790],
        [0.6978, 0.9686, 0.9701, 0.2234, 0.5633, 0.9978, 0.9766, 0.3365, 0.3512,
         0.2396],
        [0.3582, 0.9965, 0.7739, 0.5641, 0.7275, 0.3078, 0.1826, 0.5449, 0.6566,
         0.1949],
        [0.8194, 0.7996, 0.9177, 0.3419, 0.5239, 0.7048, 0.4503, 0.0758, 0.2244,
         0.0659],
        [0.6131, 0.3546, 0.0789, 0.2735, 0.0781, 0.8000, 0.0587, 0.6644, 0.2678,
         0.6351],
        [0.7244, 0.0463, 0.9280, 0.6456, 0.6837, 0.0763, 0.0759, 0.0440, 0.1849,
         0.8942],
        [0.3589, 0.6925, 0.2334, 0.3476, 0.6695, 0.1048, 0.1470, 0.5548, 0.4736,
         0.6934],
        [0.0356, 0.8016, 0.6176, 0.2867, 0.1340, 0.7196, 0.0562, 0.5548, 0.7376,
         0.2841],
        [0.9301, 0.1725, 0.4012, 0.3893, 0.8366, 0.1587, 0.3342, 0.7945, 0.8123,
         0.8724]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">adj  = sp.coo_matrix(A) <span class="comment">#è½¬æ¢æˆcoo_matrixçŸ©é˜µ</span></span><br><span class="line">values = adj.data</span><br><span class="line">values,adj.row,adj.col</span><br></pre></td></tr></table></figure>
<pre><code>(array([0.825252  , 0.24581629, 0.9340454 , 0.4631123 , 0.51142365,
        0.32479858, 0.85282457, 0.63537604, 0.29877287, 0.10873711,
        0.01895636, 0.5693259 , 0.48427123, 0.9587981 , 0.6010562 ,
        0.57548887, 0.46208388, 0.7693816 , 0.06371653, 0.97895676,
        0.6978117 , 0.9685761 , 0.97011906, 0.22341514, 0.56326205,
        0.9978037 , 0.97661865, 0.33654213, 0.35123014, 0.23959029,
        0.358207  , 0.99651885, 0.7739324 , 0.5641022 , 0.72754997,
        0.3077591 , 0.18257308, 0.5449101 , 0.65663534, 0.1949212 ,
        0.8193548 , 0.79964596, 0.9176568 , 0.34189552, 0.5239384 ,
        0.70477635, 0.4503097 , 0.07584941, 0.22442049, 0.06589556,
        0.6130815 , 0.35458   , 0.07890564, 0.27350843, 0.07805085,
        0.79995   , 0.05868119, 0.66441715, 0.267847  , 0.6351336 ,
        0.72437716, 0.04632962, 0.92803836, 0.645646  , 0.6836786 ,
        0.07632524, 0.07594979, 0.04397732, 0.18492383, 0.89419115,
        0.3588807 , 0.6925135 , 0.23337674, 0.34763372, 0.66951907,
        0.10478634, 0.14702266, 0.55476344, 0.47362745, 0.69343317,
        0.03562325, 0.80160064, 0.6175768 , 0.2867241 , 0.13401723,
        0.719559  , 0.05618161, 0.55481714, 0.7375902 , 0.28414857,
        0.9300911 , 0.17248052, 0.4012187 , 0.38931435, 0.83664143,
        0.15867668, 0.3341686 , 0.7945494 , 0.81226593, 0.8724434 ],
       dtype=float32),
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,
        6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int32),
 array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
        2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
        6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">indices = np.vstack((adj.row,adj.col)) <span class="comment"># æˆ‘ä»¬éœ€è¦çš„cooå½¢å¼çš„edge_index</span></span><br><span class="line">edge_index = torch.LongTensor(indices)<span class="comment">#PyGéœ€è¦çš„edge_index</span></span><br><span class="line">edge_index,edge_index.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 torch.Size([2, 100]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edge_attr = adj.data <span class="comment">#è¾¹æƒå€¼</span></span><br><span class="line">edge_attr = torch.FloatTensor(edge_attr)<span class="comment">#to float tensor</span></span><br><span class="line">edge_attr,edge_attr.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([0.8253, 0.2458, 0.9340, 0.4631, 0.5114, 0.3248, 0.8528, 0.6354, 0.2988,
         0.1087, 0.0190, 0.5693, 0.4843, 0.9588, 0.6011, 0.5755, 0.4621, 0.7694,
         0.0637, 0.9790, 0.6978, 0.9686, 0.9701, 0.2234, 0.5633, 0.9978, 0.9766,
         0.3365, 0.3512, 0.2396, 0.3582, 0.9965, 0.7739, 0.5641, 0.7275, 0.3078,
         0.1826, 0.5449, 0.6566, 0.1949, 0.8194, 0.7996, 0.9177, 0.3419, 0.5239,
         0.7048, 0.4503, 0.0758, 0.2244, 0.0659, 0.6131, 0.3546, 0.0789, 0.2735,
         0.0781, 0.8000, 0.0587, 0.6644, 0.2678, 0.6351, 0.7244, 0.0463, 0.9280,
         0.6456, 0.6837, 0.0763, 0.0759, 0.0440, 0.1849, 0.8942, 0.3589, 0.6925,
         0.2334, 0.3476, 0.6695, 0.1048, 0.1470, 0.5548, 0.4736, 0.6934, 0.0356,
         0.8016, 0.6176, 0.2867, 0.1340, 0.7196, 0.0562, 0.5548, 0.7376, 0.2841,
         0.9301, 0.1725, 0.4012, 0.3893, 0.8366, 0.1587, 0.3342, 0.7945, 0.8123,
         0.8724]),
 torch.Size([100]))
</code></pre><h2 id="torch"><a href="#torch" class="headerlink" title="torch**"></a>torch<em>**</em></h2><p>ä½¿ç”¨å‰é¢çš„æ–¹æ³•ï¼Œå½“ä¼ å…¥cudaçš„è¾“å…¥ç„¶åè¿›è¡Œè½¬æ¢æ—¶ï¼Œå‰é¢çš„æ–¹æ³•åªèƒ½åœ¨cpuä¸Šæ‰§è¡Œï¼Œå› ä¸ºcudaä¸æ”¯æŒnumpy(),éœ€è¦è¿›è¡Œcpuå’Œcudaçš„è½¬æ¢ã€‚ï¼ˆä¸€ç›´ä»¥ä¸ºæ˜¯å› ä¸ºæ•°æ®ä¼ è¾“ç­‰æ–¹é¢å¯èƒ½çš„å½±å“å¯¼è‡´æˆ‘çš„é€Ÿåº¦å˜æ…¢ï¼Œä½†æ˜¯ä¼¼ä¹å½±å“æ›´å¤§çš„æ˜¯å› ä¸ºåç»­æ¨¡å‹åŠ è½½éæˆbatch)ï¼‰</p>
<p>torchçš„æ–¹æ³•ä¸éœ€è¦</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">A = torch.rand([<span class="number">10</span>,<span class="number">10</span>]) <span class="comment"># 10*10çš„é‚»æ¥çŸ©é˜µAï¼Œå¸¦æœ‰æƒå€¼ï¼Œè€Œé0/1</span></span><br><span class="line">A</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227],
        [0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706, 0.1307,
         0.3265],
        [0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413, 0.7737, 0.8839,
         0.9673],
        [0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640, 0.2160, 0.1306, 0.4602,
         0.9815],
        [0.8076, 0.4725, 0.8042, 0.3854, 0.4384, 0.9577, 0.5992, 0.5335, 0.9595,
         0.1808],
        [0.3166, 0.5219, 0.1348, 0.2726, 0.6527, 0.7875, 0.2952, 0.6067, 0.5722,
         0.0738],
        [0.2799, 0.3344, 0.2588, 0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913,
         0.5702],
        [0.5489, 0.5952, 0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059,
         0.1255],
        [0.3011, 0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226,
         0.9818],
        [0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adj = A.to_sparse()</span><br><span class="line">adj, adj.indices(),adj.values()</span><br></pre></td></tr></table></figure>
<pre><code>(tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                         1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
                         3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,
                         5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
                         7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9,
                         9, 9, 9, 9, 9],
                        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,
                         9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
                         8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6,
                         7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
                         6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,
                         5, 6, 7, 8, 9]]),
        values=tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526,
                       0.6831, 0.0242, 0.3227, 0.8430, 0.0125, 0.0166, 0.2306,
                       0.6767, 0.7800, 0.3947, 0.5706, 0.1307, 0.3265, 0.8983,
                       0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413, 0.7737,
                       0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316,
                       0.1640, 0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725,
                       0.8042, 0.3854, 0.4384, 0.9577, 0.5992, 0.5335, 0.9595,
                       0.1808, 0.3166, 0.5219, 0.1348, 0.2726, 0.6527, 0.7875,
                       0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
                       0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702,
                       0.5489, 0.5952, 0.3463, 0.6634, 0.1480, 0.4949, 0.3449,
                       0.6737, 0.5059, 0.1255, 0.3011, 0.6796, 0.9407, 0.1118,
                       0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818, 0.7948,
                       0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893,
                       0.2553, 0.4072]),
        size=(10, 10), nnz=100, layout=torch.sparse_coo),
 tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227, 0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706,
         0.1307, 0.3265, 0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413,
         0.7737, 0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640,
         0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725, 0.8042, 0.3854, 0.4384,
         0.9577, 0.5992, 0.5335, 0.9595, 0.1808, 0.3166, 0.5219, 0.1348, 0.2726,
         0.6527, 0.7875, 0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
         0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702, 0.5489, 0.5952,
         0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059, 0.1255, 0.3011,
         0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818,
         0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">indices = adj.indices() <span class="comment"># æˆ‘ä»¬éœ€è¦çš„cooå½¢å¼çš„edge_index</span></span><br><span class="line">edge_index = indices<span class="comment">#PyGéœ€è¦çš„edge_index</span></span><br><span class="line">edge_index,edge_index.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 torch.Size([2, 100]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edge_attr = adj.values()</span><br><span class="line">edge_attr,edge_attr.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227, 0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706,
         0.1307, 0.3265, 0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413,
         0.7737, 0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640,
         0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725, 0.8042, 0.3854, 0.4384,
         0.9577, 0.5992, 0.5335, 0.9595, 0.1808, 0.3166, 0.5219, 0.1348, 0.2726,
         0.6527, 0.7875, 0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
         0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702, 0.5489, 0.5952,
         0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059, 0.1255, 0.3011,
         0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818,
         0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]),
 torch.Size([100]))
</code></pre><h1 id="edge-index-to-é‚»æ¥çŸ©é˜µ"><a href="#edge-index-to-é‚»æ¥çŸ©é˜µ" class="headerlink" title="edge_index to é‚»æ¥çŸ©é˜µ"></a>edge_index to é‚»æ¥çŸ©é˜µ</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> sparse_coo_tensor</span><br><span class="line">adj = sparse_coo_tensor(edge_index,edge_attr,[<span class="number">10</span>,<span class="number">10</span>])</span><br><span class="line">adj.to_dense()</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[4.5977e-01, 6.6455e-01, 4.3946e-01, 3.8642e-01, 1.2331e-01, 2.9945e-01,
         2.5433e-01, 9.7476e-01, 4.5961e-04, 5.9594e-02],
        [2.2455e-01, 9.7698e-01, 8.7531e-01, 2.8142e-01, 7.0980e-01, 6.2595e-01,
         2.3625e-01, 5.7737e-01, 4.4227e-01, 6.5420e-01],
        [5.4512e-01, 2.4614e-01, 6.9270e-01, 6.8005e-01, 1.3384e-01, 5.9974e-01,
         9.2275e-01, 3.6578e-01, 3.5667e-01, 5.8081e-01],
        [9.6142e-02, 8.5471e-01, 5.9899e-02, 3.0163e-01, 2.9641e-01, 2.8706e-01,
         4.8757e-01, 8.8466e-01, 3.4357e-01, 9.9034e-01],
        [4.5909e-01, 7.2475e-01, 2.4294e-01, 7.3560e-01, 3.2247e-01, 7.6749e-01,
         3.6008e-01, 3.0816e-01, 7.4665e-01, 6.7713e-01],
        [6.6836e-01, 8.9111e-01, 8.0428e-01, 7.9984e-01, 6.5296e-01, 8.1743e-01,
         8.8702e-01, 3.6678e-01, 4.2774e-01, 2.3170e-02],
        [8.1350e-01, 1.6834e-01, 7.7933e-02, 3.8021e-01, 9.7750e-01, 5.6143e-01,
         7.9341e-01, 3.7514e-01, 9.3114e-01, 5.6821e-01],
        [8.4002e-01, 9.2273e-01, 5.6649e-01, 7.5386e-01, 9.1587e-01, 3.9596e-02,
         8.9435e-01, 5.6476e-01, 2.3289e-01, 1.9653e-01],
        [2.1682e-01, 2.8950e-01, 7.5310e-01, 6.7648e-01, 5.1057e-02, 1.6519e-01,
         5.8807e-01, 9.4542e-02, 6.3111e-01, 2.9049e-01],
        [5.7742e-02, 3.1503e-01, 5.6936e-01, 2.2748e-01, 4.8668e-01, 6.4949e-01,
         6.1752e-01, 3.9269e-01, 2.7897e-01, 5.5806e-01]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adj = sp.coo_matrix((edge_attr,(edge_index[<span class="number">0</span>],edge_index[<span class="number">1</span>])),shape=[<span class="number">10</span>,<span class="number">10</span>])</span><br><span class="line">adj.toarray()</span><br></pre></td></tr></table></figure>
<pre><code>array([[4.5977378e-01, 6.6455245e-01, 4.3945801e-01, 3.8642406e-01,
        1.2331247e-01, 2.9944807e-01, 2.5433010e-01, 9.7475851e-01,
        4.5961142e-04, 5.9593856e-02],
       [2.2454953e-01, 9.7697508e-01, 8.7531334e-01, 2.8141612e-01,
        7.0980257e-01, 6.2595367e-01, 2.3624879e-01, 5.7737088e-01,
        4.4226754e-01, 6.5420014e-01],
       [5.4512197e-01, 2.4613553e-01, 6.9269532e-01, 6.8004644e-01,
        1.3383734e-01, 5.9973723e-01, 9.2274553e-01, 3.6578351e-01,
        3.5666680e-01, 5.8080733e-01],
       [9.6142113e-02, 8.5471165e-01, 5.9899449e-02, 3.0162632e-01,
        2.9641372e-01, 2.8705674e-01, 4.8757398e-01, 8.8466209e-01,
        3.4356719e-01, 9.9034435e-01],
       [4.5909441e-01, 7.2474545e-01, 2.4293584e-01, 7.3560286e-01,
        3.2246715e-01, 7.6749289e-01, 3.6007798e-01, 3.0815858e-01,
        7.4665487e-01, 6.7713338e-01],
       [6.6836429e-01, 8.9111018e-01, 8.0427557e-01, 7.9984426e-01,
        6.5295666e-01, 8.1743485e-01, 8.8702154e-01, 3.6678237e-01,
        4.2774427e-01, 2.3170471e-02],
       [8.1350172e-01, 1.6834372e-01, 7.7932715e-02, 3.8021082e-01,
        9.7749555e-01, 5.6143039e-01, 7.9341477e-01, 3.7514049e-01,
        9.3114382e-01, 5.6820768e-01],
       [8.4002483e-01, 9.2273450e-01, 5.6649190e-01, 7.5385606e-01,
        9.1587120e-01, 3.9596200e-02, 8.9435184e-01, 5.6475997e-01,
        2.3288828e-01, 1.9652534e-01],
       [2.1682233e-01, 2.8950059e-01, 7.5310403e-01, 6.7648250e-01,
        5.1056564e-02, 1.6518539e-01, 5.8806950e-01, 9.4541669e-02,
        6.3110876e-01, 2.9048622e-01],
       [5.7742238e-02, 3.1502587e-01, 5.6935811e-01, 2.2748303e-01,
        4.8667991e-01, 6.4949030e-01, 6.1752105e-01, 3.9268762e-01,
        2.7897447e-01, 5.5806071e-01]], dtype=float32)
</code></pre><h1 id="æ„å»ºè‡ªå®šä¹‰è¾¹æƒé‡çš„GNN"><a href="#æ„å»ºè‡ªå®šä¹‰è¾¹æƒé‡çš„GNN" class="headerlink" title="æ„å»ºè‡ªå®šä¹‰è¾¹æƒé‡çš„GNN"></a>æ„å»ºè‡ªå®šä¹‰è¾¹æƒé‡çš„GNN</h1><p>èƒ¡ä¹±å®šå€¼çš„<br>ä»£ç ä¿®æ”¹è‡ªï¼š<a href="https://zhuanlan.zhihu.com/p/426907570">https://zhuanlan.zhihu.com/p/426907570</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = GCNConv(data.num_features, <span class="number">16</span>, cached=<span class="literal">True</span>,</span><br><span class="line">                             normalize=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#         self.conv1 = GATConv(data.num_features, 16)</span></span><br><span class="line">        <span class="comment">#self.conv2 = GCNConv(16, data.num_classes, cached=True,</span></span><br><span class="line">        self.conv2 = GCNConv(<span class="number">16</span>, <span class="number">2</span>, cached=<span class="literal">True</span>,</span><br><span class="line">                            normalize=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#         self.conv2 = GATConv(16, 2)</span></span><br><span class="line">        <span class="comment"># self.conv1 = ChebConv(data.num_features, 16, K=2)</span></span><br><span class="line">        <span class="comment"># self.conv2 = ChebConv(16, data.num_features, K=2)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self</span>):</span><br><span class="line">        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr</span><br><span class="line">        x = F.relu(self.conv1(x, edge_index, edge_weight))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = self.conv2(x, edge_index, edge_weight)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv, ChebConv  <span class="comment"># noqa</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> data <span class="keyword">as</span> D</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> dataset</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>],[<span class="number">5</span>],[<span class="number">6</span>],[<span class="number">7</span>],[<span class="number">8</span>],[<span class="number">9</span>],[<span class="number">10</span>]], dtype=torch.<span class="built_in">float</span>)   <span class="comment"># N x emb(in)</span></span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">x = torch.ones(<span class="number">10</span>,dtype=torch.<span class="built_in">float</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#print(x.shape)</span></span><br><span class="line">y = torch.randint(<span class="number">0</span>,<span class="number">2</span>,[<span class="number">10</span>])</span><br><span class="line">train_mask = torch.tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>], dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">val_mask=train_mask</span><br><span class="line">test_mask=train_mask</span><br><span class="line">data=D.Data()</span><br><span class="line">data.x,data.y,data.edge_index,data.edge_attr,data.train_mask,data.val_mask,data.test_mask \</span><br><span class="line">    = x,y,edge_index,edge_attr,train_mask,val_mask,test_mask</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([10, 1])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model, data = Net().to(device), data.to(device)</span><br><span class="line">optimizer = torch.optim.Adam([</span><br><span class="line">    <span class="built_in">dict</span>(params=model.conv1.parameters(), weight_decay=<span class="number">5e-4</span>),</span><br><span class="line">    <span class="built_in">dict</span>(params=model.conv2.parameters(), weight_decay=<span class="number">0</span>)</span><br><span class="line">], lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    model.train()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()</span><br><span class="line">    <span class="comment">#F.nll_loss(model()[data], data.y).backward() #ä¸è¡Œï¼</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    logits, accs = model(), []</span><br><span class="line">    <span class="keyword">for</span> _, mask <span class="keyword">in</span> data(<span class="string">&#x27;train_mask&#x27;</span>, <span class="string">&#x27;val_mask&#x27;</span>, <span class="string">&#x27;test_mask&#x27;</span>):</span><br><span class="line">        pred = logits[mask].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        acc = pred.eq(data.y[mask]).<span class="built_in">sum</span>().item() / mask.<span class="built_in">sum</span>().item()</span><br><span class="line">        accs.append(acc)</span><br><span class="line">    <span class="keyword">return</span> accs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_val_acc = test_acc = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">    train()</span><br><span class="line">    train_acc, val_acc, tmp_test_acc = test()</span><br><span class="line">    <span class="keyword">if</span> val_acc &gt; best_val_acc:</span><br><span class="line">        best_val_acc = val_acc</span><br><span class="line">        test_acc = tmp_test_acc</span><br><span class="line">    log = <span class="string">&#x27;Epoch: &#123;:03d&#125;, Train: &#123;:.4f&#125;, Val: &#123;:.4f&#125;, Test: &#123;:.4f&#125;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(log.<span class="built_in">format</span>(epoch, train_acc, best_val_acc, test_acc))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch: 001, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 002, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 003, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 004, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 005, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 006, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 007, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 008, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 009, Train: 0.5000, Val: 0.5000, Test: 0.5000
</code></pre><h1 id="æ‰¹é‡"><a href="#æ‰¹é‡" class="headerlink" title="æ‰¹é‡"></a>æ‰¹é‡</h1><h2 id="å•ç‹¬ä¼ å…¥ï¼Œstackç»“æœ"><a href="#å•ç‹¬ä¼ å…¥ï¼Œstackç»“æœ" class="headerlink" title="å•ç‹¬ä¼ å…¥ï¼Œstackç»“æœ"></a>å•ç‹¬ä¼ å…¥ï¼Œstackç»“æœ</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">16</span>)</span><br><span class="line">        self.layer2 = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x,edg_index</span>):</span><br><span class="line">        output = torch.stack([self.layer(graph, edge_index=edge_indexi) <span class="keyword">for</span> graph,edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edg_index)], dim=<span class="number">0</span>)</span><br><span class="line">        output = torch.stack([self.layer2(graph, edge_index=edge_indexi) <span class="keyword">for</span> graph,edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(output,edg_index)], dim=<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#output = torch.sigmoid(output)</span></span><br><span class="line">        <span class="comment">#print(output.shape)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="comment">#print(edge_index.shape)</span></span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#print(edge_index.shape)</span></span><br><span class="line">model = Net()</span><br><span class="line">optimizer = torch.optim.Adam(params=model.parameters(),lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">s = time.time()</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = model(x,edge_index)</span><br><span class="line">    <span class="comment">#print(out.shape)</span></span><br><span class="line">    <span class="comment">#print(y.shape)</span></span><br><span class="line">    loss = F.mse_loss(out, y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(loss.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;time:&quot;</span>,time.time()-s)</span><br></pre></td></tr></table></figure>
<pre><code>0.7729121446609497
0.41821303963661194
0.384408563375473
time: 0.09303927421569824
</code></pre><h2 id="Batch-Data"><a href="#Batch-Data" class="headerlink" title="Batch+Data"></a>Batch+Data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">16</span>)</span><br><span class="line">        self.layer2 = GATConv(in_channels=<span class="number">16</span>,out_channels=<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x,edge_index</span>):</span><br><span class="line"><span class="comment">#         print(&quot;input:&quot;,x.shape)</span></span><br><span class="line">        data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edge_index)] </span><br><span class="line">        </span><br><span class="line">        batch = Batch.from_data_list(data_list)</span><br><span class="line">        output = self.layer(batch.x, edge_index=batch.edge_index)</span><br><span class="line"><span class="comment">#         print(&quot;output:&quot;,output.shape)</span></span><br><span class="line">        output = self.dropout(output)</span><br><span class="line">        data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(torch.split(output,x.shape[<span class="number">1</span>]),edge_index)] </span><br><span class="line">        batch = Batch.from_data_list(data_list)</span><br><span class="line">        output = self.layer2(batch.x,batch.edge_index)</span><br><span class="line">        output = self.dropout(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">optimizer = torch.optim.Adam(params=model.parameters(),lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line">s = time.time()</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    result = model(x,edge_index)</span><br><span class="line"><span class="comment">#     print(result.shape)</span></span><br><span class="line"><span class="comment">#     print(&quot;output of model&quot;,result.shape)</span></span><br><span class="line"><span class="comment">#     print(y.shape)</span></span><br><span class="line">    result = torch.stack(torch.split(result,x.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;reshape the output:&quot;</span>,result.shape)</span><br><span class="line">    loss = F.mse_loss(result, y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(loss.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;time:&quot;</span>,time.time()-s)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 1200])
torch.Size([8, 2, 1200])
reshape the output: torch.Size([8, 207, 1])
2.3954498767852783
reshape the output: torch.Size([8, 207, 1])
1.1830278635025024
reshape the output: torch.Size([8, 207, 1])
0.9167585372924805
time: 0.05799269676208496
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edge_index)] </span><br><span class="line">batch = Batch.from_data_list(data_list)</span><br><span class="line">layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">2</span>)</span><br><span class="line">result = layer(batch.x, edge_index=batch.edge_index)</span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 1200])
torch.Size([8, 2, 1200])
torch.Size([1656, 2])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand([<span class="number">2</span>, <span class="number">2</span>, <span class="number">40000</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    <span class="built_in">print</span>(i.shape)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 40000])
torch.Size([2, 40000])
</code></pre><h1 id="æ‰¹é‡é‚»æ¥çŸ©é˜µè½¬æ¢"><a href="#æ‰¹é‡é‚»æ¥çŸ©é˜µè½¬æ¢" class="headerlink" title="æ‰¹é‡é‚»æ¥çŸ©é˜µè½¬æ¢"></a>æ‰¹é‡é‚»æ¥çŸ©é˜µè½¬æ¢</h1><h2 id="è½¬æ¢å®ç°"><a href="#è½¬æ¢å®ç°" class="headerlink" title="è½¬æ¢å®ç°"></a>è½¬æ¢å®ç°</h2><h3 id="è½¬æ¢å®Œstack"><a href="#è½¬æ¢å®Œstack" class="headerlink" title="è½¬æ¢å®Œstack"></a>è½¬æ¢å®Œstack</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj2coo</span>(<span class="params">self,Ab</span>):</span><br><span class="line">        <span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">        <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">        adj = sp.coo_matrix(Ab)  <span class="comment"># è½¬æ¢æˆcoo_matrixçŸ©é˜µ</span></span><br><span class="line">        edge_attr = adj.data  <span class="comment"># è¾¹æƒå€¼</span></span><br><span class="line">        indices = np.vstack((adj.row, adj.col))  <span class="comment"># æˆ‘ä»¬éœ€è¦çš„cooå½¢å¼çš„edge_index</span></span><br><span class="line">        edge_index = torch.LongTensor(indices)  <span class="comment"># PyGéœ€è¦çš„edge_index</span></span><br><span class="line"></span><br><span class="line">        edge_attr = torch.FloatTensor(edge_attr)  <span class="comment"># to float tensor</span></span><br><span class="line">        <span class="built_in">print</span>(edge_index.shape,edge_attr.shape)</span><br><span class="line">        <span class="keyword">return</span> edge_index,edge_attr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edg_indexH, edge_attrH = torch.stack([self.adj2coo(i)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> scoadj], dim=<span class="number">0</span>), torch.stack(</span><br><span class="line">            [self.adj2coo(i)[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> adj], dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="ä¸€æ¬¡æ€§è§£å†³"><a href="#ä¸€æ¬¡æ€§è§£å†³" class="headerlink" title="ä¸€æ¬¡æ€§è§£å†³"></a>ä¸€æ¬¡æ€§è§£å†³</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj2edge_index</span>(<span class="params">self,A</span>):</span><br><span class="line">       <span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">       <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">       edg_indexAll = torch.zeros(<span class="number">0</span>,dtype=torch.int64)</span><br><span class="line">       edg_attrAll = torch.zeros(<span class="number">0</span>,dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> b <span class="keyword">in</span> A:</span><br><span class="line">           adj = sp.coo_matrix(b)  <span class="comment"># è½¬æ¢æˆcoo_matrixçŸ©é˜µ</span></span><br><span class="line">           edge_attr = adj.data  <span class="comment"># è¾¹æƒå€¼</span></span><br><span class="line">           indices = np.vstack((adj.row, adj.col))  <span class="comment"># æˆ‘ä»¬éœ€è¦çš„cooå½¢å¼çš„edge_index</span></span><br><span class="line">           edge_index = torch.LongTensor(indices)  <span class="comment"># PyGéœ€è¦çš„edge_index</span></span><br><span class="line"></span><br><span class="line">           edge_attr = torch.FloatTensor(edge_attr)  <span class="comment"># to float tensor</span></span><br><span class="line">           edg_indexAll = torch.cat((edg_indexAll, edge_index))</span><br><span class="line">           edg_attrAll = torch.cat((edg_attrAll, edge_attr))</span><br><span class="line"></span><br><span class="line">       <span class="comment">#print(&quot;edg&quot;,edg_indexAll.view(A.shape[0],2,-1).shape)</span></span><br><span class="line">       <span class="comment">#print(edg_attrAll.view(A.shape[0],-1).shape)</span></span><br><span class="line">       <span class="keyword">return</span> edg_indexAll.view(A.shape[<span class="number">0</span>],<span class="number">2</span>,-<span class="number">1</span>),edg_attrAll.view(A.shape[<span class="number">0</span>],-<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="åº”ç”¨åˆ°æ¨¡å‹"><a href="#åº”ç”¨åˆ°æ¨¡å‹" class="headerlink" title="åº”ç”¨åˆ°æ¨¡å‹"></a>åº”ç”¨åˆ°æ¨¡å‹</h2><h3 id="æ¨¡å‹ä¸­ä¼ å‚"><a href="#æ¨¡å‹ä¸­ä¼ å‚" class="headerlink" title="æ¨¡å‹ä¸­ä¼ å‚"></a>æ¨¡å‹ä¸­ä¼ å‚</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x3 = self.relu(</span><br><span class="line">            torch.stack(</span><br><span class="line">                [self.gc6(graph, edge_index=self.adj2coo(edge)[<span class="number">0</span>], edge_attr=self.adj2coo(edge)[<span class="number">1</span>]) <span class="keyword">for</span> graph, edge <span class="keyword">in</span></span><br><span class="line">                 <span class="built_in">zip</span>(x3_h,A)],</span><br><span class="line">                dim=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h3 id="Batch-Data-1"><a href="#Batch-Data-1" class="headerlink" title="Batch+Data"></a>Batch+Data</h3><p><strong>æ•ˆç‡æ›´é«˜ï¼Œå¦‚ä¸€ä¸ªepochå‰é¢æ˜¯280s,åé¢æ˜¯90s</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line">data_list = [Data(x = x_,edge_ index=self.adj2coo(edge)[<span class="number">0</span>] ,edge_attr=self.adj2coo(edge)[<span class="number">1</span>]) <span class="keyword">for</span></span><br><span class="line">x_ ,edge <span class="keyword">in</span> <span class="built_in">zip</span>(x, A) ]</span><br><span class="line">batchH = Batch.from_data_list(data_listata_list)</span><br><span class="line">x1_h = self. relu(self. gc1(batchH.xï¼Œ edge_index=batchH. edge_indexedge_attr=batchH.edge_attr ))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>å›¾ç¥ç»ç½‘ç»œ</category>
      </categories>
      <tags>
        <tag>PyG</tag>
        <tag>GNN</tag>
      </tags>
  </entry>
</search>
