<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>音乐播放</title>
    <url>/posts/802d9159/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
    <div id="aplayer-CvvyNZvJ" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="8182851368" data-server="netease" data-type="playlist" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div>
<p>ヾ(≧▽≦*)o</p>
<blockquote>
<p> music  by  @fortunato</p>
</blockquote>
<hr>
<span id="more"></span>
<h4 id="实现记录"><a href="#实现记录" class="headerlink" title="实现记录"></a>实现记录</h4><ul>
<li><p>技术</p>
<p> <a href="https://github.com/MoePlayer/hexo-tag-aplayer">GitHub - MoePlayer/hexo-tag-aplayer: Embed aplayer in Hexo posts/pages</a></p>
</li>
<li><p>步骤：</p>
<ol>
<li><p>安装插件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-tag-aplayer</span><br></pre></td></tr></table></figure>
</li>
<li><p>在_config.yml中設置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">aplayer:</span><br><span class="line">  meting: true</span><br></pre></td></tr></table></figure>
<p>注意：true之前空格</p>
</li>
<li><p>post的markdown中添加
    <div id="aplayer-PIbJDpMk" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="..." data-server="undefined" data-type="undefined" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#ad7a86"></div></p>
<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- Simple example (id, server, type)  --&gt;</span><br><span class="line">&#123;% meting &quot;60198&quot; &quot;netease&quot; &quot;playlist&quot; %&#125;</span><br><span class="line"></span><br><span class="line">&lt;!-- Advanced example --&gt;</span><br><span class="line">&#123;% meting &quot;60198&quot; &quot;netease&quot; &quot;playlist&quot; &quot;autoplay&quot; &quot;mutex:false&quot; &quot;listmaxheight:340px&quot; &quot;preload:none&quot; &quot;theme:#ad7a86&quot;%&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<p>​                注：netease是网易云</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Option</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td><strong>required</strong></td>
<td>song id / playlist id / album id / search keyword</td>
</tr>
<tr>
<td>server</td>
<td><strong>required</strong></td>
<td>Music platform: <code>netease</code>, <code>tencent</code>, <code>kugou</code>, <code>xiami</code>, <code>baidu</code></td>
</tr>
<tr>
<td>type</td>
<td><strong>required</strong></td>
<td><code>song</code>, <code>playlist</code>, <code>album</code>, <code>search</code>, <code>artist</code></td>
</tr>
</tbody>
</table>
</div>
]]></content>
  </entry>
  <entry>
    <title>latex图表公式汇总</title>
    <url>/posts/b33a9282/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><h3 id="标准三线表"><a href="#标准三线表" class="headerlink" title="标准三线表"></a>标准三线表</h3><span id="more"></span>
<p><code>\caption</code> 为标题；</p>
<p><code>\label</code>为标签，用于引用</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[!htbp]</span><br><span class="line">   <span class="keyword">\caption</span>&#123;标准三线表格&#125;<span class="keyword">\label</span>&#123;tab:001&#125; <span class="keyword">\centering</span></span><br><span class="line">   <span class="keyword">\begin</span>&#123;tabular&#125;&#123;ccccc&#125;</span><br><span class="line">       <span class="keyword">\toprule</span><span class="comment">%[1.5pt]</span></span><br><span class="line">       <span class="built_in">$</span>D<span class="built_in">$</span>(in) <span class="built_in">&amp;</span> <span class="built_in">$</span>P<span class="built_in">_</span>u<span class="built_in">$</span>(lbs) <span class="built_in">&amp;</span> <span class="built_in">$</span>u<span class="built_in">_</span>u<span class="built_in">$</span>(in) <span class="built_in">&amp;</span> <span class="built_in">$</span><span class="keyword">\beta</span><span class="built_in">$</span> <span class="built_in">&amp;</span> <span class="built_in">$</span>G<span class="built_in">_</span>f<span class="built_in">$</span>(psi.in)<span class="keyword">\\</span></span><br><span class="line">       <span class="keyword">\midrule</span><span class="comment">%[1pt]</span></span><br><span class="line">       5 <span class="built_in">&amp;</span> 269.8 <span class="built_in">&amp;</span> 0.000674 <span class="built_in">&amp;</span> 1.79 <span class="built_in">&amp;</span> 0.04089<span class="keyword">\\</span></span><br><span class="line">       10 <span class="built_in">&amp;</span> 421.0 <span class="built_in">&amp;</span> 0.001035 <span class="built_in">&amp;</span> 3.59 <span class="built_in">&amp;</span> 0.04089<span class="keyword">\\</span></span><br><span class="line">       20 <span class="built_in">&amp;</span> 640.2 <span class="built_in">&amp;</span> 0.001565 <span class="built_in">&amp;</span> 7.18 <span class="built_in">&amp;</span> 0.04089<span class="keyword">\\</span></span><br><span class="line">       <span class="keyword">\bottomrule</span><span class="comment">%[1.5pt]</span></span><br><span class="line">   <span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure>
<h3 id="表格的引用"><a href="#表格的引用" class="headerlink" title="表格的引用"></a>表格的引用</h3><p>引用前面那个表。</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">三线表如表<span class="keyword">\cref</span>&#123;tab:001&#125;所示。</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p>三线表如表5.1所示。</p>
<p>涉及宏包：<code>hyperref</code>、<code>cleveref</code></p>
<h3 id="普通表"><a href="#普通表" class="headerlink" title="普通表"></a>普通表</h3><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[htbp]</span><br><span class="line">	<span class="keyword">\centering</span>  <span class="comment">% 显示位置为中间</span></span><br><span class="line">	<span class="keyword">\caption</span>&#123;三类材料生产成本对比&#125;  <span class="comment">% 表格标题</span></span><br><span class="line">	<span class="keyword">\label</span>&#123;table:table1&#125;  <span class="comment">% 用于索引表格的标签</span></span><br><span class="line">	<span class="comment">%字母的个数对应列数，|代表分割线</span></span><br><span class="line">	<span class="comment">% l代表左对齐，c代表居中，r代表右对齐</span></span><br><span class="line">	<span class="keyword">\begin</span>&#123;tabular&#125;&#123;|c|c|c|c|&#125;  </span><br><span class="line">		<span class="keyword">\hline</span>  <span class="comment">% 表格的横线</span></span><br><span class="line">		<span class="comment">%可以避免文字偏上来调整文字与上边界的距离</span></span><br><span class="line">		 <span class="built_in">&amp;</span>A<span class="built_in">&amp;</span>B<span class="built_in">&amp;</span>C <span class="keyword">\\</span>  <span class="comment">% 表格中的内容，用&amp;分开，\\表示下一行</span></span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">		 <span class="comment">%可以避免文字偏上 </span></span><br><span class="line">		单价<span class="built_in">&amp;</span>1.2<span class="built_in">&amp;</span>1.1<span class="built_in">&amp;</span>1 <span class="keyword">\\</span></span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">		生产所需<span class="built_in">&amp;</span>0.6<span class="built_in">&amp;</span>0.66<span class="built_in">&amp;</span>0.72 <span class="keyword">\\</span></span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">		生产成本<span class="built_in">&amp;</span>0.72<span class="built_in">&amp;</span>0.726<span class="built_in">&amp;</span>0.72 <span class="keyword">\\</span></span><br><span class="line">		<span class="keyword">\hline</span></span><br><span class="line">	<span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure>
<h3 id="合并行列"><a href="#合并行列" class="headerlink" title="合并行列"></a>合并行列</h3><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[!htp]</span><br><span class="line"><span class="keyword">\renewcommand</span><span class="keyword">\arraystretch</span>&#123;1.0&#125; <span class="comment">%定义表格高度</span></span><br><span class="line"><span class="keyword">\newcolumntype</span>&#123;L&#125;&#123;X&#125;</span><br><span class="line"><span class="keyword">\newcolumntype</span>&#123;C&#125;&#123;&gt;&#123;<span class="keyword">\centering</span> <span class="keyword">\arraybackslash</span>&#125;X&#125;</span><br><span class="line"><span class="keyword">\newcolumntype</span>&#123;R&#125;&#123;&gt;&#123;<span class="keyword">\raggedright</span> <span class="keyword">\arraybackslash</span>&#125;X&#125;</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;某校学生升高体重样本&#125;</span><br><span class="line"><span class="keyword">\label</span>&#123;tab2:heightweight&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;tabularx&#125;&#123;0.9<span class="keyword">\textwidth</span>&#125;&#123;|C|C|C|C|&#125;</span><br><span class="line">   <span class="keyword">\Xhline</span>&#123;2<span class="keyword">\arrayrulewidth</span>&#125;</span><br><span class="line">	<span class="keyword">\multicolumn</span>&#123;2&#125;&#123;|c|&#125;&#123;Numbers&#125;  <span class="built_in">&amp;</span>身高<span class="built_in">&amp;</span>体重<span class="keyword">\\</span></span><br><span class="line">	<span class="keyword">\Xhline</span>&#123;2<span class="keyword">\arrayrulewidth</span>&#125;</span><br><span class="line">	<span class="keyword">\multirow</span>&#123;2&#125;&#123;*&#125;&#123;Item&#125; <span class="built_in">&amp;</span>14<span class="built_in">&amp;</span>156<span class="built_in">&amp;</span>42<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\cline</span>&#123;2-4&#125;</span><br><span class="line">	  <span class="built_in">&amp;</span>16<span class="built_in">&amp;</span>158<span class="built_in">&amp;</span>45<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\hline</span></span><br><span class="line">	3<span class="built_in">&amp;</span>14<span class="built_in">&amp;</span>162<span class="built_in">&amp;</span>48<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\hline</span></span><br><span class="line">	4<span class="built_in">&amp;</span>15<span class="built_in">&amp;</span>163<span class="built_in">&amp;</span>50<span class="keyword">\\</span></span><br><span class="line">    <span class="comment">%\cmidrule&#123;2-4&#125;</span></span><br><span class="line">	平均<span class="built_in">&amp;</span>15<span class="built_in">&amp;</span>159.75<span class="built_in">&amp;</span>46.25<span class="keyword">\\</span></span><br><span class="line">	<span class="keyword">\Xhline</span>&#123;2<span class="keyword">\arrayrulewidth</span>&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tabularx&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure>
<h3 id="浮动"><a href="#浮动" class="headerlink" title="浮动"></a>浮动</h3><p>h：here，表示放置在当前位置<br>t：top，表示放置在某页顶部<br>b：bottom，表示放置在某页底部<br>p：page，表示独占一页</p>
<p>[!h] 中的 h 是 here 的意思，! 表示忽略一些浮动体的严格规则。另外里面还可以加上 btp 选项，只要这几个参数在花括号里面，作用是不分先后顺序。强制在当前位置有时!h或者h并不是很有效，可以组合使用</p>
<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><h3 id="基础使用"><a href="#基础使用" class="headerlink" title="基础使用"></a>基础使用</h3><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[htp!]</span><br><span class="line"><span class="keyword">\centering</span></span><br><span class="line"><span class="keyword">\includegraphics</span>[width=.55<span class="keyword">\textwidth</span>]&#123;figures/fig.png&#125;  <span class="comment">%[大小][图片路径]</span></span><br><span class="line"><span class="keyword">\caption</span>&#123;算法流程图&#125;</span><br><span class="line"> <span class="keyword">\label</span>&#123;fig:circuit-diagram&#125; <span class="comment">%引用标签</span></span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<h3 id="多图并排"><a href="#多图并排" class="headerlink" title="多图并排"></a>多图并排</h3><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">\begin</span>&#123;figure&#125;[htp!]</span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[t]&#123;0.48<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\centering</span></span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=0.9<span class="keyword">\textwidth</span>]&#123;figures/fig.png&#125;</span><br><span class="line">    <span class="keyword">\caption</span>&#123;fig1&#125;</span><br><span class="line">    <span class="keyword">\label</span>&#123;fig:a&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;<span class="comment">%</span></span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[t]&#123;0.48<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">    <span class="keyword">\centering</span></span><br><span class="line">    <span class="keyword">\includegraphics</span>[width=0.9<span class="keyword">\textwidth</span>]&#123;figures/fig.png&#125;  <span class="comment">% 2.2in</span></span><br><span class="line">    <span class="keyword">\caption</span>&#123;fig2&#125;</span><br><span class="line">    <span class="keyword">\label</span>&#123;fig:b&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<h4 id="子图引用"><a href="#子图引用" class="headerlink" title="子图引用"></a>子图引用</h4><p>这相当于整体是一张大图片，大图片引用是<code>\cref&#123;fig:sample-figure&#125;</code>，子图引用别分是<code>\cref&#123;fig:sample-figure-a&#125;</code>、<code>\cref&#123;fig:sample-figure-b&#125;</code>、<code>\cref&#123;fig:sample-figure-c&#125;</code>。</p>
<h4 id="子图等高"><a href="#子图等高" class="headerlink" title="子图等高"></a>子图等高</h4><p>如果原本两张图片的高度不同，但是希望它们缩放后<strong>等高</strong>的排在同一行，参考这个例子：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[!h]</span><br><span class="line">    <span class="keyword">\centering</span></span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[c]&#123;0.48<span class="keyword">\textwidth</span>&#125;</span><br><span class="line">        <span class="keyword">\centering</span></span><br><span class="line">        <span class="keyword">\includegraphics</span>[height=0.2<span class="keyword">\textheight</span>]&#123;cat&#125;</span><br><span class="line">        <span class="keyword">\subcaption</span>&#123;一只猫&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[c]&#123;0.48<span class="keyword">\textwidth</span>&#125;</span><br><span class="line">        <span class="keyword">\centering</span></span><br><span class="line">        <span class="keyword">\includegraphics</span>[height=0.2<span class="keyword">\textheight</span>]&#123;smokeblk&#125; <span class="comment">%高度</span></span><br><span class="line">        <span class="keyword">\subcaption</span>&#123;电路图&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">    <span class="keyword">\caption</span>&#123;多图并排示例&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<h4 id="多子图并排2"><a href="#多子图并排2" class="headerlink" title="多子图并排2"></a>多子图并排2</h4><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[!htp]</span><br><span class="line">	<span class="keyword">\centering</span></span><br><span class="line">	<span class="keyword">\subfloat</span>[左1]&#123;<span class="keyword">\includegraphics</span>[width=0.4<span class="keyword">\textwidth</span>]&#123;figures/img1.png&#125;&#125;<span class="keyword">\qquad</span></span><br><span class="line">	<span class="keyword">\subfloat</span>[右1]&#123;<span class="keyword">\includegraphics</span>[width=0.4<span class="keyword">\textwidth</span>]&#123;figures/img2.png&#125;&#125; <span class="keyword">\\</span></span><br><span class="line">	<span class="keyword">\subfloat</span>[下1]&#123;<span class="keyword">\includegraphics</span>[width=0.4<span class="keyword">\textwidth</span>]&#123;figures/img2.png&#125;&#125;<span class="keyword">\qquad</span></span><br><span class="line">	<span class="keyword">\subfloat</span>[下2]&#123;<span class="keyword">\includegraphics</span>[width=0.4<span class="keyword">\textwidth</span>]&#123;figures/img1.png&#125;&#125;</span><br><span class="line">	<span class="keyword">\caption</span>&#123;多图示例&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><h3 id="行内公式"><a href="#行内公式" class="headerlink" title="行内公式"></a>行内公式</h3><p>行内公式使用 <script type="math/tex"> </script>包裹。</p>
<p>行间公式不需要编号的可以使用 <code>\[ \]</code> 包裹</p>
<h3 id="带编号的公式"><a href="#带编号的公式" class="headerlink" title="带编号的公式"></a>带编号的公式</h3><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">E=mc<span class="built_in">^</span>2</span><br><span class="line"><span class="keyword">\label</span>&#123;eq:energy&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<h3 id="常见"><a href="#常见" class="headerlink" title="常见"></a>常见</h3><h4 id="特定位置对齐"><a href="#特定位置对齐" class="headerlink" title="特定位置对齐"></a>特定位置对齐</h4><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;align&#125;</span><br><span class="line">P <span class="built_in">&amp;</span> = UI <span class="keyword">\\</span></span><br><span class="line"><span class="built_in">&amp;</span> = I<span class="built_in">^</span>2R</span><br><span class="line"><span class="keyword">\end</span>&#123;align&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;align*&#125; <span class="comment">%这样就不显示且不参与编号</span></span><br><span class="line">    P <span class="built_in">&amp;</span> = UI <span class="keyword">\\</span></span><br><span class="line">    <span class="built_in">&amp;</span> = I<span class="built_in">^</span>2R</span><br><span class="line"><span class="keyword">\end</span>&#123;align*&#125;</span><br></pre></td></tr></table></figure>
<h4 id="分段函数"><a href="#分段函数" class="headerlink" title="分段函数"></a>分段函数</h4><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\[</span></span><br><span class="line">f(x) =</span><br><span class="line">    <span class="keyword">\begin</span>&#123;cases&#125;</span><br><span class="line">        0 <span class="built_in">&amp;</span>  x <span class="keyword">\text</span>&#123;为无理数&#125; ,<span class="keyword">\\</span></span><br><span class="line">        1 <span class="built_in">&amp;</span>  x <span class="keyword">\text</span>&#123;为有理数&#125; .</span><br><span class="line">    <span class="keyword">\end</span>&#123;cases&#125;</span><br><span class="line"><span class="keyword">\]</span></span><br></pre></td></tr></table></figure>
<h4 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h4><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\[</span></span><br><span class="line"><span class="keyword">\mathbf</span>&#123;X&#125; = <span class="keyword">\left</span>(</span><br><span class="line">    <span class="keyword">\begin</span>&#123;array&#125;&#123;cccc&#125;</span><br><span class="line">    x<span class="built_in">_</span>&#123;11&#125; <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;12&#125; <span class="built_in">&amp;</span> <span class="keyword">\ldots</span> <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;1n&#125;<span class="keyword">\\</span></span><br><span class="line">    x<span class="built_in">_</span>&#123;21&#125; <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;22&#125; <span class="built_in">&amp;</span> <span class="keyword">\ldots</span> <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;2n&#125;<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\vdots</span> <span class="built_in">&amp;</span> <span class="keyword">\vdots</span> <span class="built_in">&amp;</span> <span class="keyword">\ddots</span> <span class="built_in">&amp;</span> <span class="keyword">\vdots</span><span class="keyword">\\</span></span><br><span class="line">    x<span class="built_in">_</span>&#123;n1&#125; <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;n2&#125; <span class="built_in">&amp;</span> <span class="keyword">\ldots</span> <span class="built_in">&amp;</span> x<span class="built_in">_</span>&#123;nn&#125;<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\end</span>&#123;array&#125; <span class="keyword">\right</span>)</span><br><span class="line"><span class="keyword">\]</span></span><br></pre></td></tr></table></figure>
<h3 id="公式引用"><a href="#公式引用" class="headerlink" title="公式引用"></a>公式引用</h3><ol>
<li><p>设置label</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">E=mc<span class="built_in">^</span>2</span><br><span class="line"><span class="keyword">\label</span>&#123;eq:energy&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>\cref&#123;eq:energy&#125;</code>    </p>
</li>
</ol>
<h3 id="公式在线识别"><a href="#公式在线识别" class="headerlink" title="公式在线识别"></a>公式在线识别</h3><p><a href="https://www.simpletex.cn/ai/latex_ocr">公式识别 (simpletex.cn)</a></p>
]]></content>
      <categories>
        <category>latex</category>
      </categories>
      <tags>
        <tag>数模</tag>
      </tags>
  </entry>
  <entry>
    <title>写作模板</title>
    <url>/posts/4c8b4541/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><h4 id="论文标题"><a href="#论文标题" class="headerlink" title="论文标题"></a><strong>论文标题</strong></h4><span id="more"></span>
<ul>
<li>基于所使用的主要模型或方法作为标题</li>
</ul>
<h4 id="摘要-："><a href="#摘要-：" class="headerlink" title="摘要 ："></a><strong>摘要 </strong>：</h4><ul>
<li>可以最后来写 1000字左右</li>
<li><strong>格式</strong><ul>
<li><img src="/posts/4c8b4541/image-20210904124259870.png" alt></li>
</ul>
</li>
<li><strong>开头段（必要）</strong><ul>
<li>简单交代一下背景实际意义（可选）</li>
<li>交代一下所做的事情</li>
</ul>
</li>
<li>中间段：分别针对三个问题<ul>
<li>解决了什么问题 </li>
<li>应用了什么方法 ：对应这个问题的求解思路，说明应用的模型</li>
<li>得到了什么结果：必要数值可以呈现</li>
</ul>
</li>
<li>结尾段（可选）<ul>
<li>总结 对类似问题做适当的推广</li>
</ul>
</li>
<li>废话<ul>
<li><img src="/posts/4c8b4541/image-20210904124756585.png" alt></li>
</ul>
</li>
</ul>
<h4 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a><strong>关键词</strong></h4><ul>
<li>4-6</li>
<li>主要模型  出现次数多的体现主要内容（1-2个）</li>
</ul>
<h4 id="一、问题重述"><a href="#一、问题重述" class="headerlink" title="一、问题重述"></a><strong>一、问题重述</strong></h4><ul>
<li>格式<ul>
<li><strong>1.1问题背景</strong></li>
<li><strong>1.2问题提出</strong></li>
</ul>
</li>
<li>方式：<ul>
<li>1.在原题上改：这部分不是重点部分，时间来不及可以选这个方法</li>
<li>丰富一下</li>
</ul>
</li>
</ul>
<h4 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、问题分析"></a><strong>二、问题分析</strong></h4><ul>
<li>题目中包含的信息条件，利用信息和条件对题目做整体分析，确定用什么方法建模，每个问题单独放一段，分析过程简明扼要，不需要放结论</li>
<li>一般不超过一页，问题较多时不超过两页</li>
<li>图</li>
<li>格式<ul>
<li><strong>可选：总的</strong></li>
<li><strong>2.1对问题一的分析</strong></li>
<li><strong>2.2对问题二的分析</strong></li>
<li><strong>2.3对问题三的分析</strong></li>
</ul>
</li>
</ul>
<h4 id="三、模型假设"><a href="#三、模型假设" class="headerlink" title="三、模型假设"></a>三、模型假设</h4><ul>
<li><strong>1。 2。 3.。。</strong></li>
<li>题目中明确给出的假设条件</li>
<li>排除生活中的小概率事件</li>
<li>仅考虑问题中的核心因素，不考虑次要因素<ul>
<li>不要过于简化</li>
</ul>
</li>
<li><img src="/posts/4c8b4541/image-20210904133357130.png" alt></li>
</ul>
<h4 id="四、符号说明"><a href="#四、符号说明" class="headerlink" title="四、符号说明"></a>四、符号说明</h4><p><strong>三线表</strong></p>
<ul>
<li>临时变量可以不放</li>
<li>下文中首次出现这些变量时也要解释</li>
<li>可以加一下单位</li>
</ul>
<h4 id="五、模型建立与求解"><a href="#五、模型建立与求解" class="headerlink" title="五、模型建立与求解"></a>五、模型建立与求解</h4><ul>
<li><strong>5.1 问题一模型建立与求解</strong></li>
<li><strong>5.2问题二模型建立与求解</strong></li>
<li>…..</li>
</ul>
<h4 id="六、模型的分析与检验（Option"><a href="#六、模型的分析与检验（Option" class="headerlink" title="六、模型的分析与检验（Option)"></a>六、模型的分析与检验（Option)</h4><ul>
<li><p>分析</p>
<ul>
<li>常见两种：1.灵敏度分析<ul>
<li>控制其他参数不变，改变某个重要参数的值，观察模型变化</li>
<li><img src="/posts/4c8b4541/image-20210904135644870.png" alt></li>
</ul>
</li>
<li>误差分析<ul>
<li>预测问题或数值计算问题</li>
</ul>
</li>
</ul>
</li>
<li><p>检验</p>
<ul>
<li>最常见的是稳定性检验</li>
<li><img src="/posts/4c8b4541/image-20210904140719365.png" alt></li>
</ul>
</li>
</ul>
<h4 id="七、模型的评价"><a href="#七、模型的评价" class="headerlink" title="七、模型的评价"></a><strong>七、模型的评价</strong></h4><ul>
<li><strong>7.1 模型的评价</strong>：<ul>
<li>优点</li>
<li>缺点</li>
</ul>
</li>
<li><strong>7.2 模型的改进</strong>：针对模型中的缺点可以改进的地方</li>
<li><strong>7.3 模型的推广</strong> 可选</li>
</ul>
<h4 id="八、参考文献"><a href="#八、参考文献" class="headerlink" title="八、参考文献"></a>八、参考文献</h4><ul>
<li>不要去引用博客 和 以往的论文</li>
</ul>
<h4 id="附录"><a href="#附录" class="headerlink" title="附录"></a><strong>附录</strong></h4><h3 id="编辑好的论文模板"><a href="#编辑好的论文模板" class="headerlink" title="编辑好的论文模板"></a>编辑好的论文模板</h3><p><a href="https://github.com/Xandra298/For_GMCM">Xandra298/For_GMCM (github.com)</a></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>数模</tag>
      </tags>
  </entry>
  <entry>
    <title>miketex+vscode</title>
    <url>/posts/75b83972/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="miketex安装配置"><a href="#miketex安装配置" class="headerlink" title="miketex安装配置"></a>miketex安装配置</h2><span id="more"></span>
<p>参考链接：</p>
<p><a href="https://blog.csdn.net/DrGuCoding/article/details/123523407">https://blog.csdn.net/DrGuCoding/article/details/123523407</a></p>
<p>其中，perl安装我使用了strawberry的。</p>
<h2 id="VSCODE"><a href="#VSCODE" class="headerlink" title="VSCODE"></a>VSCODE</h2><ol>
<li><p>安装 LaTeX Workshop 插件</p>
<p>插件市场搜索安装</p>
</li>
<li><p>配置 LaTeX Workshop</p>
</li>
</ol>
<p>​        【设置】中找到setting.json文件，添加相关配置</p>
<p>​        目前使用的：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;latex-workshop.showContextMenu&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> <span class="comment">//右键菜单  </span></span><br><span class="line"><span class="attr">&quot;latex-workshop.intellisense.package.enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> <span class="comment">//根据加载的包，自动完成命令或包  </span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.autoBuild.run&quot;</span><span class="punctuation">:</span> <span class="string">&quot;never&quot;</span><span class="punctuation">,</span> <span class="comment">//禁止保存文件时自动build </span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.recipes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;</span><span class="punctuation">,</span> <span class="comment">//放在第一个的为默认方案</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PDFLaTeX&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PDFLaTeX with Shell Escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;pdflatex-with-shell-escape&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;XeLaTeX&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;XeLaTeX with Shell Escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;xelatex-with-shell-escape&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex -&gt; bibtex -&gt; pdflatex*2&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  </span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;LaTeXmk&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;latexmk&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BibTeX&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;bibtex&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;latex-workshop.latex.tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latexmk&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latexmk&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-pdf&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-outdir=%OUTDIR%&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex-with-shell-escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pdflatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;--shell-escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex-with-shell-escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xelatex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;--shell-escape&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-synctex=1&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-interaction=nonstopmode&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;-file-line-error&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bibtex&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>各种命令点击即可操作</p>
<p><img src="/posts/75b83972/image-20230918172742533.png" alt></p>
</li>
</ol>
<p>​    快捷键：左侧ctrl+alt+J 定位到pdf位置</p>
<p>​        pdf位置 ctrl+鼠标点击 定位到tex位置</p>
<ul>
<li><p>终端使用miketex编译： xelatex file.tex 等</p>
<p><a href="https://zhuanlan.zhihu.com/p/256370737">xelatex 以及 latexmk 命令行编译 - 知乎 (zhihu.com)</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>latex</category>
      </categories>
      <tags>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title>使用wandb可视化参数选取</title>
    <url>/posts/bad385cb/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Sweep"><a href="#Sweep" class="headerlink" title="Sweep"></a>Sweep</h2><blockquote>
<p>在高维超参数空间中搜索，以找到性能最好的模型，会很不方便。超参数sweep提供了一种有组织的、有效的方法来进行模型的大决战，并挑选出最准确的模型。它们通过自动搜索超参数值的组合（如学习率、批量大小、隐藏层数量、优化器类型）来找到最优化的值。</p>
</blockquote>
<span id="more"></span>
<p>官方教程colab:</p>
<p><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=T_lZSMgX4DLg">Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&amp;B.ipynb - Colaboratory (google.com)</a></p>
<h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><h3 id="setup"><a href="#setup" class="headerlink" title="setup"></a>setup</h3><p>可参见前一篇文章。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install wandb -Uq</span><br></pre></td></tr></table></figure>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">wandb.login()</span><br></pre></td></tr></table></figure>
<p>现在开始正式的来使用sweep!</p>
<p><strong><u>注：后续代码都是python代码，1-3都在main.py中写即可。</u></strong></p>
<h3 id="1-Define-the-sweep"><a href="#1-Define-the-sweep" class="headerlink" title="1. Define the sweep"></a>1. Define the sweep</h3><h4 id="1-1-选择搜索方法"><a href="#1-1-选择搜索方法" class="headerlink" title="1.1 选择搜索方法"></a>1.1 选择搜索方法</h4><blockquote>
<p> We provide the following search <code>methods</code>:</p>
<ul>
<li><p><strong><code>grid</code> Search</strong> – Iterate over every combination of hyperparameter values. Very effective, but can be <strong>computationally costly</strong>.</p>
</li>
<li><p><strong><code>random</code> Search</strong> – Select each new combination at random according to provided <code>distribution</code>s. Surprisingly effective!</p>
</li>
<li><p><strong><code>bayes</code>ian Search</strong> – Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.</p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sweep_config = &#123;</span><br><span class="line">    <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;random&#x27;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>设置目标: </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">metric = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;loss&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;goal&#x27;</span>: <span class="string">&#x27;minimize&#x27;</span>   </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;metric&#x27;</span>] = metric</span><br></pre></td></tr></table></figure>
<p>如果是acc，那么就是<code>maximize</code></p>
<h4 id="1-2-命名超参数"><a href="#1-2-命名超参数" class="headerlink" title="1.2 命名超参数"></a>1.2 命名超参数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parameters_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="string">&#x27;adam&#x27;</span>, <span class="string">&#x27;sgd&#x27;</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;fc_layer_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;values&#x27;</span>: [<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    <span class="string">&#x27;dropout&#x27;</span>: &#123;</span><br><span class="line">          <span class="string">&#x27;values&#x27;</span>: [<span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">sweep_config[<span class="string">&#x27;parameters&#x27;</span>] = parameters_dict</span><br></pre></td></tr></table></figure>
<p>不想变化的超参数, 值设一个：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;value&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure>
<p>可以给出分布：<a href="https://docs.wandb.com/sweeps/configuration#distributions">设置分布</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parameters_dict.update(&#123;</span><br><span class="line">    <span class="string">&#x27;learning_rate&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># a flat distribution between 0 and 0.1</span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">0.1</span></span><br><span class="line">      &#125;,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: &#123;</span><br><span class="line">        <span class="comment"># integers between 32 and 256</span></span><br><span class="line">        <span class="comment"># with evenly-distributed logarithms </span></span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;q_log_uniform_values&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;q&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="string">&#x27;min&#x27;</span>: <span class="number">32</span>,</span><br><span class="line">        <span class="string">&#x27;max&#x27;</span>: <span class="number">256</span>,</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure>
<p>看看现在的<code>sweep_config</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">pprint.pprint(sweep_config)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;method&#x27;: &#x27;random&#x27;,</span><br><span class="line"> &#x27;metric&#x27;: &#123;&#x27;goal&#x27;: &#x27;minimize&#x27;, &#x27;name&#x27;: &#x27;loss&#x27;&#125;,</span><br><span class="line"> &#x27;parameters&#x27;: &#123;&#x27;batch_size&#x27;: &#123;&#x27;distribution&#x27;: &#x27;q_log_uniform_values&#x27;,</span><br><span class="line">                               &#x27;max&#x27;: 256,</span><br><span class="line">                               &#x27;min&#x27;: 32,</span><br><span class="line">                               &#x27;q&#x27;: 8&#125;,</span><br><span class="line">                &#x27;dropout&#x27;: &#123;&#x27;values&#x27;: [0.3, 0.4, 0.5]&#125;,</span><br><span class="line">                &#x27;epochs&#x27;: &#123;&#x27;value&#x27;: 1&#125;,</span><br><span class="line">                &#x27;fc_layer_size&#x27;: &#123;&#x27;values&#x27;: [128, 256, 512]&#125;,</span><br><span class="line">                &#x27;learning_rate&#x27;: &#123;&#x27;distribution&#x27;: &#x27;uniform&#x27;,</span><br><span class="line">                                  &#x27;max&#x27;: 0.1,</span><br><span class="line">                                  &#x27;min&#x27;: 0&#125;,</span><br><span class="line">                &#x27;optimizer&#x27;: &#123;&#x27;values&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;]&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>早停及其他设置等：</li>
</ul>
<p><a href="https://docs.wandb.com/sweeps/configuration#stopping-criteria">https://docs.wandb.com/sweeps/configuration#stopping-criteria</a></p>
<h3 id="2-initialize-the-Sweep"><a href="#2-initialize-the-Sweep" class="headerlink" title="2. initialize the Sweep"></a>2. initialize the Sweep</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sweep_id = wandb.sweep(sweep_config, project=<span class="string">&quot;pytorch-sweeps-demo&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-run-the-Sweep-agent"><a href="#3-run-the-Sweep-agent" class="headerlink" title="3. run the Sweep agent"></a>3. run the Sweep agent</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">config=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># Initialize a new wandb run</span></span><br><span class="line">    <span class="keyword">with</span> wandb.init(config=config):</span><br><span class="line">        <span class="comment"># If called by wandb.agent, as below,</span></span><br><span class="line">        <span class="comment"># this config will be set by Sweep Controller</span></span><br><span class="line">        config = wandb.config</span><br><span class="line"></span><br><span class="line">        loader = build_dataset(config.batch_size)</span><br><span class="line">        network = build_network(config.fc_layer_size, config.dropout)</span><br><span class="line">        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.epochs):</span><br><span class="line">            avg_loss = train_epoch(network, loader, optimizer)</span><br><span class="line">            wandb.log(&#123;<span class="string">&quot;loss&quot;</span>: avg_loss, <span class="string">&quot;epoch&quot;</span>: epoch&#125;)           </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">batch_size</span>):</span><br><span class="line">   </span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(),</span><br><span class="line">         transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line">    <span class="comment"># download MNIST training dataset</span></span><br><span class="line">    dataset = datasets.MNIST(<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                             transform=transform)</span><br><span class="line">    sub_dataset = torch.utils.data.Subset(</span><br><span class="line">        dataset, indices=<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(dataset), <span class="number">5</span>))</span><br><span class="line">    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_network</span>(<span class="params">fc_layer_size, dropout</span>):</span><br><span class="line">    network = nn.Sequential(  <span class="comment"># fully-connected, single hidden layer</span></span><br><span class="line">        nn.Flatten(),</span><br><span class="line">        nn.Linear(<span class="number">784</span>, fc_layer_size), nn.ReLU(),</span><br><span class="line">        nn.Dropout(dropout),</span><br><span class="line">        nn.Linear(fc_layer_size, <span class="number">10</span>),</span><br><span class="line">        nn.LogSoftmax(dim=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> network.to(device)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_optimizer</span>(<span class="params">network, optimizer, learning_rate</span>):</span><br><span class="line">    <span class="keyword">if</span> optimizer == <span class="string">&quot;sgd&quot;</span>:</span><br><span class="line">        optimizer = optim.SGD(network.parameters(),</span><br><span class="line">                              lr=learning_rate, momentum=<span class="number">0.9</span>)</span><br><span class="line">    <span class="keyword">elif</span> optimizer == <span class="string">&quot;adam&quot;</span>:</span><br><span class="line">        optimizer = optim.Adam(network.parameters(),</span><br><span class="line">                               lr=learning_rate)</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">network, loader, optimizer</span>):</span><br><span class="line">    cumu_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ➡ Forward pass</span></span><br><span class="line">        loss = F.nll_loss(network(data), target)</span><br><span class="line">        cumu_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ⬅ Backward pass + weight update</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        wandb.log(&#123;<span class="string">&quot;batch loss&quot;</span>: loss.item()&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cumu_loss / <span class="built_in">len</span>(loader)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wandb.agent(sweep_id, train, count=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><p>去url查看即可</p>
<h4 id="Parallel-Coordinates-Plot"><a href="#Parallel-Coordinates-Plot" class="headerlink" title="Parallel Coordinates Plot"></a>Parallel Coordinates Plot</h4><p>​        将超参数值映射到模型度量。</p>
<p>​        面板左侧可以选择对某些run进行隐藏，隐藏之后，【并行关联plot】和后面说到的【参数重要性plot】中都会隐藏和排除那些run。</p>
<p>​        <img src="/posts/bad385cb/image-20230321163057544.png" style="zoom:67%;"></p>
<h4 id="超参数重要性"><a href="#超参数重要性" class="headerlink" title="超参数重要性"></a>超参数重要性</h4><p>Hyperparameter Importance Plot</p>
<p>​    超参数的重要性图浮现了哪些超参数是你的指标的最佳预测因素。报告特征重要性（来自随机森林模型）和相关性（隐含线性模型）。</p>
<p>​    <a href="https://docs.wandb.ai/guides/app/features/panels/parameter-importance?_gl=1*1fibtjr*_ga*MTA4ODY1MjM2Ni4xNjc5MjgyNTkw*_ga_JH1SJHJQXJ*MTY3OTQ3NTQ0OS4xNi4xLjE2Nzk0NzYwMTguNTIuMC4w">Parameter Importance | Weights &amp; Biases Documentation (wandb.ai)</a></p>
<p><img src="/posts/bad385cb/image-20230322171329626.png" alt></p>
<blockquote>
<p>重要性列</p>
<p><u>显示了每个高参数在预测所选度量方面有用的程度。</u>我们可以想象一种场景，首先要调整大量的超参数，并利用这种情节来磨练哪些<strong>值得进一步的探索</strong>。然后，<strong>随后的扫描可能仅限于最重要的超参数</strong>，从而更快，更便宜。</p>
<p>注意：我们使用基于树的模型而不是线性模型来计算这些重要性，因为前者对分类数据和不归一化的数据更有宽容度。</p>
<p>在下一步中，我们可能会再次扫荡探索这些超参数的更多细粒度值。有趣的是，尽管Learning_rate和batch_size很重要，但它们与输出的相关性并不很好。这就引入到我们说的【相关性】。</p>
<p>相关性</p>
<p><u>捕获单个超参数和度量值之间的线性关系。</u>他们回答了这个问题 : 使用超参数（例如SGD Optimizer）和我的Val_loss（在这种情况下的答案是肯定的）之间是否存在显着关系。相关值范围为-1到1，其中<strong>正值代表正线性相关，负值代表负线性相关，值为0表示无相关。通常，在任一方向上大于0.7的值表示强相关。</strong></p>
<p>我们可能会使用此图来进一步探索与我们的度量相关性较高相关的值（在这种情况下，我们可能会选择随机梯度下降，或者在RMSPROP或NADAM上选择ADAM）或训练更多时代。</p>
<p>关于解释相关性需要注意的地方：</p>
<ul>
<li><p>相关性显示了关联的证据，不一定是因果关系。</p>
</li>
<li><p>相关性对离群值敏感，离群值可能会将牢固的关系转化为中等的关系，特别是如果尝试的超参数的样本量很小，则可能会将其变为中间的异常值。</p>
</li>
<li><p>最后，相关仅捕获超参数和指标之间的线性关系。如果存在牢固的多项式关系，则不会被相关性捕获。</p>
</li>
</ul>
<p>重要性与相关性之间的差异是由于<u>重要性解释了超参数之间的相互作用</u>，而<u>相关性仅测量单个超参数对度量值的影响</u>。其次，<strong>相关仅捕获线性关系，而重要性可以捕获更复杂的关系。</strong></p>
<p>如您所见，重要性和相关性是了解超参数如何影响模型性能的强大工具。</p>
</blockquote>
<h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><ol>
<li>config可选项，包括early stop ,scheduler等</li>
<li><code>bayesian Search</code></li>
</ol>
<h2 id="bug记录"><a href="#bug记录" class="headerlink" title="bug记录"></a>bug记录</h2><ul>
<li><p>运行有时候还是会出现process communicating error，解决方案参见前一篇文章。具体修改<code>with wandb.init():</code></p>
</li>
<li><p>自己的错误：由于自己训练模型的时候有<code>import train from train</code> (自定义的方法)，而此次使用sweep又def 了一个train（），与train同名，产生错误。</p>
</li>
<li><p>network error</p>
<p>即使我fork了之后，sweep过程中，总是有几次会network error，随后报错process communicating failed。虽然其会继续下一次的实验，但是这样很影响。</p>
<p><a href="https://blog.csdn.net/weixin_41978699/article/details/122794205">wandb: Network error (ConnectionError), entering retry loop._harry_tea的博客-CSDN博客</a></p>
<p>解决方式1：offline 部署</p>
</li>
</ul>
<h3 id="offline部署"><a href="#offline部署" class="headerlink" title="offline部署"></a>offline部署</h3><ol>
<li>在文件开头加上</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;WANDB_API_KEY&quot;</span>] = YOUR_KEY_HERE</span><br><span class="line">os.environ[<span class="string">&quot;WANDB_MODE&quot;</span>] = <span class="string">&quot;offline&quot;</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>最后训练完后会出现<code>wandb sync wandb/xxx</code>，按照提示同步即可</p>
<p>shell命令执行</p>
</li>
</ol>
<p><a href="https://docs.wandb.ai/ref/cli/wandb-sync">wandb sync | Weights &amp; Biases Documentation</a></p>
<ul>
<li><p>我offline跑sweep,然后把所有的run wandb sync，发现错误。sweep不正常</p>
<ol>
<li><p>metric未和log里的名称对应，注意，对应的是name之间的对应，而不是value的变量名！</p>
</li>
<li><p>offline的情况下出现其他问题（sync之后只能找到4/10个run)</p>
</li>
</ol>
</li>
<li><p>此外，在offline sync过程中，有时候会出现network error，过一会就能走了（retry loop)</p>
</li>
</ul>
<h3 id="online-记录"><a href="#online-记录" class="headerlink" title="online 记录"></a>online 记录</h3><ul>
<li>online跑，wandb.init() <code>reinit=True</code>这一参数没有设置，并且设置<code>setting=wandb.Settings(start_method=(&quot;thread&quot;))</code>，成功运行中</li>
</ul>
]]></content>
      <categories>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>wandb</tag>
      </tags>
  </entry>
  <entry>
    <title>使用wandb可视化</title>
    <url>/posts/aa8baae/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="wandb"><a href="#wandb" class="headerlink" title="wandb"></a>wandb</h2><blockquote>
<p> wandb是 <strong>Weights &amp; Biases</strong> 的缩写，这款工具能够帮助跟踪你的机器学习项目。 它能够自动记录模型训练过程中的超参数和输出指标，然后可视化和比较结果，并快速与同事共享结果。</p>
</blockquote>
<p>官网文档：<a href="https://docs.wandb.ai/">What is Weights &amp; Biases? | Weights &amp; Biases Documentation (wandb.ai)</a></p>
<h2 id="简单使用操作"><a href="#简单使用操作" class="headerlink" title="简单使用操作"></a>简单使用操作</h2><span id="more"></span>
<h3 id="0-注册wandb账号，并获取api-key"><a href="#0-注册wandb账号，并获取api-key" class="headerlink" title="0. 注册wandb账号，并获取api key"></a>0. 注册wandb账号，并获取api key</h3><ul>
<li>在官网注册账号：<a href="https://wandb.ai/">Weights &amp; Biases (wandb.ai)</a> （github账号即可注册）</li>
<li>获取api key（按照官网引导即可）<ul>
<li>api key后续要用到</li>
</ul>
</li>
</ul>
<h3 id="1-set-up"><a href="#1-set-up" class="headerlink" title="1. set up"></a>1. set up</h3><ul>
<li><p>pip安装</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install wandb</span><br></pre></td></tr></table></figure>
</li>
<li><p>登录wandb</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">wandb login</span><br></pre></td></tr></table></figure>
<p>会提示输入api key。如果已经登录过了，想要重新登录，则使用relogin</p>
</li>
</ul>
<h3 id="2-在代码中配置"><a href="#2-在代码中配置" class="headerlink" title="2. 在代码中配置"></a>2. 在代码中配置</h3><ul>
<li><p>导入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化新的 W&amp;B 运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">config = &#123;&#125; <span class="comment">#实验设置，如lr等。wandb.init传入conifg,实际上只是用于显示标识自己设置的参数。</span></span><br><span class="line">wandb.init(project=<span class="string">&quot;project_name&quot;</span>，config= config)</span><br></pre></td></tr></table></figure>
</li>
<li><p>跟踪指标</p>
<p>train_acc为代码epoch中实际的变量。通过该命令，可以绘制出指标变化图像。也可以记录自己想要的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wandb.log(&#123;<span class="string">&#x27;accuracy&#x27;</span>: train_acc, <span class="string">&#x27;loss&#x27;</span>: train_loss&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>关于权重梯度等的显示</strong></p>
</li>
</ul>
<p>​        一行简单的命令即可：    </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wandb.watch(model, log=&#x27;all&#x27;)</span><br></pre></td></tr></table></figure>
<p>​        加载模型定义完之后。</p>
<ul>
<li><p>最后</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wandb.finish()</span><br></pre></td></tr></table></figure>
<p>jupyter book必须加，其他可选。</p>
</li>
</ul>
<h3 id="3-运行代码"><a href="#3-运行代码" class="headerlink" title="3.运行代码"></a>3.运行代码</h3><ul>
<li><p>运行自己的代码</p>
</li>
<li><p>控制台会显示结果可视化在云端的哪个链接。每次run都会保留一个log在本地。</p>
</li>
</ul>
<p><img src="/posts/aa8baae/image-20230321151113119.png" alt style="zoom:67%;"></p>
<h3 id="4-可视化结果展示"><a href="#4-可视化结果展示" class="headerlink" title="4. 可视化结果展示"></a>4. 可视化结果展示</h3><p>进入project下对应run的链接</p>
<ul>
<li>charts为前面通过log命令跟踪的指标</li>
</ul>
<p><img src="/posts/aa8baae/image-20230321150645567.png" alt style="zoom: 67%;"></p>
<ul>
<li><p>通过watch我们可以看到梯度和权重！</p>
<p><img src="/posts/aa8baae/image-20230321150827903.png" alt style="zoom:67%;"></p>
</li>
</ul>
<p><img src="/posts/aa8baae/image-20230321150911169.png" alt style="zoom:67%;"></p>
<h2 id="完整代码示例"><a href="#完整代码示例" class="headerlink" title="完整代码示例"></a>完整代码示例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># !usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding:UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># @Author:</span></span><br><span class="line"><span class="comment"># @File:wandb_gra.py</span></span><br><span class="line"><span class="comment"># @Time:2023-03-20 13:51</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> 文件说明：</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> &quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> CNN_Net</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, device, train_loader, optimizer, epoch</span>):</span><br><span class="line"> model.train()</span><br><span class="line"></span><br><span class="line"> n_ex = <span class="built_in">len</span>(train_loader)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>(train_loader), total=n_ex):</span><br><span class="line">  data, target = data.to(device), target.to(device)</span><br><span class="line">  optimizer.zero_grad()</span><br><span class="line">  output = model(data)</span><br><span class="line">  loss = F.nll_loss(output, target)</span><br><span class="line">  loss.backward()</span><br><span class="line">  optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, device, test_loader</span>):</span><br><span class="line"> model.<span class="built_in">eval</span>()</span><br><span class="line"> test_loss = <span class="number">0</span></span><br><span class="line"> correct = <span class="number">0</span></span><br><span class="line"> <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">  <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">   data, target = data.to(device), target.to(device)</span><br><span class="line">   output = model(data)</span><br><span class="line">   test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()</span><br><span class="line">   pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">   correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"> test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line"> tqdm.write(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">  test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">  <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line"><span class="comment">##注意</span></span><br><span class="line"> wandb.log(&#123;<span class="string">&#x27;test_loss&#x27;</span>: test_loss,</span><br><span class="line">             <span class="string">&#x27;accuracy&#x27;</span>: correct / <span class="built_in">len</span>(test_loader.dataset)&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"> config = &#123;</span><br><span class="line">  <span class="string">&#x27;BATCH_SIZE&#x27;</span>: <span class="number">64</span>,</span><br><span class="line">  <span class="string">&#x27;TEST_BATCH_SIZE&#x27;</span>: <span class="number">1000</span>,</span><br><span class="line">  <span class="string">&#x27;EPOCHS&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="string">&#x27;LR&#x27;</span>: <span class="number">0.01</span>,</span><br><span class="line">  <span class="string">&#x27;MOMENTUM&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">&#x27;SEED&#x27;</span>: <span class="number">17</span>,</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"><span class="comment">##注意</span></span><br><span class="line"> wandb.init(project=<span class="string">&#x27;explore-gradients&#x27;</span>, reinit=<span class="literal">True</span>, config=config)</span><br><span class="line"></span><br><span class="line"> use_cuda = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"> torch.manual_seed(config[<span class="string">&#x27;SEED&#x27;</span>])</span><br><span class="line"></span><br><span class="line"> device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"> kwargs = &#123;<span class="string">&#x27;num_workers&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pin_memory&#x27;</span>: <span class="literal">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"> train_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                 transform=transforms.Compose([</span><br><span class="line">                  transforms.ToTensor(),</span><br><span class="line">                  transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                 ])),</span><br><span class="line">  batch_size=config[<span class="string">&#x27;BATCH_SIZE&#x27;</span>], shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"> test_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">&#x27;../data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">   transforms.ToTensor(),</span><br><span class="line">   transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">  ])),</span><br><span class="line">  batch_size=config[<span class="string">&#x27;TEST_BATCH_SIZE&#x27;</span>], shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"> model = CNN_Net().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">##注意</span></span><br><span class="line"> wandb.watch(model, log=<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line"></span><br><span class="line"> optimizer = optim.SGD(model.parameters(),</span><br><span class="line">                       lr=config[<span class="string">&#x27;LR&#x27;</span>],</span><br><span class="line">                       momentum=config[<span class="string">&#x27;MOMENTUM&#x27;</span>])</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, config[<span class="string">&#x27;EPOCHS&#x27;</span>] + <span class="number">1</span>):</span><br><span class="line">  train(model, device, train_loader, optimizer, epoch)</span><br><span class="line">  test(model, device, test_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line"> main()</span><br></pre></td></tr></table></figure>
<h2 id="bug记录"><a href="#bug记录" class="headerlink" title="bug记录"></a>bug记录</h2><ul>
<li>如果出现process communicating error:</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wandb.init(project=<span class="string">&#x27;project_name&#x27;</span>, reinit=<span class="literal">True</span>, config=config,setting=wandb.Settings(start_method=(<span class="string">&quot;fork&quot;</span>)))</span><br></pre></td></tr></table></figure>
<p>特定版本以上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wandb.init(project=<span class="string">&#x27;explore-gradients&#x27;</span>, reinit=<span class="literal">True</span>, config=config,setting=wandb.Settings(start_method=(<span class="string">&quot;thread&quot;</span>)))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>wandb</tag>
      </tags>
  </entry>
  <entry>
    <title>CLIP-TSA:CLIP-Assisted Temporal Self-Attention</title>
    <url>/posts/d3b330ab/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://arxiv.org/pdf/2212.05136.pdf">paper</a> (Under Submission CVPR)</p>
<span id="more"></span>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>解决VAD问题：由于劳动密集型性质（帧级别的标注？），通常以弱监督的方式表述为多实例学习问题(MIL）。</p>
<ul>
<li>相比该领域传统使用的C3D和I3D模型，我们使用ViT-encoded visual features from CLIP，以使用一种创新的方式来有效地提取判别表示。</li>
<li>model long- and short-range temporal dependencies， 并使用时间自注意力机制（TSA）来提取重要的片段（snipppets of interest)</li>
<li>进行了消融实验，实验表明我们提出的CLIP-TSA 在广泛使用的两个benchmark数据集（<strong>UCF-Crmie和ShanghaiTec</strong>)大范围的优于SOTA</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>分别介绍了有监督、无监督和弱监督（基于MIL框架）的VAD方法的优缺点。</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol>
<li><p>弱监督方法的<strong>已有提取视频特征骨架C3D、I3D和2Stream的缺陷（它们是在动作识别任务上预训练的）：</strong></p>
<p>与动作识别问题不同，VAD依赖于清晰地表示场景中的事件的区别性表征。因此，由于领域的鸿沟（domain gap)，这些骨架并不合适[1])。</p>
</li>
<li><p>已有的MIL-based弱监督VAD受限于应对 <strong>异常视频中包含任意数量的异常片段</strong></p>
</li>
</ol>
<h3 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h3><ol>
<li><p>针对性提出解决方案：使用CLIP进行特征提取。</p>
<p><strong>CLIP的优势</strong>及其为什么能够有效：</p>
<p>最近（21-23）”vision language”工作的成功证明了通过CLIP（Contrastive Language-Image Pre-traning)框架学习到的特征表示的有效性。</p>
<p>CLIP由两个网络组成：vision encoder 和 text encoder ， 在互联网公开可用资源收集到的400 million text-image pairs上训练。给定一组words和一张图片，CLIP可以评估他们之间的语义相似性。</p>
<p>因此，我们使用CLIP作为特征提取器。</p>
</li>
<li><p>提出top-k function</p>
<p>受differentiable top-k operator[2]的启发，提出top-k function, 它定位了视频中感兴趣的κ个片段，并在相似的MIL 设置中采用 differentiable hard attention，以证明其对传统的、流行的设置的有效性和适用性。</p>
</li>
<li><p>引入Temporal Self-attention机制（TSA）</p>
<p>目标是通过衡量片段的异常程度生成重新赋权的注意力特征（reweighted attention feature)</p>
</li>
</ol>
<p>提出的CLIP-TSA采用MIL框架，由三个组件构成：</p>
<p>（1） 使用CLIP进行的特征编码</p>
<p>（2）使用TSA机制在时间维度上进行片段一致性建模</p>
<p>（3） 使用差异最大化训练器定位异常片段</p>
<p>三个评估数据集：UCF-Crime, ShanghaiTec和XD-Violence</p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li>提出适用于弱监督VAD问题的Temporal Self-Attention(TSA)机制，并获得了视频片段的异常似然性得分。</li>
<li>我们运用CLIP，它使用ViT作为视觉特征的主干，引入了1)CLIP特征的新用法，2)分析由异常动作组成的视频中的新型上下文表示</li>
<li>经验性地验证了我们提出方法的有效性，结果表明：据我们所知，在任何类型的监督设置下，它实现了比目前所有以UCF-Crime和ShanghaiTec数据集为基准的SOTA方法更优的性能。对于XD-violence数据集，他打败了不融合声音特征进行训练的SOTA</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>Unsupervised VAD</li>
<li>Weakly-supervised VAD</li>
<li>Vision-Language Pre-trained Models</li>
<li>Attention Mechanism</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>pipeline如下：</p>
<p><img src="/posts/d3b330ab/Untitled.png" alt></p>
<p>（1） 使用CLIP进行的特征编码</p>
<p>（2）使用TSA机制在时间维度上进行片段一致性建模，并下选取关联最多的top-k个</p>
<p>（3） 使用差异最大化训练器定位异常片段</p>
<h3 id="feature-embedding"><a href="#feature-embedding" class="headerlink" title="feature embedding"></a>feature embedding</h3><ul>
<li><p>choose the middle frame $I_i$ that represents each snippet $s_i$</p>
</li>
<li><p>encode frame $I_i$ with the pretrained Vision Transformer to extract visual feature $I_i^f$</p>
</li>
<li><p>then project feature $I_i^f$ onto the visual projection matrix L, which was pretrained by CLIP to obtain the image embedding $f_i = L*I_i^f$</p>
</li>
<li><p>thus got the embedding feature $F_k$  of video X, which consist of  snippets    </p>
<script type="math/tex; mode=display">X = \{s_i\}|^{T_k}_{i=1}</script></li>
<li><p>finally apply the video normalization</p>
</li>
</ul>
<h3 id="Temporal-Self-Attention-TSA"><a href="#Temporal-Self-Attention-TSA" class="headerlink" title="Temporal Self-Attention (TSA)"></a><strong>Temporal Self-Attention (TSA)</strong></h3><p>目标：model the coherency between snippets of a video and select the top-k most relevant snippets</p>
<p>组成： (i) temporal scorer network： 获取score向量。将feature变成score向量（$R^{T\times 1}$) ，论文里网络为三层MLP</p>
<p>(ii) top-<em>κ</em> score nominator：提取K个关联性最大的片段。具体见如下算法二。有借助高斯噪声、基于分数幅度获取top-k个、one-hot编码（Through the soft one-hot encoding mechanism, the higher amount of attention, or weight, is placed near and at the indices of top-<em>κ</em> scores）</p>
<p>(iii) fusion network： combine information</p>
<p>输入：前述基于CLIP提取到的特征</p>
<p>输出：reweighted attention Feature</p>
<p><img src="/posts/d3b330ab/Untitled 1.png" alt></p>
<p><img src="/posts/d3b330ab/Untitled 2.png" alt></p>
<h3 id="Difference-Maximization-Trainer-Learning"><a href="#Difference-Maximization-Trainer-Learning" class="headerlink" title="Difference Maximization Trainer Learning"></a><strong>Difference Maximization Trainer Learning</strong></h3><p>mini batch训练，输入分成2*B（batchsize)，一半从normal bags中加载，一半从abnormal bags中加载。</p>
<p>在TSA阶段之后，分别得到两部分的reweighted attention feature。</p>
<p>接着，将feature送入一个卷积网络模块J，J由dilated convolutions和non-local block组成，以此基于重新加权的大小模拟片段之间的长期和短期关系。</p>
<p>输出的convoluted attention features接着送入一个浅层的MIL-based score classifier，输出的分数决定特征片段的二元异常状态。</p>
<ul>
<li><p>每个convoluted attention features执行 Difference Maximization Trainer (DMT)</p>
<p>基于特征幅度选取top-a个特征，定义loss将异常片段明显区分于正常片段，具体过程与<a href="https://arxiv.org/pdf/2101.10030.pdf">RTFM</a>论文的类似。</p>
</li>
</ul>
<h3 id="Infer"><a href="#Infer" class="headerlink" title="Infer"></a>Infer</h3><p>测试阶段不执行normlization。</p>
<p>分类器最后得到的一组分数U，每个分数$u_i$表示对应index的异常相似度，值为0-1之间。$u_i$被四舍五入取得二元分数，1代表异常，0代表正常。</p>
<p>能够进行帧级别的测试：片段的score（对应片段级结果）保留原始顺序，repeat $\delta$次。</p>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a><strong>Experimental Results</strong></h2><p>数据集：<strong>UCF-Crime Dataset、ShanghaiTech Campus Dataset、XD-Violence Dataset</strong></p>
<p>指标：AUC@ROC（<strong>UCF-Crime、ShanghaiTech）</strong>、AUC@PR（<strong>XD-Violence）</strong></p>
<h3 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a><strong>Performance Comparison</strong></h3><p><img src="/posts/d3b330ab/Untitled 3.png" style="zoom:80%;"></p>
<p><img src="/posts/d3b330ab/Untitled 4.png" style="zoom: 80%;"></p>
<p><img src="/posts/d3b330ab/Untitled 5.png" style="zoom:80%;"></p>
<h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a><strong>Ablation Study</strong></h3><ul>
<li>TSA机制的有效性：</li>
</ul>
<p><img src="/posts/d3b330ab/Untitled 6.png" style="zoom:80%;"></p>
<ul>
<li>K的参数选择</li>
</ul>
<p>其中，分析的是超参r</p>
<p><img src="/posts/d3b330ab/Untitled 7.png" alt style="zoom: 80%;"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>UCF-Crime</th>
<th>ShanghaiTec</th>
<th>XD-violence</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.7</td>
<td>[0.3,0.7]</td>
<td>0.9</td>
</tr>
</tbody>
</table>
</div>
<p>作者通过分析数据分布，来解释最优r值在不同数据集之间不同的原因：</p>
<p>信息：1）data distribution of UCF-Crime (1,900 videos with 13 types of anomalies), ShanghaiTech Campus (317,398 videos with 130 anomaly events), and XD-Violence (4,754 videos with 6 types of anomalies) datasets</p>
<p>2）frame-level <strong><em>anomaly-to-all ratio</em></strong> of their test sets, which are 0.1819, 0.4247, and 0.4977,</p>
<p><img src="/posts/d3b330ab/Untitled 8.png" alt></p>
<p>基于信息给到的分析：</p>
<p>ShanghaiTec是一个具有较多异常事件的大尺度数据，因此我们假设该模型具有足够的泛化性，因此，值设为[0.3,0.7]在<strong><em>anomaly-to-all ratio</em></strong>  附近。</p>
<p>而UCF-Crime和XD-Violence具有不平衡的类分布。此外，做良好判别的决策所依赖的重要特征，不仅限于异常片段，也包括了一些正常片段，特别是作为损失计算的一部分，其中异常top片段和正常片段的幅度都被考虑在内。因此，这两个数据集的最好r不分布在<strong><em>anomaly-to-all ratio</em></strong>附近。</p>
<p><img src="/posts/d3b330ab/Untitled 9.png" style="zoom:80%;"></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>本文提出了一种有效的端到端弱监督VAD框架CLIP-TSA。具体地说，我们提出了一种新的TSA机制，它可以在最小限度的情况下最大化对特征子集的注意力关注噪声，并显示了其对弱监督VAD问题的适用性。我们还将TSA应用于clip提取的特征，以证明其对视觉语言特征的有效性，并在弱监督的VAD问题中利用视觉语言特征。通过将我们的数据集与sota进行比较，我们还通过经验验证了我们的模型在VAD的三个流行数据集上的卓越性。</p>
<p>未来的研究可能着眼于更好的技术，以结合时间和空间信息，并以较少的注释处理不平衡的数据。</p>
<p>像 Li 等人 (2022)[3]这样的注意力技术 和自监督学习 (Caron 等人, 2021; Chen 等人, 2020a) 也是提高性能的潜在扩展。</p>
<p>引用：</p>
<p>[1] Kun Liu and Huadong Ma. Exploring background-bias for anomaly detection in surveillance videos. In <em>Proceedings of the 27th ACM International Conference on Multimedia</em>, pp. 1490–1499, 2019.</p>
<p>[2] Jean-Baptiste Cordonnier, Aravindh Mahendran, Alexey Dosovitskiy, Dirk Weissenborn, Jakob Uszkoreit, and Thomas Unterthiner. Differentiable patch selection for image recognition. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 2351–2360, June 2021.</p>
<p>[3] Yehao Li, Ting Yao, Yingwei Pan, and Tao Mei. Contextual transformer networks for visual recognition. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2022.</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>VAD</tag>
        <tag>弱监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>How Attentive are Graph Attention Networks</title>
    <url>/posts/82187def/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><a href="https://arxiv.org/pdf/2105.14491.pdf">paper地址</a> (ICLR2022)</p>
<p><a href="https://openreview.net/forum?id=F72ximsx7C1">How Attentive are Graph Attention Networks? openreview</a></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><span id="more"></span>
<p>GAT：</p>
<ul>
<li><p>在GAT中，每个节点关注它的邻居，并将自己的representation作为query。</p>
</li>
<li><p>limitation:</p>
<p>在本文中，我们证明了GAT计算的是一种非常有限的attention: attention scores的排序在query node上是无条件的。（即，注意力分数的排序不因query node而异）</p>
<ul>
<li><p>将上述的这种有限的注意力定义为静态注意力（<strong><em>static attention</em></strong>)，并将其与表示更丰富的动态注意力相区分。</p>
</li>
<li><p>由于GAT使用的是静态注意力，因此存在一些他不能表达的简单图问题：</p>
<p>在一个受控的问题中，我们表明静态注意力甚至阻碍GAT与训练数据拟合。（见4.1节）</p>
</li>
</ul>
</li>
</ul>
<p>提出GATv2：</p>
<ul>
<li>为了解决上述局限性，我们通过修改操作顺序，引入了一个简单的修复办法，并提出了GATv2：一种严格来说比GAT更富表达力的变体。</li>
<li>进行了广泛的评估，并表明GATv2在12个OGB和其他基准测试上优于GAT，同时我们匹配了它们的参数成本。</li>
<li>代码：<a href="https://github.com/tech-srl/how_attentive_are_gats；GATv2作为PyTorch">https://github.com/tech-srl/how_attentive_are_gats；GATv2作为PyTorch</a> Geometric library，the Deep Graph Library and the TensorFlow GNN library的一部分可用。</li>
</ul>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ul>
<li>Velickovi ˇ c et al. (2018) 提出GAT。</li>
</ul>
<p>在GAT中，每个节点用它自己的表示作为query来关注/处理（attend to)其邻居以更新自己的表示。</p>
<p>这泛化了标准的平均或最大池化邻居（Kipf和Welling，2017; Hamilton等，2017）→ 通过允许每个节点计算其邻居的加权平均值，并（softly）选择其最相关的邻居。</p>
<p>Velickovi ˇ c et al.也将transformer的自注意力机制从序列泛化到图。</p>
<ul>
<li><p>GAT执行一种静态注意力</p>
<p>对于任何查询节点，注意函数相对于邻居（key）分数是单调的。也就是说，<strong>注意系数的排序（目标排序）在图中的所有节点上共享，并且在查询节点上不受影响（即不因查询节点而异）。</strong></p>
<p>该事实损伤了GAT的表现力。</p>
</li>
</ul>
<h3 id="静态注意力"><a href="#静态注意力" class="headerlink" title="静态注意力"></a>静态注意力</h3><p>静态注意力：对于任何 query nodes，注意函数相对于邻域（key）分数是单调的。即：注意系数的排序在图中的所有节点上共享，并且在查询节点上不受条件的影响。如 Figure1 所示：</p>
<p><img src="/posts/82187def/Untitled.png" style="zoom:90%;"></p>
<p>由上面图可以看出，第一幅图就是静态注意力，第二幅图是动态注意力。</p>
<p>第一幅图中每个查询节点q对【k0,k1…k9】计算注意力系数时，都是k8的注意力分数最大，也就是无论q是什么，k8的贡献都是相对最大的。为了解决这个问题，作者提出了GATv2来使用动态注意力，如第二幅图，每个query有对于所有key不同的attention系数的排序</p>
<h2 id="2-PRELIMINARIES"><a href="#2-PRELIMINARIES" class="headerlink" title="2. PRELIMINARIES"></a>2. PRELIMINARIES</h2><ul>
<li><p>GNN</p>
<script type="math/tex; mode=display">
h'_i = f_θ (h_i, AGGREGATE ({h_j | j ∈ N_i}))</script></li>
<li><p>GAT</p>
<p>A scoring function <em>e</em> 对于每一个边 （j,i) 计算socre，表示邻居j的特征对节点i的重要性：</p>
<script type="math/tex; mode=display">
e (h_i, h_j ) = LeakyReLU(a^T · [W h_i||W h_j ])  \quad\quad(2)</script><p>$a ∈ R^{2d’} , W ∈ R^{d’×d}$，为可学习参数。||表示concatenation。这些注意力分数在所有邻居$j\in N_i$之间使用softmax normalized，定义得到注意力函数为：</p>
<script type="math/tex; mode=display">
α_{ij} = softmax_j (e (h_i, h_j )) = \frac{exp (e (h_i, h_j ))
}{\sum _{j'∈N_i}exp (e (h_i, h_j' ))}\quad\quad (3)</script><p>然后，GAT使用归一化注意系数计算相邻节点的转换特征（接着用一个非线性σ）的加权平均值，作为i的新表示：</p>
<script type="math/tex; mode=display">
h_i' = σ (\sum _{j∈N_i} α_{ij} · W h_j) \quad\quad (4)</script></li>
</ul>
<h2 id="3-THE-EXPRESSIVE-POWER-OF-GRAPH-ATTENTION-MECHANISMS"><a href="#3-THE-EXPRESSIVE-POWER-OF-GRAPH-ATTENTION-MECHANISMS" class="headerlink" title="3. THE EXPRESSIVE POWER OF GRAPH ATTENTION MECHANISMS"></a>3. THE EXPRESSIVE POWER OF GRAPH ATTENTION MECHANISMS</h2><h3 id="3-1-THE-IMPORTANCE-OF-DYNAMIC-WEIGHTING"><a href="#3-1-THE-IMPORTANCE-OF-DYNAMIC-WEIGHTING" class="headerlink" title="3.1 THE IMPORTANCE OF DYNAMIC WEIGHTING"></a>3.1 THE IMPORTANCE OF DYNAMIC WEIGHTING</h3><p>回答Q：为什么不是动态会限制attention呢？</p>
<ul>
<li><p>Attention</p>
<p>Attention: Attention是一种机制，它给定一个额外的查询向量（query vector)来计算一组输入key向量的分布。</p>
<p>如果attention函数总是将一个key的权重计算的至少与其他任何key一样大，而与query无关，那么我们称他为<strong>static attention</strong>（即不管query是什么，计算的一组key里面，最大的（不小于其他key) 那个是定死的）</p>
</li>
<li><p><strong>Definition 3.1</strong> （<strong>static attention</strong>)</p>
<p>A (possibly infinite) family of scoring functions <em>F ⊆ (</em>R<em>d ×</em> R<em>d →</em> R) computes <em>static scoring</em> for a given set of key vectors <script type="math/tex">K=\{k_1, ...,k_n\} ⊂R^d</script> and query vectors <script type="math/tex">Q =\{q_1, ..., q_m\} ⊂R^d</script>, if for every <script type="math/tex">f \in F</script> there exists a “highest scoring” key <script type="math/tex">j_f∈ [n]</script> such that for every query i∈[m] and key j∈ [n] it holds that <script type="math/tex">f(q_i,k_{j_f})\ge f(q_i,k_j)</script>. We say that a family of attention functions computes <em>static attention</em> given K and Q , if its scoring function computes static scoring, possibly followed by monotonic normalization such as softmax.</p>
</li>
<li><p>静态注意力非常有限</p>
<p>静态注意非常有限，因为无论查询如何，每个函数$f\in F$都有一个总是选中的key。这些函数不能模拟不同key对不同query有不同关联的情况。</p>
</li>
<li><p><strong>Defifinition 3.2</strong> (<strong>Dynamic attention</strong>)</p>
<p>A (possibly infifinite) family of scoring functions <em>F ⊆ (</em>R<em>d ×</em> R<em>d →</em> R) computes <em>dynamic attention</em> for a given set  of key vectors <script type="math/tex">K=\{k_1, ...,k_n\} ⊂R^d</script> and <script type="math/tex">Q =\{q_1, ..., q_m\} ⊂R^d</script>,  if for any mapping $\phi: [m] → [n]$ , there exists $f \in F$ such that for any query <script type="math/tex">i\in [m]</script> and any key <script type="math/tex">j _{\neq \phi(i)} \in [n]</script>: <script type="math/tex">f(q_i, k_ϕ(i)) > f(q_i, k_j)</script>. We say that a family of attention functions computes <em>dynamic attention</em> for K and Q, if its scoring function computes dynamic scoring, possibly followed by monotonic normalization such as softmax.</p>
<p>也就是说，动态注意可以通过查询i选择每个键ϕ(i)，使<script type="math/tex">f(q_i, k_ϕ(i))</script>在<script type="math/tex">\{f（q_i，k_j）| j∈[n])\}</script>中最大。请注意，动态注意和静态注意都是排他性的属性，但它们并不是互补的。此外，每个动态注意族对于相同的K和Q都有严格的静态注意族子集。</p>
</li>
<li><p><strong>Attending by decaying</strong></p>
<p>另一种思考注意力的方式是“focus”于最相关的输入的能力。Focusing只能通过衰减其他输入，即，给出这些输入衰减的输入值的分数低于其他输入值。如果一个键的注意力得分总是比其他键相同或更高（如静态注意），那么任何查询都不能忽略这个键或衰减这个键的score.</p>
</li>
</ul>
<h3 id="3-2-THE-LIMITED-EXPRESSIVITY-OF-GAT"><a href="#3-2-THE-LIMITED-EXPRESSIVITY-OF-GAT" class="headerlink" title="3.2 THE LIMITED EXPRESSIVITY OF GAT"></a>3.2 THE LIMITED EXPRESSIVITY OF GAT</h3><p><strong>Theorem 1.</strong> <em>A GAT layer computes only static attention, for any set of node representations $K = Q = {h_1, …, h_n}$. In particular, for n &gt;</em> 1<em>, a GAT layer does not compute dynamic attention.</em></p>
<p>证明：</p>
<p><img src="/posts/82187def/Untitled 1.png" alt></p>
<p>定理1的结果是，对于任何一组节点V和训练的GAT层，注意函数α定义了一个节点的constant ranking（argsort），无论查询节点i是哪个。即，存在$s_j = a_2^T W h_j$, 我们可以对于任意选择的$h_i$, 得到α相对于每个节点的分数${sj | j∈V}$是单调的。这种全局排序引出了每个邻居群Ni的局部排序。 hi的唯一影响是在所产生的注意力分布的“锐度”上。这在图1a（底部）中得到了演示，其中不同的曲线表示不同的查询（hi）。</p>
<p><strong>Generalization to multi-head attention</strong></p>
<p>对于多头注意力机制，theorem1同样适用于每一个头，得到的输出是静态注意力头的拼接。</p>
<h3 id="3-3-BUILDING-DYNAMIC-GRAPH-ATTENTION-NETWORKS"><a href="#3-3-BUILDING-DYNAMIC-GRAPH-ATTENTION-NETWORKS" class="headerlink" title="3.3 BUILDING DYNAMIC GRAPH ATTENTION NETWORKS"></a>3.3 BUILDING DYNAMIC GRAPH ATTENTION NETWORKS</h3><p>standard GAT 评分函数（Eq.2）的主要问题是学习到的W和a是连续应用的，因此可以分解成一个单一的线性层。为了解决这个限制，我们简单地在非线性(LeakyReLU)之后应用a layer，在拼接之后应用W layer，有效地应用一个MLP来计算每个query-key对的分数：</p>
<script type="math/tex; mode=display">
GAT: \quad e (h_i, h_j ) = LeakyReLU(a^T · [W h_i||W h_j ]) \quad (6)</script><script type="math/tex; mode=display">
GATv2 (our\ fixed\ version):\quad e (h_i, h_j ) = a^T LeakyReLU( W · [ h_i||h_j ]) \quad (7)</script><p>简单的修改对注意功能的表达性有显著的影响：</p>
<p><strong>Theorem 2.</strong> <em>A GATv2 layer computes dynamic attention for any set of node representations  $K = Q = {h_1, …, h_n}$.</em></p>
<p>证明见附录A。主要思想是我们可以定义一个适当的函数，GATv2将是一个通用近似器（Cybenko，1989；Hornik，1991）。相比之下，GAT（式（52）)不能近似任何这样的期望的函数（定理1）。</p>
<p><strong>Complexity</strong></p>
<ul>
<li>时间复杂度</li>
</ul>
<p>both: $O (|V|dd’ + |E|d’)$，可以通过合并线性层减少。</p>
<ul>
<li>参数复杂度：</li>
</ul>
<p><img src="/posts/82187def/Untitled 2.png" alt></p>
<h2 id="4-EVALUATION"><a href="#4-EVALUATION" class="headerlink" title="4. EVALUATION"></a>4. EVALUATION</h2><p>首先，我们使用一个简单的合成问题（synthetic problem）来证明GAT的弱点，<strong>即GAT甚至不能拟合（甚至不能达到较高的训练精度）</strong>，但很容易通过GATv2来解决（第4.1节）。</p>
<p>第二，我们证明GATv2对边缘噪声更鲁棒，因为它的动态注意机制允许它衰减噪声（假）边缘，而GAT的性能随着噪声的增加而严重降低(第4.2节)。</p>
<p>最后，我们在12个基准测试中比较了GAT和GATv2。（第4.3至4.6节和附录D.3)。我们发现在所有测试GAT的基准测试中都不如GATv2。</p>
<h3 id="4-1-SYNTHETIC-BENCHMARK-DICTIONARYLOOKUP"><a href="#4-1-SYNTHETIC-BENCHMARK-DICTIONARYLOOKUP" class="headerlink" title="4.1 SYNTHETIC BENCHMARK: DICTIONARYLOOKUP"></a>4.1 SYNTHETIC BENCHMARK: DICTIONARYLOOKUP</h3><p>条形码预测问题</p>
<p><img src="/posts/82187def/Untitled 3.png" alt></p>
<p>虽然这是一个人为的问题，但它与具有共享多个查询的键的任何子图相关，并且每个查询都需要以不同的方式处理这些键。这样的子图在现实世界的各种领域很常见。</p>
<p><strong>Result</strong></p>
<p>如上右图</p>
<ul>
<li><p>GAT with a single head (GAT1<em>h</em>) failed to fit the <em>training</em> set for any value of <em>k</em>, no matter for how many iterations it was trained, and after trying various training methods.</p>
</li>
<li><p>GAT8<em>h</em> successfully fits the <em>training</em> set, but generalizes <em>poorly</em> to the <em>test</em> set.</p>
</li>
<li><p>GATv2 easily achieves 100% training and 100% test accuracies for any value of <em>k</em>, and even for <em>k</em>=100 (not shown) and using a <em>single head</em></p>
</li>
<li><p>GIN（non-attentive baselines ）的实验</p>
<p><img src="/posts/82187def/Untitled 4.png" style="zoom:80%;"></p>
</li>
</ul>
<p><strong>Visualization</strong></p>
<p>见Figure1</p>
<p><strong>The role of multi-head attention</strong></p>
<p>GAT作者发现多头注意的作用是“稳定学习过程”。然而，图3显示，增加头部的数量严格提高了训练的准确性，因此，提高表达性。因此，GAT依赖于有多个注意力头。相比之下，即使是一个GATv2头也比一个多头GAT泛化更好。</p>
<p>Q： 多头注意力缺乏解释性，真的能一定提高准确性吗</p>
<p>A：在实际训练中，有的时候反而下降了呢。为什么呢 （见4.4 NODE-PREDICTION）</p>
<p><img src="/posts/82187def/Untitled 5.png" alt></p>
<h3 id="4-2-ROBUSTNESS-TO-NOISE"><a href="#4-2-ROBUSTNESS-TO-NOISE" class="headerlink" title="4.2 ROBUSTNESS TO NOISE"></a>4.2 ROBUSTNESS TO NOISE</h3><p><img src="/posts/82187def/Untitled 6.png" style="zoom:80%;"></p>
<p>GATv2相比GAT对于噪声受到的影响更小。我们推断动态注意力帮助模型区分噪声边。</p>
<h3 id="4-3-PROGRAMS-VARMISUSE"><a href="#4-3-PROGRAMS-VARMISUSE" class="headerlink" title="4.3 PROGRAMS: VARMISUSE"></a>4.3 PROGRAMS: VARMISUSE</h3><p>在Varmisuse的结果</p>
<p><img src="/posts/82187def/Untitled 7.png" style="zoom: 80%;"></p>
<h3 id="4-4-NODE-PREDICTION"><a href="#4-4-NODE-PREDICTION" class="headerlink" title="4.4 NODE-PREDICTION"></a>4.4 NODE-PREDICTION</h3><p><img src="/posts/82187def/Untitled 8.png"></p>
<p>table (a)中，GATv2 一个头的都比GAT多头的要好。</p>
<p>但是，不管是GAT还是GATv2，都可以在表中观察到8头反而没有1头好的情况！四个数据集中，GATv2有两个，GAT有三个。所以？？？</p>
<h3 id="4-5-GRAPH-PREDICTION-QM9"><a href="#4-5-GRAPH-PREDICTION-QM9" class="headerlink" title="4.5 GRAPH-PREDICTION: QM9"></a>4.5 GRAPH-PREDICTION: QM9</h3><p>QM9 每个图都是一个分子，其目标是将每个图回归到13个实值的量子化学性质（property)。</p>
<p><img src="/posts/82187def/Untitled 9.png" alt></p>
<ul>
<li><p>GATv2比GAT有更低的误差，且比这三个模型都更低误差。</p>
</li>
<li><p>存在一些情况是GCN与GIN这类没有应用注意力机制的模型反而表现的更好，我们假设在modeling these properties时不需要注意力。</p>
</li>
<li><p>疑问</p>
<ol>
<li><p>观察到一个数据集GAT优于GATv2，说明不是所有情况都一定GATv2优于GAT。首先模型参数他是将GAT调到最优然后直接用于GATv2，不排除GATv2没有调好参数的情况，但是也可能存在一种情况：在某些建模属性/图结构下（比较简单？）并不需要动态注意力呢，或者说动态注意力反而使他更差？→ Discussion部分</p>
</li>
<li><p>非注意力机制模型GCN等在有些时候反而表现的更好。论文解释是推断可能在modeling these properties时不需要注意力。对于这种情况是否有详细的情况解释呢？</p>
<p>一个解释例子：当每个邻居的attention都几乎一样的时候，用attention机制基本就没有提升，而多出来的参数会导致优化和训练更难。</p>
</li>
</ol>
</li>
</ul>
<h3 id="4-6-LINK-PREDICTION"><a href="#4-6-LINK-PREDICTION" class="headerlink" title="4.6 LINK-PREDICTION"></a>4.6 LINK-PREDICTION</h3><p><img src="/posts/82187def/Untitled 10.png" alt></p>
<p>GATv2表现优于GAT。</p>
<p>关于GraphSAGE的表现更好，作者的猜测与假设：</p>
<ul>
<li><p>我们假设在这些数据集中可能不需要注意。</p>
<p><img src="/posts/82187def/Untitled 11.png" alt></p>
</li>
<li><p>另一种可能性是，动态注意力在具有高节点度的图中特别有用：</p>
<p>在ogbn products和ogbn-proteins中（table1)的平均节点度分别为50.5和597（见附录C中的表5）。然而，ogbl-collab and ogbl-citation2（table 3）的平均节点度要低得多，为8.2和20.7。</p>
</li>
<li><p>我们假设，当邻居总数较高时，动态注意机制对于选择最相关的邻居特别有用</p>
</li>
</ul>
<p>提出future work：关于数据集平均节点度的影响这一课题的GNN架构优化</p>
<h3 id="4-7-Discussion"><a href="#4-7-Discussion" class="headerlink" title="4.7 Discussion"></a>4.7 Discussion</h3><ul>
<li><strong>Which graph attention mechanism should I use?</strong></li>
</ul>
<ol>
<li>太简单的任务使用较强的模型可能会过拟合，更强的图注意力机制在节点之间相互越复杂的情况下理论上表现更好。</li>
</ol>
<p>通常不可能预先确定哪种体系结构的性能最好。一个理论上较弱的模型可能在实践中表现得更好，因为如果任务是“太简单”的且不需要这样的表达能力，一个较强的模型可能会过拟合训练数据。直观地说，我们认为节点之间的相互作用越复杂，GNN从理论上更强的图注意机制中获得的好处就越大，如GATv2。</p>
<ol>
<li>GAT vs GATv2 | 全局排序 vs 邻居排序</li>
</ol>
<p>主要的问题是，这个problem<strong>是否有一个“有影响力的”节点的全局排名（GAT就足够了），或者不同的节点是否有不同邻居的邻居排名（使用GATv2）。</strong></p>
<p>GAT的作者在<a href="https://twitter.com/PetarV_93/status/1399685979506675714">推特上</a>证实，GAT的设计适用于当时（2017年）“容易过拟合”的的数据集，如Cora、Citeseer（Senetal.，2008年），<strong>他们这些数据集可能具有“globally important”节点的底层静态排名</strong>。GAT的作者同意这一观点：更新和更具挑战性的基准测试可能需要更强的注意机制，如GATv2。在本文中，我们回顾了传统的假设，并表明许多现代图基准和数据集包含更复杂的交互，因此需要动态的注意力。</p>
<p><img src="/posts/82187def/Untitled 12.png" style="zoom:67%;"></p>
<p><img src="/posts/82187def/Untitled 13.png" style="zoom:67%;"></p>
<h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h2><p>在本文中，我们发现流行和广泛使用的图注意网络不计算动态注意。相反，在标准定义和实现中的注意机制的结果只是静态的：对于任何查询，它的邻居分数对于每个节点的分数是单调的。因此，GAT甚至不能表达简单的对齐问题。为了解决这个限制，我们引入了一个简单的修复并提出了GATv2：通过修改GAT中的操作顺序，GATv2实现了一个通用的近似注意函数，因此严格比GAT更强大。</p>
<p>我们在一个需要动态选择节点的综合问题中，展示了GATv2相对于GAT的经验优势，以及来自OGB和其他公共数据集的11个基准测试。我们的实验表明GATv2在所有基准测试中都优于GAT，同时具有相同的参数代价。</p>
<p>我们鼓励社区在将新的GNN架构与常见的强基线进行比较时，使用GATv2而不是GAT。在复杂的任务和领域中，以及在具有挑战性的数据集中，一个模型使用GAT作为内部组件可以用GATv2替换它，以适应严格上更强大的模型。为此，我们在<a href="https://github.com/tech-srl/how_attentive_are_gats">https://github.com/tech-srl/how_attentive_are_gats</a> 上公开了我们的代码，并且GATv2可以作为PyTorch Geometric library, the Deep Graph Library, and TensorFlow GNN的一部分使用。在 <a href="https://nn.labml.ai/graphs/gatv2">https://nn.labml.ai/graphs/gatv2</a> 上有一个带注释的实现 。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>GAT</tag>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Guide for starting a new project</title>
    <url>/posts/5e0e6968/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>翻译整理自<a href="https://github.com/google-research/tuning_playbook#choosing-the-batch-size-to-minimize-training-time">google-research/tuning_playbook</a></p>
<h1 id="开展一个新项目的指南"><a href="#开展一个新项目的指南" class="headerlink" title="开展一个新项目的指南"></a>开展一个新项目的指南</h1><span id="more"></span>
<p><em>摘要： 我们在调整过程中做出的许多决定可以在项目开始时一次性做出，只有在情况发生变化时才偶尔重新审视。</em></p>
<p>我们的指导假定以下内容：</p>
<ul>
<li>已经完成了问题制定、数据清理等基本工作，花时间调整模型架构和训练配置是有意义的。</li>
<li>已经设置了一个可以进行训练和评估的流水线，并且可以轻松执行感兴趣的各种模型的训练和预测任务。</li>
<li>已经选择并实施了适当的指标。这些指标应尽可能反映部署环境中测量的内容。</li>
</ul>
<h2 id="选择模型架构"><a href="#选择模型架构" class="headerlink" title="选择模型架构"></a>选择模型架构</h2><p><strong>摘要：</strong> <em>在开始一个新项目时，尝试重用一个已经有效的模型。</em></p>
<ul>
<li>首先选择一个成熟、常用的模型架构以获得有效的工作。总是可以稍后构建自定义模型。</li>
<li>模型架构通常具有各种超参数，用于确定模型的大小和其他细节（例如层数、层宽、激活函数类型）。<ul>
<li>因此，选择架构实际上意味着选择一个不同模型的家族（每个对应一种模型超参数设置）。</li>
<li>我们将在<a href="https://github.com/google-research/tuning_playbook#choosing-the-initial-configuration">Choosing the initial configuration</a> and <a href="https://github.com/google-research/tuning_playbook#a-scientific-approach-to-improving-model-performance">A scientific approach to improving model performance</a>中考虑选择模型超参数的问题。</li>
</ul>
</li>
<li>如果可能，尝试找到一篇尽可能接近手头问题的论文，并将其作为起点进行复现。</li>
</ul>
<h2 id="选择优化器"><a href="#选择优化器" class="headerlink" title="选择优化器"></a>选择优化器</h2><p><strong>摘要：</strong> <em>从手头问题类型的最流行优化器开始。</em></p>
<ul>
<li><p>没有优化器是所有机器学习问题和模型架构的“最佳”优化器。即使只是<a href="https://arxiv.org/abs/1910.05446">比较优化器的性能也是一项艰巨的任务</a>。🤖</p>
</li>
<li><p>我们建议坚持使用成熟、流行的优化器，特别是在开始新项目时。</p>
<ul>
<li>理想情况下，请选择用于同一类型问题的最流行优化器。</li>
</ul>
</li>
<li><p>准备关注所选优化器的所有超参数。</p>
<ul>
<li><p>具有更多超参数的优化器可能需要更多的调整工作才能找到最佳配置。</p>
</li>
<li><p>在项目的初始阶段，当我们试图找到其他各种超参数的最佳值时（例如架构超参数），将优化器超参数视为干扰参数 （Nuisance hyperparameters），这是非常重要的。</p>
<p>（Nuisance hyperparameters是未被特定，但是在理论测试时被考虑到的那些，即它们是需要优化以便比较科学超参数（Scientific hyperparameters) 的不同值的参数。科学超参数是我们试图衡量它们对模型性能造成的影响的参数。</p>
</li>
<li><p>在项目的初始阶段，可能更喜欢使用更简单的优化器（例如具有固定动量的SGD或具有固定<em>ϵ</em>、<em>β1</em>和<em>β2</em>的Adam），然后稍后切换到更一般的优化器。</p>
</li>
</ul>
</li>
<li><p>我们喜欢的成熟优化器（但不限于）包括：</p>
<ul>
<li>带有动量的SGD（我们喜欢Nesterov变体）</li>
<li>Adam和NAdam，它们比带有动量的SGD更一般。请注意，Adam具有4个可调超参数<a href="https://arxiv.org/abs/1910.05446">它们都很重要</a>！</li>
<li>请参阅[Adam的超参数如何调整？]<ul>
<li>根据上面的讨论，关于搜索空间以及应该从搜索空间中采样多少点的一般性陈述是非常困难的。请注意，Adam中的所有超参数并不都同样重要。以下经验法则对应于不同的“预算”，用于研究中的试验次数。 - 如果研究中的试验次数少于10次，只调整（基本）学习率。 - 如果10-25次试验，调整学习率和β1。 - 如果25+次试验，调整学习率，β1和ϵ。 - 如果可以运行的试验次数大大超过25次，还可以调整β2。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="选择批量大小"><a href="#选择批量大小" class="headerlink" title="选择批量大小"></a>选择批量大小</h2><p><strong>摘要：</strong> <em>批量大小控制训练速度，不应该用来直接调整验证集性能。通常，理想的批量大小将是可用硬件支持的最大批量大小。</em></p>
<ul>
<li>批量大小是确定<em>训练时间</em>和<em>计算资源消耗</em>的关键因素。</li>
<li>增加批量大小通常会减少训练时间。这可能是非常有益的，因为它：<ul>
<li>允许在固定的时间间隔内更彻底地调整超参数，可能导致更好的最终模型。</li>
<li>减少开发周期的延迟，允许更频繁地测试新想法。</li>
</ul>
</li>
<li>增加批量大小可以减少、增加或不改变资源消耗。</li>
<li>批量大小不应该被当作用于验证集性能的可调超参数。<ul>
<li>只要所有超参数都得到很好的调整（特别是学习率和正则化超参数），并且训练步数足够，使用任何批量大小都应该可以获得相同的最终性能（请参见 <a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a> ）。</li>
<li>请参阅为什么不应该将批量大小调整为直接改善验证集性能？<ul>
<li>改变批量大小<em>而不改变任何其他训练管道的细节</em>通常会影响验证集性能。</li>
<li>但是，如果为每个批量大小单独优化训练管道，两个批量大小之间的验证集性能差异通常会消失。</li>
<li>与批量大小最强烈相互作用的超参数，因此对于每个批量大小最重要的是单独调整优化器超参数（例如学习率，动量）和正则化超参数。<ul>
<li>较小的批量大小会由于样本方差向训练算法引入更多噪声，并且此噪声可能具有正则化效果。因此，较大的批量大小可能更容易过度拟合，可能需要更强的正则化和/或额外的正则化技术。</li>
</ul>
</li>
<li>此外，改变批量大小时，<a href="https://github.com/google-research/tuning_playbook#choosing-the-batch-size-to-minimize-training-time">可能需要调整训练步骤的数量</a>。</li>
<li>一旦考虑到所有这些影响，目前尚无令人信服的证据表明批量大小会影响最大可达到的验证性能（参见<a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="确定可行的批量大小和估计训练吞吐量"><a href="#确定可行的批量大小和估计训练吞吐量" class="headerlink" title="确定可行的批量大小和估计训练吞吐量"></a>确定可行的批量大小和估计训练吞吐量</h3><ul>
<li>对于给定的模型和优化器，可用硬件通常会支持一定范围的批量大小。限制因素通常是加速器内存。</li>
<li>不幸的是，在不运行或者至少不编译整个训练程序的情况下计算哪些批量大小将适合内存可能很困难。</li>
<li>最简单的解决方案通常是运行不同批量大小（例如增加2的幂）的训练作业，直到其中一个作业超过可用的内存为止。</li>
<li>对于每个批量大小，我们应该训练足够长的时间来获得<em>训练吞吐量</em>的可靠估计</li>
</ul>
<p>训练吞吐量 =（#每秒处理的实例）</p>
<p>或者，等效地，<em>每步时间</em>。</p>
<p>每步时间 =（批量大小）/（训练吞吐量）</p>
<ul>
<li>当加速器尚未饱和时，如果批量大小翻倍，训练吞吐量也应该翻倍（或者至少接近翻倍）。等效地，每步时间随着批量大小的增加应该是恒定的（或者至少接近恒定）。</li>
<li>如果情况不是这样，那么训练管道就具有瓶颈，例如I / O或计算节点之间的同步。在继续之前，这可能值得诊断和纠正。</li>
<li>如果训练吞吐量仅增加到某个最大批量大小，邤我们应该只考虑到该最大批量大小，即使硬件支持更大的批量大小。<ul>
<li>使用较大批量大小的所有好处均假定训练吞吐量会增加。  如果不是，修复瓶颈或使用较小的批量大小。</li>
<li><strong>梯度累积</strong>模拟比硬件支持的更大的批量大小，因此不提供任何吞吐量优势。 在应用工作中通常应避免使用它。</li>
</ul>
</li>
<li>每次更改模型或优化器时（例如，不同的模型架构可能允许更大的批量大小适合内存），可能需要重复这些步骤。</li>
</ul>
<h3 id="选择批量大小以最小化训练时间"><a href="#选择批量大小以最小化训练时间" class="headerlink" title="选择批量大小以最小化训练时间"></a>选择批量大小以最小化训练时间</h3><p>训练时间 =（每步时间）x（总步数）</p>
<ul>
<li><p>我们通常可以认为每步时间对于所有可行的批量大小来说都是近似恒定的。 当没有并行计算的开销并且所有训练瓶颈都已经诊断和纠正（请参阅上一节以了解如何识别训练瓶颈）时，这是正确的。 实践中，随着批量大小的增加，通常至少有一些开销。</p>
</li>
<li><p>随着批量大小的增加，要达到固定性能目标所需的总步数通常会减少（所有相关超参数在更改批量大小时重新调整; Shallue et al. 2018）。</p>
<ul>
<li>例如。 将批量大小翻倍可能会使所需的总步数减半。 这称为<strong>完美缩放</strong>。</li>
</ul>
</li>
<li><p>完美缩放适用于所有批量大小，直到一个临界批量大小，超出该批量大小，收益就会逐渐减少。</p>
<ul>
<li>最终，增加批量大小不再减少训练步骤的数量（但永远不会增加）。</li>
</ul>
</li>
<li><p>因此，最小化训练时间的批量大小通常是仍然提供减少训练步骤数量的最大批量大小。</p>
<ul>
<li><p>此批量大小取决于数据集，模型和优化器，除了为每个新问题找到它的实验之外，如何计算它是一个未解决的问题。 🤖</p>
</li>
<li><p>在比较批量大小时，要注意示例预算/epoch预算（固定训练示例呈现的数量来运行所有实验）和步骤预算（固定训练步骤的数量来运行所有实验）之间的区别。</p>
<ul>
<li>使用epoch预算比较批量大小只探测完美缩放模式，即使更大的批量大小仍然可以通过减少所需的训练步骤来提供有意义的加速。</li>
</ul>
</li>
<li><p>通常，可用硬件支持的最大批量大小小于关键批量大小。因此，<strong>一个很好的经验法则（无需运行任何实验）是使用尽可能大的批量大小。</strong></p>
</li>
<li><p><strong>如果使用更大的批量大小会增加训练时间，那么没有必要使用更大的批量大小。</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="选择批量大小以最小化资源消耗"><a href="#选择批量大小以最小化资源消耗" class="headerlink" title="选择批量大小以最小化资源消耗"></a>选择批量大小以最小化资源消耗</h3><ul>
<li>增加批量大小与之相关的资源成本有两种类型：<ol>
<li><em>预付费用</em>，例如购买新硬件或重写训练管道以实现多GPU/多TPU训练。</li>
<li><em>使用费用</em>，例如对团队资源预算进行计费，云提供商收费，电费/维护费用。</li>
</ol>
</li>
<li>如果增加批量大小会带来显着的前期成本，那么最好推迟增加批量大小，直到项目已成熟，并且更容易评估成本效益权衡。 实施多主机并行训练程序可能会引入错误和微妙的问题，因此可能最好从一个更简单的管道开始。（另一方面，训练时间的大幅加速可能在大量调整实验需要时很有益。）</li>
<li>我们将总使用成本（可能包括多种不同类型的成本）称为“资源消耗”。 我们可以将资源消耗分解为以下组件：</li>
</ul>
<p>资源消耗=（每步资源消耗）x（总步数）</p>
<ul>
<li>增加批量大小通常允许我们减少总步数。 资源消耗是增加还是减少将取决于每步消耗如何改变。<ul>
<li>增加批量大小可能会<em>减少</em>资源消耗。 例如，如果使用较大批量大小的每个步骤都可以在与较小批量大小相同的硬件上运行（仅每步时间稍有增加）</li>
<li>增加批量大小可能<em>不会改变</em>资源消耗。例如，如果将批量大小翻倍，可以减少所需步骤的一半，并使用两倍的GPU，总消耗（以GPU小时为单位）将不会改变。</li>
<li>增加批量大小可能会<em>增加</em>资源消耗。例如，如果增加批量大小需要升级硬件，每步的消耗增加可能会超过步骤数量的减少。</li>
</ul>
</li>
</ul>
<h3 id="更改批量大小需要重新调整大多数超参数"><a href="#更改批量大小需要重新调整大多数超参数" class="headerlink" title="更改批量大小需要重新调整大多数超参数"></a>更改批量大小需要重新调整大多数超参数</h3><ul>
<li>大多数超参数的最佳值对批量大小敏感。 因此，更改批量大小通常需要重新开始调整过程。</li>
<li>与批量大小最密切相关的超参数，因此最重要的是为每个批量大小单独调整，是优化器超参数（例如学习率，动量）和正则化超参数。</li>
<li>在选择项目开始时的批量大小时要牢记这一点。 如果您稍后需要切换到不同的批量大小，则重新调整所有内容以适应新批量大小可能很困难，耗时且昂贵。</li>
</ul>
<h3 id="批量归一化如何与批量大小交互"><a href="#批量归一化如何与批量大小交互" class="headerlink" title="批量归一化如何与批量大小交互"></a>批量归一化如何与批量大小交互</h3><p>批量归一化很复杂，一般来说，应该使用不同于梯度计算的批量大小来计算统计信息。 有关详细讨论，请参见<a href="https://github.com/google-research/tuning_playbook#batch-normalization-implementation-details">批量归一化部分</a></p>
<h2 id="选择初始配置"><a href="#选择初始配置" class="headerlink" title="选择初始配置"></a>选择初始配置</h2><ul>
<li>在开始超参数调整之前，我们必须确定起点。 这包括指定（1）模型配置（例如层数），（2）优化器超参数（例如学习率）以及（3）训练步骤数。</li>
<li>确定此初始配置将需要一些手动配置的训练运行和试错。</li>
<li>我们的指导原则是找到一个简单，相对快速，相对低资源消耗的配置，可以获得“合理”的结果。<ul>
<li>“简单”意味着尽可能避免花哨的东西；这些都可以稍后添加。 即使花哨的东西最终证明有帮助，在初始配置中添加它们也会浪费时间来调整无用的功能，或者合并不必要的复杂性。<ul>
<li>例如，先使用恒定的学习率，然后再添加花哨的衰减计划。</li>
</ul>
</li>
<li>选择快速且资源消耗最小的初始配置将使超参数调整更加高效。<ul>
<li>例如，从较小的模型开始。</li>
</ul>
</li>
<li>“合理”的性能取决于问题，但至少意味着训练的模型在验证集上的表现要好得多，比随机机会好（尽管它可能足够糟糕，不值得部署）。</li>
</ul>
</li>
<li>选择训练步骤数量涉及以下考量：<ul>
<li>一方面，训练更多步骤可以提高性能，并使超参数调整更容易（请参见<a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>）。</li>
<li>另一方面，训练步骤较少意味着每次训练运行更快，使用的资源更少，通过减少周期之间的时间来提高调整效率，并允许并行运行更多实验。此外，如果最初选择了不必要的大步骤预算，则可能很难在以后更改它，例如一旦为该步数调整了学习率计划。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Deep Learning Tuning Playbook</tag>
      </tags>
  </entry>
  <entry>
    <title>Exploiting Completeness and Uncertainty of Pseudo Labels</title>
    <url>/posts/d2ac8e77/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Exploiting-Completeness-and-Uncertainty-of-Pseudo-Labels"><a href="#Exploiting-Completeness-and-Uncertainty-of-Pseudo-Labels" class="headerlink" title="Exploiting Completeness and Uncertainty of Pseudo Labels"></a>Exploiting Completeness and Uncertainty of Pseudo Labels</h1><p><a href="https://arxiv.org/abs/2212.04090">[2212.04090] Exploiting Completeness and Uncertainty of Pseudo Labels for Weakly Supervised Video Anomaly Detection (arxiv.org)</a>(CVPR 2022.10)</p>
<aside>
💡 这篇论文提出了一种利用伪标签的完整性和不确定性的弱监督视频异常检测方法。它由一个完整性增强的伪标签生成器组成，该生成器使用3D CNN提取视频特征，并使用多头分类器训练多样性损失和MIL排序损失来生成初始伪标签，以及一个迭代的不确定性感知伪标签细化策略，该策略使用蒙特卡罗（MC）丢失来测量不确定性，并逐渐细化伪标签以训练所需的分类器。 UCF-Crime，TAD和XD-Violence的实验表明，与几种最先进的方法相比，它的性能良好。
</aside>

<span id="more"></span>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><hr>
<h3 id="现有方法"><a href="#现有方法" class="headerlink" title="现有方法"></a>现有方法</h3><p>paper将现有的弱监督方法分为两种：</p>
<ul>
<li>MIL</li>
<li>two-stage self-training</li>
</ul>
<p>基于MIL的方法由于缺少clip-level的标注，得到的异常分数常常是较为不精确的。而two-stage self-training 方法的提出可以缓解该问题。</p>
<p>two-stage self-training[5,12]</p>
<ol>
<li>基于MIL方法为clips生成伪标签(pseudo labels）</li>
<li>用伪标签去精细化判别表示</li>
</ol>
<h3 id="limitations"><a href="#limitations" class="headerlink" title="limitations"></a>limitations</h3><p>针对two-stage self training 的 <strong>Completeness and Uncertainty of Pseudo Labels</strong></p>
<ul>
<li><p>用于伪标签生成的ranking loss 忽略异常事件的完整性</p>
<p>“一个正袋可能包含多个异常事件片段，，但是MIL只会检测到最像的一个。”(really?)</p>
<p><img src="/posts/d2ac8e77/Untitled.png" alt></p>
<p>橘色部分代表ground truth, 现有的方法如b所示，关注在最异常的片段。因此，提出使用基于diversity loss的多头分类模块，以生成能够覆盖完整异常事件的伪标签（如c所示）</p>
</li>
<li><p>在第二步中  生成伪标签的不确定性 未被考虑</p>
<p>伪标签通常是有噪声的，直接使用进行最后分类模型的训练可能损害模型性能表现。</p>
</li>
</ul>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>分别针对两个limitations</p>
<ul>
<li>提出多头模块生成伪标签，引入diversity loss以确保多个分类头生成的伪标签的分布差异→ 确保异常事件的完整性检测 （对应step1)<ul>
<li>通过这种方式，每一个头倾向于发现不同的异常事件，因此可以让伪标签尽可能覆盖更多的异常事件</li>
</ul>
</li>
<li>设计一个迭代的基于不确定性的训练策略 （对应step2)<ul>
<li>使用Monte Carlo(MC) Dropout 度量不确定性</li>
<li>将低不确定性的片段用于最后分类器的训练 (该过程逐渐迭代细化伪标签）<ul>
<li>第一次迭代  细化 step1生成的伪标签</li>
<li>剩余的迭代细化分类器每次迭代的输出伪标签</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>我们设计了一个基于多样性损失的多头分类器方案，使得伪标签覆盖尽可能多的异常片段。</li>
<li>我们设计了一种迭代的不确定性感知的自我训练策略，以逐步提高伪标签的质量。</li>
<li>在UCF-Crime、TAD和XD-Violence上进行的实验表明，与几种最先进的方法相比，它具有良好的性能。</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><hr>
<p><img src="/posts/d2ac8e77/Untitled 1.png" alt></p>
<p>1)  使用预训练的3D CNN模型提取视频特征（paper使用的是I3D）</p>
<p>2）经过多样性损失和MIL排序损失训练的多头分类器来生成初始的片段伪标签</p>
<p>3）利用一个迭代的不确定性感知的伪标签细化策略， 逐步提高伪标签的质量，训练最终期望的分类器。</p>
<blockquote>
<p>Completeness Enhanced Pseudo Label Generator<br>用预先训练好的3D CNN来提取视频特征。将这些特征输入受多样性损失约束的多头分类器，以检测完整的异常事件。</p>
</blockquote>
<p>Iterative Uncertainty Aware Pseudo Label Refinement<br>在第一次迭代中，我们从first stage的多头分类器中获得初始的clip级伪标签，并通过Monte Carlo Dropout计算其不确定性。然后根据不确定性选择可靠的片段来训练一个新的片段分类器。在剩下的迭代中，使用新的片段分类器更新伪标签。</p>
<blockquote>
</blockquote>
<h3 id="Completeness-of-Pseudo-Labels"><a href="#Completeness-of-Pseudo-Labels" class="headerlink" title="Completeness of Pseudo Labels"></a><strong>Completeness of Pseudo Labels</strong></h3><p>伪标签生成器由并行的多头分类器组成。each head由三个全连接层组成</p>
<p><img src="/posts/d2ac8e77/Untitled 2.png" alt></p>
<ul>
<li>diversity loss</li>
</ul>
<p>each head输出每个片段的异常分数，并通过softmax生成分数的分布：</p>
<p><img src="/posts/d2ac8e77/Untitled 3.png" alt></p>
<p>通过多样性损失（diversity loss) 将属于不同head的分数分布互相区分开来← 通过最小化任意两头之间的余弦相似度</p>
<p><img src="/posts/d2ac8e77/Untitled 4.png" alt></p>
<ul>
<li>regularization term</li>
</ul>
<p>片段分数序列的正则化项：平衡多头并避免由于一头占主导地位导致的性能下降</p>
<p><img src="/posts/d2ac8e77/Untitled 5.png" alt></p>
<p>在多样性损失和范数正则化的作用下，多头产生的异常得分可以达到最大的区别，并能够检测不同的异常片段。</p>
<p>sigmoid所有头异常分数的平均得到片段级的标签</p>
<p><img src="/posts/d2ac8e77/Untitled 6.png" alt></p>
<ul>
<li><p>ranking loss</p>
<p>最大化异常和正常实例的差距</p>
</li>
</ul>
<p><img src="/posts/d2ac8e77/Untitled 7.png" alt></p>
<h3 id="Uncertainty-of-Pseudo-Labels"><a href="#Uncertainty-of-Pseudo-Labels" class="headerlink" title="Uncertainty of Pseudo Labels"></a><strong>Uncertainty of Pseudo Labels</strong></h3><p>为了训练最终期望的片段分类器fc，而不是直接使用在step1获得的片段级伪标签 提出了一种不确定性感知的自训练策略挖掘具有可靠伪标签的片段。</p>
<p>具体地说，我们引入了利用Monte Carlo Dropout 的不确定性估计，从而选择具有低不确定性（即可靠的）伪标签的片段进行训练fc。这个过程进行了几次迭代。伪标签最初是在第一阶段获得的，然后进行经由fc更新。</p>
<p><img src="/posts/d2ac8e77/Untitled 8.png" alt></p>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><p><img src="/posts/d2ac8e77/Untitled 9.png" alt></p>
<p><img src="/posts/d2ac8e77/Untitled 10.png" alt="Untitled"></p>
<p><img src="/posts/d2ac8e77/Untitled 11.png" alt></p>
<p>消融实验</p>
<p><img src="/posts/d2ac8e77/Untitled 12.png" alt></p>
<p>超参分析</p>
<p><img src="/posts/d2ac8e77/Untitled 13.png" alt></p>
<p>最好的结果是双头</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>VAD</tag>
        <tag>弱监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>zero-shot</title>
    <url>/posts/2ac833a5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><blockquote>
<p>Zero-shot is the natural <em>best-case scenario</em> for a model as it means we require <em>zero</em> training samples before shifting it to a new domain or task.<br>zero-shot是一个模型的自然最佳情况，因为这意味着我们将其迁移到新的领域或者任务时需要零个训练样本</p>
</blockquote>
<span id="more"></span>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>Sota的CV模型在特定的任务和数据集中表现良好，但是不能很好的泛化，他们无法处理在他们已经训练过的领域之外的新的类别或者图片。收集足够大的标记数据集以使用传统方法对这些专业用例的CV模型进行微调可能非常困难。</p>
<p>理想情况下，CV模型应该学习图像的内容，而不是过分关注最初训练理解的特定标签。比如，对于狗的图像，模型应该理解“狗在图像中”，当然那，如果它能理解背景中有树木、现在在白天、狗在草地上，那将更加有用。</p>
<p>分类训练的结果恰恰与该理想情况相反。模型学习将狗的internal representation放到相同的“狗向量空间”，将猫的放到相同的“猫向量空间”。他们关注的点在于图片是否与类匹配的yes or no。</p>
<p>重新训练分类模型是一种选择，但是需要大量的时间和成本投入：收集一个分类数据集和模型训练过程本身。</p>
<h2 id="N-shot和Zero-shot"><a href="#N-shot和Zero-shot" class="headerlink" title="N-shot和Zero-shot"></a>N-shot和Zero-shot</h2><h3 id="N-shot-learning"><a href="#N-shot-learning" class="headerlink" title="N-shot learning"></a>N-shot learning</h3><blockquote>
<p>Here we define <em>N</em> as the number of samples required to train a model to begin making predictions in a new domain or on a new task.</p>
</blockquote>
<p>定义N为  为了在新领域或者新任务进行预测 而需要用于训练一个模型的样本数量。</p>
<p>如今，许多SotA模型都是在ResNet或BERT等用大量数据上进行预训练的。然后针对特定任务和领域对这些预训练模型进行<em>微调</em>。例如，可以使用 <a href="https://www.pinecone.io/learn/imagenet">ImageNet 对 ResNet</a> 模型进行预训练，然后针对服装分类进行微调。</p>
<p>像 ResNet 和 BERT 这样的模型被称为<em>“N-shot”</em>learner，因为我们需要<em>许多</em>训练样本才能在最后的微调步骤中达到可接受的性能。</p>
<p>只有当我们有计算、时间和数据允许我们微调模型时，N-shot learning才有可能。理想情况下，我们希望最大限度地提高模型性能，同时最小化N-shot要求。即提出Zero-shot。</p>
<h3 id="zero-shot"><a href="#zero-shot" class="headerlink" title="zero-shot"></a>zero-shot</h3><p>zero-shot是一个模型的自然最佳情况，因为这意味着我们将其迁移到新的领域或者任务时需要零个训练样本。</p>
<h2 id="Zero-shot实现"><a href="#Zero-shot实现" class="headerlink" title="Zero-shot实现"></a>Zero-shot实现</h2><p>OpenAI的CLIP已经证明自己是一个非常灵活的分类模型，通常需要zero的再训练。</p>
<p><strong>C</strong>ontrastive <strong>L</strong>anguage-I mage <strong>P</strong>retraining （CLIP） 是 OpenAI 于 2021 年发布的一个主要基于transformer的模型 [1]。</p>
<p>我们在这里使用的 CLIP 版本包括一个用于编码文本嵌入的文本转换器和一个用于编码图像嵌入的视觉转换器 （ViT）。</p>
<p>两种 CLIP 模型都在预训练期间进行了优化，以对齐向量空间中的相似文本和图像。它通过获取<strong>图像文本对</strong> (image-text pairs )并在向量空间中将其输出向量推近，同时分离非对(non-pairs)的向量来实现这一点。</p>
<p><img src="/posts/2ac833a5/image-20230206150750481.png" alt></p>
<p>它与典型的分类模型区别开来有几个原因。首先，OpenAI在一个<strong>由4亿文本图像对组成的庞大</strong>数据集上对其进行了训练，这些数据集是从互联网上抓取的。</p>
<p>这里有三个主要好处：</p>
<ol>
<li>CLIP只需要<strong>图像-文本对</strong>，而不是特定的类标签，这要归功于contrastive而不是classification的训练功能。在当今以社交媒体为中心的世界中，这种类型的数据非常丰富。</li>
<li>大数据集大小意味着 CLIP 可以对图像中显示的一般文本概念建立深刻的理解。</li>
<li>文本描述符通常描述图像的各种特征，而不仅仅是一个特征。这意味着可以构建图像（和文本）的更全面的表示。</li>
</ol>
<p>CLIP的这些优点是导致其出色的zero-shot性能的主要因素。</p>
<p>数据对比：</p>
<p><img src="/posts/2ac833a5/image-20230206151132885.png" alt></p>
<h3 id="zero-shot-classification"><a href="#zero-shot-classification" class="headerlink" title="zero-shot classification"></a>zero-shot classification</h3><p>这些<em>“类”</em>中的每一个都作为向量从文本编码器分别输出为T1,T2和T3。给定一张猫的照片，我们使用 ViT 模型对其进行编码以创建矢量我I1.当我们用余弦相似性计算这些向量的相似性时，我们期望sim（T3，I1）返回最高分。</p>
<p><img src="/posts/2ac833a5/image-20230206151357836.png" alt></p>
<h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p><a href="https://www.pinecone.io/learn/zero-shot-image-classification-clip/">Zero-shot Image Classification with OpenAI’s CLIP | Pinecone</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>理论认知</tag>
      </tags>
  </entry>
  <entry>
    <title>几个基础图神经网络</title>
    <url>/posts/71dd2457/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="GCN、GraphSAGE和GAT"><a href="#GCN、GraphSAGE和GAT" class="headerlink" title="GCN、GraphSAGE和GAT"></a>GCN、GraphSAGE和GAT</h1><span id="more"></span>
<h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><ul>
<li>公式：（I是单位矩阵）</li>
</ul>
<p><img src="/posts/71dd2457/image-20221126212953575.png" alt="image-20221126212953575"></p>
<ul>
<li>聚合过程</li>
</ul>
<p>度矩阵的作用主要是归一化。如下图，GCN聚合的过程实际上是将邻居节点信息相加。如节点1和节点2、节点3相连，矩阵相乘的结果是：节点1的特征=节点2+节点3+自己。</p>
<p><img src="/posts/71dd2457/image-20221126213047435.png" alt="image-20221126213047435"></p>
<ul>
<li>GCN操作</li>
</ul>
<p>如下图是两层GCN卷积：（N，C）*（C，F） =&gt;（N，F）</p>
<p>分类：1）最后输出的维度为分类的类数；2）不为分类的类数，只是作为一个特征提取器， 加上全连接层进行分类。</p>
<p><img src="/posts/71dd2457/image-20221126213249170.png" alt="image-20221126213249170"></p>
<h2 id="GraphSAGE-SAmple-and-aggreGatE"><a href="#GraphSAGE-SAmple-and-aggreGatE" class="headerlink" title="GraphSAGE(SAmple and aggreGatE)"></a>GraphSAGE(SAmple and aggreGatE)</h2><p>提出归纳式的graph embedding方法，之前的graph embedding方法都是所有节点都在图中，对于没有<br>看到过的节点是不能处理的，这种叫做直推式方法。<br>而GraphSAGE这种归纳式的方法，可 以对于没见过的节点也生成embedding。<br>GraphSAGE不仅限于构建embedding,也通过聚合周围邻居节点的特征。</p>
<h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><p><img src="/posts/71dd2457/image-20221126212301603.png" alt="image-20221126212301603"></p>
<h3 id="邻居采样"><a href="#邻居采样" class="headerlink" title="邻居采样"></a>邻居采样</h3><p>聚合邻居个数采用固定长度k。</p>
<p>当k&lt;邻居总数时，直接<code>neighbors = np.random.choice(neighbors,self.max_degree,replace=False)</code></p>
<p>当k&gt;邻居数时，<code>neighbors = np.random.choice(neighbors,self.max_degree,replace=True)</code> (比如当邻居数是2，而要采样3个时，先将2个都放进来，然后再在2个邻居里面随机选一个凑三个)</p>
<p>作者发现该方法在K=2，即两层时可以达到好的表现。S1*S2&lt;= 500（S1表示第一次采样的邻居数）</p>
<h3 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h3><p>aggregator 需要满足的性质：</p>
<ul>
<li><p>对称的</p>
</li>
<li><p>对于输入排列不变的</p>
<p>（即改变邻居节点输入的顺序，输出的结果不变）</p>
</li>
</ul>
<p>三种</p>
<ul>
<li><p>mean aggregator</p>
<p><img src="/posts/71dd2457/image-20221126212500331.png" alt="image-20221126212500331"></p>
</li>
<li><p>LSTM aggregator</p>
<p>LSTM本身是有顺序的，但是通过将输入节点随机排列，使得适用于无序集合。</p>
<p>容量大，表现好。</p>
</li>
<li><p>Pooling aggregator</p>
</li>
</ul>
<p><img src="/posts/71dd2457/image-20221126212637461.png" alt="image-20221126212637461"></p>
<p><img src="/posts/71dd2457/image-20221126212630219.png" alt="image-20221126212630219"></p>
<p>不仅可以使用max，使用其他的排列不变性函数都可以，如mean和max效果上是没有差异的。</p>
<p>通过W可以改变输出的维度。</p>
<h2 id="GraphSAGE-minibatch"><a href="#GraphSAGE-minibatch" class="headerlink" title="GraphSAGE minibatch"></a>GraphSAGE minibatch</h2><p>和GCN使用全图不同的是，GraphSage用采样的方式，在minibatch下，可以不使用全图信息。使得在大规模图上训练变得可行。</p>
<p>算法如下图所示：</p>
<p><img src="/posts/71dd2457/image-20221126210734688.png" alt="image-20221126210734688"></p>
<h3 id="邻居采样：从第K-1层到第0层（从内到外）"><a href="#邻居采样：从第K-1层到第0层（从内到外）" class="headerlink" title="邻居采样：从第K-1层到第0层（从内到外）"></a><strong>邻居采样：从第K-1层到第0层</strong>（从内到外）</h3><p>以节点a为中心进行邻居采样。节点a所在层为第k层，此时k=2。聚合的总结点数为Sall = 1。</p>
<p>第k-1层，聚合第k层的Sk个邻居节点。此时B1层采样节点a（第2层）的S2个邻居，即三个邻居；采样的总节点数为Sall = Sall*S2 = 3.</p>
<p>第k-2层，聚合第k-1层的Sk-1个邻居。此时B0层采样B1层的S1个邻居，即B1层的三个节点的对应的两个邻居。总邻居数为Sall = Sall*S1 = 6.</p>
<p><img src="/posts/71dd2457/image-20221126205428637.png" alt style="zoom:67%;"></p>
<p>保存所有这些采样的节点作为后续聚合用。可以减少内存，在大图上用。</p>
<h3 id="节点聚合：从第1层到第K层（从外到内）"><a href="#节点聚合：从第1层到第K层（从外到内）" class="headerlink" title="节点聚合：从第1层到第K层（从外到内）"></a>节点聚合：从第1层到第K层（从外到内）</h3><p><img src="/posts/71dd2457/image-20221126210846442.png" alt="image-20221126210846442"></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练的是GraphSage的权重函数W</p>
<p>经过GraphSage后，生成的embedding:Zu,求loss</p>
<p><img src="/posts/71dd2457/image-20221126211203555.png" alt="image-20221126211203555"></p>
<p>作者提出经过embedding之后，相近的节点应该有相似的表示，反之，区别较大的节点的表示应该很不同。zu为节点u的表示，应该使得相似的节点u和v，他们的表示$z_u^T z_v$乘积比较大，而不相似的乘积比较小=》该式的loss越小越好。</p>
<h2 id="GAT-Graph-Attention-Networks"><a href="#GAT-Graph-Attention-Networks" class="headerlink" title="GAT(Graph Attention Networks)"></a>GAT(Graph Attention Networks)</h2><ul>
<li>公式：</li>
</ul>
<script type="math/tex; mode=display">
\alpha _{ij} = \frac{exp(LeakyReLU(\vec a^T[W\vec h_i||W\vec h_j]))}{\sum_{k\in N_i} exp(LeakyReLU(\vec a^T[W\vec h_i||W\vec h_k]))}</script><script type="math/tex; mode=display">
\vec h'_i = \sigma(\sum \limits_{j \in N_i}a_{ij} W\vec h_j)</script><p>​    N为邻居节点集合，||为concat，W为共享的权值</p>
<ul>
<li>具体例子：</li>
</ul>
<p><img src="/posts/71dd2457/image-20221126214520133.png" alt="image-20221126214520133"></p>
<ul>
<li><p>多头注意力机制</p>
<p><img src="/posts/71dd2457/image-20221126214858258.png" alt style="zoom:67%;"></p>
<p><img src="/posts/71dd2457/image-20221126214941394.png" alt style="zoom:67%;"></p>
</li>
</ul>
<p>​    每一个注意力机制都学到节点的特征，然后将这K个拼接到一起作为最后的结果。</p>
<p>​    如果多头注意力机制在最后一层，用softmax预测，则拼接没必要，直接求平均。如果是接一个全连接层，拼接无所谓。</p>
<h2 id="网络对比"><a href="#网络对比" class="headerlink" title="网络对比"></a>网络对比</h2><p><img src="/posts/71dd2457/image-20221126215407142.png" alt style="zoom:67%;"></p>
<p>应用：</p>
<p>三者都可以用于半监督的任务。但是提出说GCN不能用于推理学习任务（即学习一张图，推荐没见过的另一张图），说是因为GCN的邻接矩阵的定义在两张图里面是不同的。（？？）那GAT就可以是因为是动态的聚合邻居吗，即非需要全图。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h2 id="GCN-1"><a href="#GCN-1" class="headerlink" title="GCN"></a>GCN</h2><p><a href="https://github.com/tkipf/pygcn">tkipf/pygcn: Graph Convolutional Networks in PyTorch (github.com)</a></p>
<p>数据集coras</p>
<p>pycharm调试</p>
<p>简单的跑一下默认数值 Test set results: loss= 0.7157 accuracy= 0.8320</p>
<h2 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h2><p><a href="https://github.com/Diego999/pyGAT">Diego999/pyGAT: Pytorch implementation of the Graph Attention Network model by Veličković et. al (2017, https://arxiv.org/abs/1710.10903) (github.com)</a></p>
<p>github上仓库有对GAT代码进行更新，新的代码减少内存的占用：原本a_input是通过将所有节点concat；新的代码是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span>  <span class="title function_">_prepare_attentional_mechanism_input</span>(<span class="params">self, Wh</span>):</span><br><span class="line">    <span class="comment"># Wh.shape (N, out_feature)</span></span><br><span class="line">    <span class="comment"># self.a.shape (2 * out_feature, 1)</span></span><br><span class="line">    <span class="comment"># Wh1&amp;2.shape (N, 1)</span></span><br><span class="line">    <span class="comment"># e.shape (N, N)</span></span><br><span class="line">    Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])</span><br><span class="line">    Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])</span><br><span class="line">    <span class="comment"># broadcast add</span></span><br><span class="line">    e = Wh1 + Wh2.T</span><br><span class="line">    <span class="keyword">return</span> self.leakyrelu(e)</span><br></pre></td></tr></table></figure>
<ul>
<li>batch的实现</li>
</ul>
<p>输入：[batch,node,feature]</p>
<p>adj: [batch,node,node]</p>
<p>关于GAT batch的实现，该仓库的issue中有讨论，并有提出一些解决方式。</p>
<p>我自己粗略的实现，在GraphAttentionLayer中修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, adj</span>):</span><br><span class="line">       h = torch.matmul(<span class="built_in">input</span>, self.W)</span><br><span class="line">       <span class="built_in">print</span>(h.shape)</span><br><span class="line">       <span class="comment">#N = h.size()[0]</span></span><br><span class="line">       N = h.size()[<span class="number">1</span>]</span><br><span class="line">       <span class="built_in">print</span>(N)</span><br><span class="line">       <span class="comment">#a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)</span></span><br><span class="line">       a_input = torch.cat([h.repeat(<span class="number">1</span>,<span class="number">1</span>, N).view(h.shape[<span class="number">0</span>],N * N, -<span class="number">1</span>), h.repeat(<span class="number">1</span>,N, <span class="number">1</span>)], dim=<span class="number">2</span>).view(h.shape[<span class="number">0</span>],N, -<span class="number">1</span>, <span class="number">2</span> * self.out_features)</span><br><span class="line">       <span class="built_in">print</span>(a_input.shape)</span><br><span class="line">       <span class="comment">#e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))</span></span><br><span class="line">       e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(<span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>一个博客的实现和我的思路类似：<a href="https://blog.csdn.net/pixian3729/article/details/110261140">GAT（参数中加入batch）_2snoopy的博客-CSDN博客</a></p>
<p>该方法其实还是挺消耗内存的。</p>
<p>Diego999减轻内存占用并应用batch的实现：</p>
<p><a href="https://github.com/Diego999/pyGAT/issues/62">How to implement batch training? · Issue #62 · Diego999/pyGAT (github.com)</a></p>
<p>实际中确实有减少内存占用，但是GAT本身的特质内存消耗比较大，可以去探索其他改进的GNN。</p>
<h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><p>tensorflow版本:<a href="https://github.com/williamleif/GraphSAGE">williamleif/GraphSAGE: Representation learning on large graphs using stochastic graph convolutions. (github.com)</a></p>
<p>pytorch实现（简洁版本）：<a href="https://github.com/williamleif/graphsage-simple">williamleif/graphsage-simple: Simple reference implementation of GraphSAGE. (github.com)</a></p>
<p><a href="https://blog.csdn.net/qq_35812205/article/details/126681519">【GraphSAGE实践】YelpChi评论图数据集上的反欺诈检测_山顶夕景的博客-CSDN博客_yelpchi数据集</a></p>
]]></content>
      <categories>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>图基本知识</title>
    <url>/posts/5f3db67/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="图基本知识"><a href="#图基本知识" class="headerlink" title="图基本知识"></a>图基本知识</h1><h2 id="图的表示"><a href="#图的表示" class="headerlink" title="图的表示"></a>图的表示</h2><p>点和边构成的数据结构</p>
<p>日常生活中无处不在：图像：像素和像素之间的连接构成的图; 网页： 网页之间的跳转;</p>
<span id="more"></span>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><strong>无向图和有向图</strong></p>
<h3 id="表示"><a href="#表示" class="headerlink" title="表示"></a>表示</h3><ul>
<li>邻接矩阵</li>
</ul>
<h2 id="图的性质"><a href="#图的性质" class="headerlink" title="图的性质"></a>图的性质</h2><h3 id="度"><a href="#度" class="headerlink" title="度"></a>度</h3><ul>
<li>无向图的度==该节点连接的边的数量</li>
<li>有向图的度<ul>
<li>出度：从该节点指向的边的数量</li>
<li>入度：指向该节点的边的数量</li>
</ul>
</li>
</ul>
<h3 id="子图"><a href="#子图" class="headerlink" title="子图"></a>子图</h3><p>​    子图所有的节点都包含在大图里面；</p>
<p>​    子图的边都是大图的边的子集；</p>
<h3 id="连通图和连通分量"><a href="#连通图和连通分量" class="headerlink" title="连通图和连通分量"></a>连通图和连通分量</h3><p>无向图</p>
<ul>
<li><p>连通图：</p>
<p>任意节点i能够通过一些边到达节点j，则称之为连通图；反之非连通图。</p>
<p>对于一个无向图：没有孤立的节点其实都能连通</p>
</li>
<li><p>连通分量：<br>无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。</p>
<p>连通图只有一个连通分量：他本身；非连通图有多个连通分量。</p>
</li>
</ul>
<p>有向图的连通性</p>
<ul>
<li>强连通图：给定图G的任意两个结点u,v可互相到达。</li>
<li>弱连通图：至少有一对结点不满足单向连通，但去掉边的方向之后从无向图的观点看是连通图。</li>
</ul>
<h3 id="最短路径和图直径"><a href="#最短路径和图直径" class="headerlink" title="最短路径和图直径"></a>最短路径和图直径</h3><p>两结点的最短到达路径就是最短路径</p>
<p>两两结点的最短路径中的长度最大值是图直径。</p>
<h3 id="度中心性"><a href="#度中心性" class="headerlink" title="度中心性"></a>度中心性</h3><script type="math/tex; mode=display">
度中心性 = \frac{N_{degree}}{n-1}</script><p>$N_{degree}$表示该节点的度，n为该节点所在图的节点总数。</p>
<h3 id="特征向量中心性Eigenvector-Centrality"><a href="#特征向量中心性Eigenvector-Centrality" class="headerlink" title="特征向量中心性Eigenvector Centrality"></a>特征向量中心性Eigenvector Centrality</h3><p>最大特征值对应的特征向量作为特征向量中心性的对比指标。</p>
<p>A为邻接矩阵；</p>
<p>如图，最大的特征值是第一个，所以特征向量对应第一列。</p>
<p>（特征向量中心性将特征向量的负值变成正进行统一对比）</p>
<p><img src="/posts/5f3db67/image-20221126140426649.png" style="zoom: 67%;"></p>
<p>特征向量中心性不仅考虑了自己节点的度，还考虑了和他向量节点的度的情况。如v4的值会比v2和v3大是因为它虽然度和v2\v3一样大，但是相连的是v1和v5，比v2/v3向量的节点的度总体要大。</p>
<p><strong>conclu:特征向量中心性比度中心性可以更好的表示节点在图中所处的位置。</strong></p>
<h3 id="中介中心性-Betweenness-Centrality"><a href="#中介中心性-Betweenness-Centrality" class="headerlink" title="中介中心性 Betweenness Centrality"></a>中介中心性 Betweenness Centrality</h3><script type="math/tex; mode=display">
Betweenness  = \frac{经过该节点的最短路径}{其余两两节点的最短路径}</script><h3 id="连接中心性-Closeness"><a href="#连接中心性-Closeness" class="headerlink" title="连接中心性 Closeness"></a>连接中心性 Closeness</h3><script type="math/tex; mode=display">
Closeness = \frac{n-1}{该节点到其他节点最短路径之和}</script><p>​    n为节点总数；</p>
<h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="网页排序算法"><a href="#网页排序算法" class="headerlink" title="网页排序算法"></a>网页排序算法</h3><h4 id="pagerank"><a href="#pagerank" class="headerlink" title="pagerank"></a>pagerank</h4><p>边的pagerank值为节点向外指向时平分的结果。如节点2向外指向的边有两条，因此现在那两条边的pagerank值都为pagerank2/2。</p>
<p>节点的pagerank值即为指向它的边的值的和。</p>
<p><img src="/posts/5f3db67/image-20221126142317310.png" style="zoom:67%;"></p>
<p>不断的迭代，最后每个节点的pagerank值达到稳态    。</p>
<p>阻尼系数：如节点3到节点4的概率有0.15。</p>
<h4 id="HITS"><a href="#HITS" class="headerlink" title="HITS"></a>HITS</h4><p><img src="/posts/5f3db67/image-20221126142814847.png" style="zoom: 67%;"></p>
<p>每个节点都有authority值和hub值</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">lis =<span class="keyword">lambda</span> x:random.randint(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">edges  = pd.DataFrame()</span><br><span class="line">edges[<span class="string">&#x27;sources&#x27;</span>] = [lis(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line">edges[<span class="string">&#x27;targets&#x27;</span>] = [lis(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line">edges[<span class="string">&#x27;weights&#x27;</span>] = [<span class="number">1</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>)]</span><br><span class="line"></span><br><span class="line">G = nx.from_pandas_edgelist(edges,source=<span class="string">&#x27;sources&#x27;</span>,target=<span class="string">&#x27;targets&#x27;</span>,edge_attr=<span class="string">&#x27;weights&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;G:&quot;</span>,G)</span><br><span class="line"><span class="built_in">print</span>(nx.__version__)</span><br><span class="line"><span class="built_in">print</span>(nx.adjacency_matrix(G))</span><br><span class="line"><span class="comment">#度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;degree:&quot;</span>,nx.degree(G))</span><br><span class="line"><span class="comment"># 连通分量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;connected_components&quot;</span>,<span class="built_in">list</span>(nx.connected_components(G)))</span><br><span class="line"><span class="comment">#图直径</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;diameter:&quot;</span>,nx.diameter(G))</span><br><span class="line"><span class="comment"># 度中心性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;degree_centrality:&quot;</span>,nx.degree_centrality(G))</span><br><span class="line"><span class="comment">#特征向量中心性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;eigenvector:&quot;</span>,nx.eigenvector_centrality(G))</span><br><span class="line"><span class="comment"># betweenness 中介中心性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;betweenness:&quot;</span>,nx.betweenness_centrality(G))</span><br><span class="line"><span class="comment"># closeness 连接中心性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;closenesss:&quot;</span>,nx.closeness_centrality(G))</span><br><span class="line"><span class="comment">#pagerank</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pagerank:&quot;</span>,nx.pagerank(G))</span><br><span class="line"><span class="comment">#hits</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hits:&quot;</span>,nx.hits(G))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.</span><br><span class="line">  print(nx.adjacency_matrix(G))</span><br><span class="line">G: Graph with 6 nodes and 8 edges</span><br><span class="line">2.8.4</span><br><span class="line">  (0, 0)	1</span><br><span class="line">  (0, 2)	1</span><br><span class="line">  (0, 3)	1</span><br><span class="line">  (0, 4)	1</span><br><span class="line">  (1, 1)	1</span><br><span class="line">  (1, 4)	1</span><br><span class="line">  (1, 5)	1</span><br><span class="line">  (2, 0)	1</span><br><span class="line">  (2, 3)	1</span><br><span class="line">  (3, 0)	1</span><br><span class="line">  (3, 2)	1</span><br><span class="line">  (4, 0)	1</span><br><span class="line">  (4, 1)	1</span><br><span class="line">  (5, 1)	1</span><br><span class="line">degree: [(3, 5), (1, 4), (4, 2), (2, 2), (5, 2), (6, 1)]</span><br><span class="line">connected_components [&#123;1, 2, 3, 4, 5, 6&#125;]</span><br><span class="line">diameter: 4</span><br><span class="line">degree_centrality: &#123;3: 1.0, 1: 0.8, 4: 0.4, 2: 0.4, 5: 0.4, 6: 0.2&#125;</span><br><span class="line">eigenvector: &#123;3: 0.6845438993664699, 1: 0.2664667519552274, 4: 0.4038050904760662, 2: 0.4038050904760662, 5: 0.3528502881437044, 6: 0.09886704157967073&#125;</span><br><span class="line">betweenness: &#123;3: 0.6000000000000001, 1: 0.4, 4: 0.0, 2: 0.0, 5: 0.6000000000000001, 6: 0.0&#125;</span><br><span class="line">closenesss: &#123;3: 0.625, 1: 0.5, 4: 0.45454545454545453, 2: 0.45454545454545453, 5: 0.625, 6: 0.35714285714285715&#125;</span><br><span class="line">pagerank: &#123;3: 0.26059842893288254, 1: 0.22624644367910318, 4: 0.1397855189975688, 2: 0.1397855189975688, 5: 0.1444805278346477, 6: 0.08910356155822868&#125;</span><br><span class="line">hits: (&#123;3: 0.3097026575730737, 1: 0.1205522404859372, 4: 0.18269069072963665, 2: 0.18269069072963665, 5: 0.1596357156065535, 6: 0.04472800487516233&#125;, &#123;3: 0.30970265757307375, 1: 0.1205522404859372, 4: 0.1826906907296366, 2: 0.18269069072963656, 5: 0.1596357156065534, 6: 0.04472800487516234&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>视频来源：<a href="https://www.bilibili.com/video/BV1aB4y1Q7RL">https://www.bilibili.com/video/BV1aB4y1Q7RL</a></p>
<h1 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h1><p><a href="https://github.com/shenweichen/GraphEmbedding">代码</a></p>
<ol>
<li>DeepWalk :采用随机游走，形成序列，采用skip-gram方 式生成节点embedding。</li>
<li>node2vec :不同的随机游走策略，形成序列，类似skip-gram方 式生成节点embedding。</li>
<li>LINE :捕获节点的一-阶和二阶相似度，分别求解，再将一阶二阶拼接在一起， 作为节点的embedding</li>
<li>struc2vec :对图的结构信息进行捕获，在其结构重要性大于邻居重要性时，有较好的效果。</li>
<li>SDNE :采用了多个非线性层的方式捕获一阶二阶的相似性。</li>
</ol>
<h2 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h2><ul>
<li>适用于无向图</li>
</ul>
<p>随机游走获得节点序列</p>
<p>使用skipgram算法完成嵌入</p>
<p>window size d是向前向后看多少个节点</p>
<p>算法：</p>
<p><img src="/posts/5f3db67/image-20221126154802461.png" alt style="zoom: 50%;"></p>
<p>如下图：给定v4节点，算出v2,v3,v5,v6同时出现的概率。然后完成嵌入。</p>
<p><img src="/posts/5f3db67/image-20221126155109322.png" alt style="zoom:50%;"></p>
<ul>
<li><p>embedding效果对比，看参数作用</p>
<p>DeepWalk是无监督的完成图嵌入，效果判别通过将完成嵌入的图（有label)输入分类器,看分类效果</p>
<ul>
<li><p>embedding size d</p>
<p>d变大，效果</p>
<p>一定范围内上升，超过一定值，反而下降</p>
</li>
<li><p>迭代次数</p>
</li>
</ul>
</li>
</ul>
<p>​                迭代次数增加，效果上升；到达一定值再增加，效果变化有限</p>
<h2 id="LINE"><a href="#LINE" class="headerlink" title="LINE"></a>LINE</h2><p>large-scale Information Network Embedding</p>
<p>作者提出LINE用于大规模图上表示节点之间的结构信息表现比较好</p>
<ul>
<li><strong>一阶</strong>：局部的结构信息。</li>
<li><strong>二阶</strong>：节点的邻居。共享邻居的节点可能是相似的。</li>
</ul>
<p>一阶相似性：两个节点相连接，且边的权重很大，那么他们的一阶相似性很高</p>
<p>二阶相似性： 两个节点的邻居很相似，那么即使这两个节点没有相互连接，他们的二阶相似性也很大</p>
<p>如图，六节点和七节点一阶相似性高，五节点和六节点的embedding的二阶相似性很高：</p>
<p><img src="/posts/5f3db67/image-20221126160339470.png" alt style="zoom: 50%;"></p>
<ul>
<li><p>节点的度比较低的话，使用LINE效果不会很好</p>
</li>
<li><p>适用于有向图和无向图</p>
</li>
</ul>
<p>一阶和二阶embedding训练的loss：</p>
<p><img src="/posts/5f3db67/image-20221126163731692.png" alt style="zoom: 50%;"></p>
<p><img src="/posts/5f3db67/image-20221126163701508.png" alt style="zoom:50%;"></p>
<p>最后的embedding是一阶和二阶的直接拼接</p>
<h2 id="Node2Vec"><a href="#Node2Vec" class="headerlink" title="Node2Vec"></a>Node2Vec</h2><p>和DeepWalk相似，不同的是采用了有策略的游走</p>
<p>游走策略：</p>
<p><img src="/posts/5f3db67/image-20221126170021320.png" alt style="zoom:67%;"></p>
<p>DFS，即q值小，探索性强，会捕捉同质性节点，即相邻节点表示类似；BFS，即p值小，保守周围，会捕捉结构性，即某些节点的图上结构类似。</p>
<h2 id="struct2vec"><a href="#struct2vec" class="headerlink" title="struct2vec"></a>struct2vec</h2><p>之前的方式都是基于近邻，但是有些节点没有近邻也有结构相似性</p>
<h2 id="SDNE"><a href="#SDNE" class="headerlink" title="SDNE"></a>SDNE</h2><p>structural deep network embedding</p>
<p>涉及 autoencoder的思想</p>
]]></content>
      <categories>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>【pytorch-learning】(三) 可视化</title>
    <url>/posts/f19419c5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="tensorboard的使用"><a href="#tensorboard的使用" class="headerlink" title="tensorboard的使用"></a>tensorboard的使用</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install tensorboard</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="add-scalar"><a href="#add-scalar" class="headerlink" title="add_scalar"></a>add_scalar</h3><h4 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a><strong>运行代码</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span>  SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)<span class="comment"># 保存log的文件夾</span></span><br><span class="line"><span class="comment">##y=x</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>,<span class="number">2</span>*i,i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<h4 id="命令行运行：打开事件文件"><a href="#命令行运行：打开事件文件" class="headerlink" title="命令行运行：打开事件文件"></a><strong>命令行运行：打开事件文件</strong></h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=logs --port=6007</span><br></pre></td></tr></table></figure>
<p>tensorboard参数： —logdir=文件夹名称 —port=端口号 可以不设置端口号就是默认，为了避免冲突可以设置</p>
<p>由于多次添加，导致log文件中有各种，可能导致tensorboard显示曲线的一些拟合等。</p>
<p>解决：</p>
<ul>
<li>删除logs文件夹下的文件，重新运行程序。</li>
<li>对应每个任务每次都设立子文件夹。</li>
</ul>
<h4 id="浏览器查看"><a href="#浏览器查看" class="headerlink" title="浏览器查看"></a><strong>浏览器查看</strong></h4><p>网址在命令行有显示。前面示例的为 localhost:6007。</p>
<h3 id="add-image"><a href="#add-image" class="headerlink" title="add_image"></a>add_image</h3><p>图片</p>
<p>数据类型需要tensor或者numpy array</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span>  SummaryWriter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">img_path = <span class="string">&quot;./hymenoptera_data/hymenoptera_data/train/ants/0013035.jpg&quot;</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">img_array = np.array(img_PIL)</span><br><span class="line"><span class="built_in">print</span>(img_array.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(img_array))</span><br><span class="line">writer.add_image(<span class="string">&quot;test&quot;</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">&quot;HWC&quot;</span>)<span class="comment">##默认是CHW,如果不是需要进行设置</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<h3 id="add-graph"><a href="#add-graph" class="headerlink" title="add_graph"></a>add_graph</h3><p>可视化模型</p>
<ul>
<li>代码中使用tensorboard的add_graph将模型加入，注意传参需要传入模型输入。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">model = Model()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.ones(<span class="number">64</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>)</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs_seq&quot;</span>)</span><br><span class="line">writer.add_graph(model,<span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>命令行运行命令打开事件文件</p>
</li>
<li><p>浏览器查看模型，可以点击放大，看模型具体层</p>
</li>
</ul>
<p><img src="/posts/f19419c5/模型.png" alt="tensorboard查看"></p>
<h1 id="Visdom可视化"><a href="#Visdom可视化" class="headerlink" title="Visdom可视化"></a>Visdom可视化</h1><p>窗口视图，界面友好</p>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><ul>
<li>方式一</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install visdom</span><br></pre></td></tr></table></figure>
<p>命令行运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m visdom.server</span><br></pre></td></tr></table></figure>
<p>如果报错找不到路径，解决方式：在该目录下自己创建该文件夹</p>
<ul>
<li>安装方式2：避免download问题</li>
</ul>
<ol>
<li>pip uninstall visdom</li>
<li>从github下载visdom文件</li>
<li>cd 该目录下，pip install -e .</li>
<li>在项目路径下 python -m visdom.server成功启动</li>
</ol>
<h2 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h2><p>visdom的一些具体使用：<a href="https://blog.csdn.net/weixin_41010198/article/details/117853358">https://blog.csdn.net/weixin_41010198/article/details/117853358</a></p>
<h4 id="一个使用实例"><a href="#一个使用实例" class="headerlink" title="一个使用实例"></a><strong>一个使用实例</strong></h4><ol>
<li>命令行运行<code>python -m visdom.server</code>成功启动</li>
<li>运行代码</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">loss = torch.rand(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">global_step = torch.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">viz = Visdom()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">viz.line([<span class="number">0.</span>],[<span class="number">0.</span>],win=<span class="string">&#x27;train_loss&#x27;</span>,opts = <span class="built_in">dict</span>(title=<span class="string">&#x27;train_loss&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx,lossi <span class="keyword">in</span> <span class="built_in">enumerate</span>(loss):</span><br><span class="line">   </span><br><span class="line">    viz.line([lossi.item()],[idx],win = <span class="string">&#x27;train_loss&#x27;</span>,update=<span class="string">&#x27;append&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ol>
<li>浏览器查看</li>
</ol>
<p><img src="/posts/f19419c5/image-20221124200104212.png" alt="浏览器视图" style="zoom:67%;"></p>
<h4 id="完整模型训练测试过程中使用visdom可视化"><a href="#完整模型训练测试过程中使用visdom可视化" class="headerlink" title="完整模型训练测试过程中使用visdom可视化"></a>完整模型训练测试过程中使用visdom可视化</h4><p><a href="https://github.com/Xandra298/Pytorchlearning/tree/master/mnist data/MNIST">手写数字识别数据集</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">import</span>  torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span>  torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span>  torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span>    torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> visdom <span class="keyword">import</span> Visdom</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">200</span></span><br><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line">epochs=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./mnist data/&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       <span class="comment"># transforms.Normalize((0.1307,), (0.3081,))</span></span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./mnist data/&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># transforms.Normalize((0.1307,), (0.3081,))</span></span><br><span class="line">    ])),</span><br><span class="line">    batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">200</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">200</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">200</span>, <span class="number">10</span>),</span><br><span class="line">            nn.LeakyReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">net = MLP().to(device)</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=learning_rate)</span><br><span class="line">criteon = nn.CrossEntropyLoss().to(device)</span><br><span class="line"></span><br><span class="line">viz = Visdom()</span><br><span class="line"></span><br><span class="line">viz.line([<span class="number">0.</span>], [<span class="number">0.</span>], win=<span class="string">&#x27;train_loss&#x27;</span>, opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;train loss&#x27;</span>))</span><br><span class="line">viz.line([[<span class="number">0.0</span>, <span class="number">0.0</span>]], [<span class="number">0.</span>], win=<span class="string">&#x27;test&#x27;</span>, opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;test loss&amp;acc.&#x27;</span>,</span><br><span class="line">                                                   legend=[<span class="string">&#x27;loss&#x27;</span>, <span class="string">&#x27;acc.&#x27;</span>]))</span><br><span class="line">global_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">        logits = net(data)</span><br><span class="line">        loss = criteon(logits, target)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># print(w1.grad.norm(), w2.grad.norm())</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        global_step += <span class="number">1</span></span><br><span class="line">        viz.line([loss.item()], [global_step], win=<span class="string">&#x27;train_loss&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data = data.view(-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        data, target = data.to(device), target.cuda()</span><br><span class="line">        logits = net(data)</span><br><span class="line">        test_loss += criteon(logits, target).item()</span><br><span class="line"></span><br><span class="line">        pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct += pred.eq(target).<span class="built_in">float</span>().<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    viz.line([[test_loss, correct / <span class="built_in">len</span>(test_loader.dataset)]],</span><br><span class="line">             [global_step], win=<span class="string">&#x27;test&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    viz.images(data.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), win=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    viz.text(<span class="built_in">str</span>(pred.detach().cpu().numpy()), win=<span class="string">&#x27;pred&#x27;</span>,</span><br><span class="line">             opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;pred&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>视图</li>
</ul>
<p>​        <img src="/posts/f19419c5/image-20221124201948485.png" alt="image-20221124201948485"></p>
<h2 id="端口占用处理"><a href="#端口占用处理" class="headerlink" title="端口占用处理"></a>端口占用处理</h2><p>windows上</p>
<ul>
<li>查找本端口当前使用情况</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">netstat -ano |findstr &quot;8097&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TCP    0.0.0.0:8097           0.0.0.0:0              LISTENING       12236</span><br><span class="line">  TCP    [::]:8097              [::]:0                 LISTENING       12236</span><br></pre></td></tr></table></figure>
<ul>
<li>查询当前端口PID的进程，前一步看到为12236</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tasklist | findstr 12236</span><br></pre></td></tr></table></figure>
<ul>
<li>终止进程</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">taskkill /f /t /im &quot;12236&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">成功: 已终止 PID 12236 (属于 PID 7560 子进程)的进程。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>【pytorch-learning】(二) 模型搭建-训练-测试</title>
    <url>/posts/13fc6476/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h1><h2 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h2><p>基本骨架为 <code>torch.nn.Module</code></p>
<span id="more"></span>
<p>实现一个继承自Module的类，该类中主要包含init和forward方法。</p>
<p>通过forward方法完成网络的前向传递。</p>
<p>详细讲解见我记的B站小土堆的笔记：<a href="https://github.com/Xandra298/Pytorchlearning/blob/master/小土堆/1.2pytorch使用_神经网络搭建.ipynb">神经网络搭建</a></p>
<p>一个简单的代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;dataset/&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),download= <span class="literal">True</span>)</span><br><span class="line">dataloader  = DataLoader(dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model_conv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model_conv, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">3</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span>  x</span><br><span class="line"></span><br><span class="line">model = Model_conv()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs,target = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>torch.nn.Sequential</code>使用示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Linear, Sequential</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">model = Model()</span><br></pre></td></tr></table></figure>
<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>修改已有网络模型用于自己的任务</p>
<h3 id="实例一：将VGG16用于数据集CIFAR10的分类"><a href="#实例一：将VGG16用于数据集CIFAR10的分类" class="headerlink" title="实例一：将VGG16用于数据集CIFAR10的分类"></a>实例一：将VGG16用于数据集CIFAR10的分类</h3><p>VGG16<a href="https://pytorch.org/vision/0.9/models.html">模型</a> 的dataset是<a href="https://pytorch.org/vision/0.8/datasets.html#imagenet">ImagNet</a></p>
<p>通过torchvision.models.vgg16(pretained=True)(pretained=True会将其权重也下载下来）将模型下载下来之后，默认保存路径是<code>C:\Users\[usename].cache\torch\hub\checkpoints</code></p>
<p>VGG16用于1000分类（最后全连接层的输出是1000），使用数据集CIFAR10是需要10分类的。因此难点在于如何使用该VGG模型进行迁移。 下文代码展现了两种主要方式</p>
<h4 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="comment"># vgg16_false = torchvision.models.vgg16(pretrained=False)</span></span><br><span class="line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;dataset&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">##traindata是10分类，而vgg16是1000分类</span></span><br><span class="line"></span><br><span class="line">vgg16_true.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16_true)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>VGG模型添加了一层之后的结构</p>
<p>多了一层添加的：</p>
<p><code>(add_linear): Linear(in_features=1000, out_features=10, bias=True)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (1): ReLU(inplace=True)</span><br><span class="line">    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (3): ReLU(inplace=True)</span><br><span class="line">    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (6): ReLU(inplace=True)</span><br><span class="line">    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (8): ReLU(inplace=True)</span><br><span class="line">    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (11): ReLU(inplace=True)</span><br><span class="line">    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (13): ReLU(inplace=True)</span><br><span class="line">    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (15): ReLU(inplace=True)</span><br><span class="line">    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (18): ReLU(inplace=True)</span><br><span class="line">    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (20): ReLU(inplace=True)</span><br><span class="line">    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (22): ReLU(inplace=True)</span><br><span class="line">    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (25): ReLU(inplace=True)</span><br><span class="line">    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (27): ReLU(inplace=True)</span><br><span class="line">    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (29): ReLU(inplace=True)</span><br><span class="line">    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Linear(in_features=25088, out_features=4096, bias=True)</span><br><span class="line">    (1): ReLU(inplace=True)</span><br><span class="line">    (2): Dropout(p=0.5, inplace=False)</span><br><span class="line">    (3): Linear(in_features=4096, out_features=4096, bias=True)</span><br><span class="line">    (4): ReLU(inplace=True)</span><br><span class="line">    (5): Dropout(p=0.5, inplace=False)</span><br><span class="line">    (6): Linear(in_features=4096, out_features=1000, bias=True)</span><br><span class="line">  )</span><br><span class="line">  (add_linear): Linear(in_features=1000, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h4><p>想要加到其中的classifier里面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vgg16_true.classifier.add_module(<span class="string">&#x27;add_linear&#x27;</span>,nn.Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h3 id="实例二：resnet18"><a href="#实例二：resnet18" class="headerlink" title="实例二：resnet18"></a>实例二：resnet18</h3><p>获取网络中的模型，通过Sequential完成新模型的组建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18 <span class="comment">##从网络获取模型</span></span><br><span class="line">trained_model = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">                <span class="comment">#*用于迭代取出list中的内容</span></span><br><span class="line">model = nn.Sequential(*<span class="built_in">list</span>(trained_model.children())[:-<span class="number">1</span>],<span class="comment">#[b,512,1,1]</span></span><br><span class="line">                          nn.Flatten(),<span class="comment">#[b,512,1,1]=&gt;[b,512]</span></span><br><span class="line">                          nn.Linear(<span class="number">512</span>,<span class="number">5</span>)</span><br><span class="line">                          ).to(device)</span><br></pre></td></tr></table></figure>
<h1 id="模型保存和读取"><a href="#模型保存和读取" class="headerlink" title="模型保存和读取"></a>模型保存和读取</h1><h2 id="方式一-1"><a href="#方式一-1" class="headerlink" title="方式一"></a>方式一</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ##保存方式1 模型结构+模型参数</span></span><br><span class="line"><span class="comment"># ### 参数：模型，路径</span></span><br><span class="line"></span><br><span class="line">torch.save(vgg16,<span class="string">&quot;vgg16_modelsave_1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">###读取方式1&gt;&gt;保存方式1</span></span><br><span class="line"><span class="comment">##参数：路径</span></span><br><span class="line">model = torch.load(<span class="string">&quot;vgg16_modelsave_1.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>
<h2 id="方式二（推荐）"><a href="#方式二（推荐）" class="headerlink" title="方式二（推荐）"></a>方式二（推荐）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#保存方式2 模型参数（官方推荐）</span></span><br><span class="line"><span class="comment">##参数：模型.state_dict(),路径</span></span><br><span class="line"><span class="comment">##527M</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg16_modelsave_2.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##读取方式2&gt;&gt;保存方式2</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg16_modelsave_2.pth&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br></pre></td></tr></table></figure>
<h2 id="方式一的报错实例"><a href="#方式一的报错实例" class="headerlink" title="方式一的报错实例"></a>方式一的报错实例</h2><p>报错过程：</p>
<ol>
<li><p>a.py中创建模型，并使用toch.save(model,”model path”)</p>
</li>
<li><p>b.py中加载该模型：model = torch.load(“model path”)</p>
</li>
</ol>
<p>解决方案：要让该文件能访问到该模型的定义。</p>
<ul>
<li><p>在直接加载前重新定义一下该模型</p>
</li>
<li><p>或者 <code>from model_save import *</code> 即在头文件import一下该模型定义文件</p>
</li>
</ul>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p><a href="https://github.com/Xandra298/Pytorchlearning/blob/master/4.随机梯度下降.ipynb">详细理论</a>)</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>通过损失函数计算经过训练的模型其预测结果与真实值的误差，loss越小说明二者越接近。</p>
<p>通过梯度下降搜索极值点。计算loss，通过loss.backward()反向传播进行自动求导获得梯度。</p>
<p>对于模型而言，变化的是各个权重参数w。</p>
<p><a href="https://pytorch.org/docs/1.8.1/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">CrossEntropyLoss</a></p>
<p>使用实例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span>  nn</span><br><span class="line">x = torch.tensor([<span class="number">0.1</span>,<span class="number">0.8</span>,<span class="number">0.1</span>])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">x = x.reshape(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">loss_cross = nn.CrossEntropyLoss()</span><br><span class="line">result_cross = loss_cross(x,y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>决定梯度下降的方式。</p>
<p>使用主要关联四行代码：</p>
<ul>
<li><code>optim = torch.optim.SGD(model.parameters(),lr=0.01)</code>  （SGD为一种优化器）</li>
</ul>
<p>epoch 内</p>
<ul>
<li><code>optim.zero_grad()</code> ##将优化器梯度清零，每一次循环注意清零</li>
<li><code>result_loss.backward()</code></li>
<li><code>optim.step()</code></li>
</ul>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;----epoch &#123;&#125; starting----&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment">##训练步骤开始</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs,targets = data</span><br><span class="line">        outputs = model(imgs)</span><br><span class="line">        loss = loss_fn(outputs,targets)</span><br><span class="line"></span><br><span class="line">        <span class="comment">##优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_train_step+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">           <span class="built_in">print</span>(<span class="string">&quot;batch &#123;&#125;---loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step,loss.item()))</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="模型测试评估"><a href="#模型测试评估" class="headerlink" title="模型测试评估"></a>模型测试评估</h1><p>将测试集传入训练好的模型得到预测输出。</p>
<p>将预测输出和测试集的label进行比较以评估该模型。</p>
<p>有标签的评估指标有：</p>
<ul>
<li>准确率</li>
<li>召回率</li>
<li>精确率</li>
<li>F1-score</li>
<li>…</li>
</ul>
<p>另外，如ROC曲线，AUC，AP等也是常见的评估</p>
<h1 id="自定义数据集实战"><a href="#自定义数据集实战" class="headerlink" title="自定义数据集实战"></a>自定义数据集实战</h1><h2 id="数据预处理与加载"><a href="#数据预处理与加载" class="headerlink" title="数据预处理与加载"></a>数据预处理与加载</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os,glob</span><br><span class="line"><span class="keyword">import</span> random,csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pokemen</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root,resize,mode</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param root: 数据集根目录；</span></span><br><span class="line"><span class="string">                    这次的存储形式是根目录下有文件夹，每个文件夹下是数据集图片，文件夹名称是对应的类别</span></span><br><span class="line"><span class="string">        :param resize:</span></span><br><span class="line"><span class="string">        :param mode: train\test\val</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Pokemen, self).__init__()</span><br><span class="line">        self.root = root</span><br><span class="line">        self.resize = resize</span><br><span class="line"></span><br><span class="line">        self.name2label = &#123;&#125;<span class="comment"># 存储name对应编码的字典</span></span><br><span class="line">        <span class="comment">#遍历根目录下文件夹名称</span></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(os.path.join(root))):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root,name)):</span><br><span class="line">                <span class="comment"># not a dir</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 按照先后顺序获得编码</span></span><br><span class="line">            self.name2label[name] = <span class="built_in">len</span>(self.name2label.keys())</span><br><span class="line">        <span class="built_in">print</span>(self.name2label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从csv文件中读取 image_path-label；</span></span><br><span class="line">        <span class="comment"># load_csv方法实现将数据集条目：image_path-label 整理到csv文件中</span></span><br><span class="line">        self.images,self.labels = self.load_csv(<span class="string">&quot;image.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#划分数据集</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>: <span class="comment">#60%</span></span><br><span class="line">            self.images = self.images[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;val&#x27;</span>: <span class="comment">#20%</span></span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.images)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.labels)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.images)):]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.labels)):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_csv</span>(<span class="params">self,filename</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        将数据集的image_path-label存储到csv文件中，并从csv文件加载</span></span><br><span class="line"><span class="string">        :param filename: 存储csv的文件路径</span></span><br><span class="line"><span class="string">        :return: images,labels==&gt; images_path,labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        savepath = os.path.join(self.root,filename)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">            images = []</span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> self.name2label.keys():</span><br><span class="line">                <span class="comment">#获取对应文件夹下的图片文件,存储到list(images)内</span></span><br><span class="line">                images += glob.glob(os.path.join(self.root,name,<span class="string">&#x27;*.png&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.gif&#x27;</span>))</span><br><span class="line">            <span class="comment">#print(images)</span></span><br><span class="line">            <span class="comment">#&#x27;./pokeman/squirtle\\00000073.png&#x27;</span></span><br><span class="line">            random.shuffle(images) <span class="comment">#shuffle</span></span><br><span class="line">            <span class="comment">#写入csv</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(savepath,mode=<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                writer = csv.writer(f)</span><br><span class="line">                <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">                    name = img.split(os.sep)[-<span class="number">2</span>]</span><br><span class="line">                    label = self.name2label[name]</span><br><span class="line">                    writer.writerow([img,label])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;written into csv file:&#x27;</span>,savepath)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#从csv文件读取</span></span><br><span class="line">        images,labels = [],[]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(savepath) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">                img,label = row</span><br><span class="line">                label = <span class="built_in">int</span>(label)</span><br><span class="line">                images.append(img)</span><br><span class="line">                labels.append(label)</span><br><span class="line">        <span class="keyword">assert</span>  <span class="built_in">len</span>(images) == <span class="built_in">len</span>(labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span>  images,labels</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :return: 数据集长度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :param item: range in [0,len(images)]</span></span><br><span class="line"><span class="string">        :return: self.images,self.labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">        img,label = self.images[item],self.labels[item]</span><br><span class="line">        </span><br><span class="line">        tf = transforms.Compose(</span><br><span class="line">            [<span class="keyword">lambda</span> x:Image.<span class="built_in">open</span>(x).convert(<span class="string">&#x27;RGB&#x27;</span>), <span class="comment"># open image and convert to RGB</span></span><br><span class="line">             transforms.Resize((<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>),<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>))),</span><br><span class="line">             transforms.RandomRotation(<span class="number">15</span>),</span><br><span class="line">             transforms.CenterCrop(self.resize),</span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>]),<span class="comment">#values computed from ImageNet，we could use it in other dataset   </span></span><br><span class="line">             </span><br><span class="line">             ]  </span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        img = tf(img)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line">db = Pokemon(<span class="string">&#x27;./pokeman&#x27;</span>, <span class="number">224</span>, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(x.shape,y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;.ipynb_checkpoints&#39;: 0, &#39;bulbasaur&#39;: 1, &#39;charmander&#39;: 2, &#39;mewtwo&#39;: 3, &#39;pikachu&#39;: 4, &#39;squirtle&#39;: 5&#125;
written into csv file:  ./pokeman\image.csv
torch.Size([3, 224, 224]) torch.Size([])
</code></pre><h3 id="数据集加载：DataLoader"><a href="#数据集加载：DataLoader" class="headerlink" title="数据集加载：DataLoader"></a>数据集加载：DataLoader</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  visdom</span><br><span class="line"><span class="keyword">import</span>  torchvision</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">db = Pokemon(<span class="string">&#x27;./pokeman&#x27;</span>, <span class="number">224</span>, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(x.shape,y.shape)</span><br><span class="line">loader = DataLoader(db,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="网络创建"><a href="#网络创建" class="headerlink" title="网络创建"></a>网络创建</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Resnet.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span>  torch <span class="keyword">import</span>  nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResBlk</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    resnet block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,ch_in,ch_out,stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param ch_in:[b,ch,h,w]</span></span><br><span class="line"><span class="string">        :param ch_out:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ResBlk, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=<span class="number">3</span>,stride=stride,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(ch_out)</span><br><span class="line">        self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(ch_out)</span><br><span class="line"></span><br><span class="line">        self.extra = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ch_out!=ch_in:</span><br><span class="line">            self.extra = nn.Sequential(</span><br><span class="line">                nn.Conv2d(ch_in,ch_out,kernel_size=<span class="number">1</span>,stride=stride),</span><br><span class="line">                nn.BatchNorm2d(ch_out)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out =  F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.bn2(self.conv2(out))</span><br><span class="line"></span><br><span class="line">        <span class="comment">##short cut</span></span><br><span class="line">        <span class="comment">#extra module:[b,ch_in,h,w]=&gt;[b,ch_out,h,w]</span></span><br><span class="line">        <span class="comment">#element-wise add</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        out = self.extra(x) +out</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet18</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_class</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet18, self).__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>,<span class="number">16</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">3</span>,padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#followed 4 blocks</span></span><br><span class="line">        <span class="comment">#[b,16,h,w]=&gt;[b,32,h,w]</span></span><br><span class="line">        self.blk1 =ResBlk(<span class="number">16</span>,<span class="number">32</span>,stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># [b,32,h,w]=&gt;[b,64,h,w]</span></span><br><span class="line">        self.blk2 = ResBlk(<span class="number">32</span>,<span class="number">64</span>,stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment">#[b,64,h,w]=&gt;[b,128,h,w]</span></span><br><span class="line">        self.blk3 = ResBlk(<span class="number">64</span>,<span class="number">128</span>,stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># [b,128,h,w]=&gt;[b,256,h,w]</span></span><br><span class="line">        self.blk4 = ResBlk(<span class="number">128</span>,<span class="number">256</span>,stride=<span class="number">2</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.outlayer = nn.Linear(<span class="number">256</span>*<span class="number">3</span>*<span class="number">3</span>,num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="comment">#[b,64,h,w]=&gt;[b,1024,h,w]</span></span><br><span class="line">        x = self.blk1(x)</span><br><span class="line">        x = self.blk2(x)</span><br><span class="line">        x = self.blk3(x)</span><br><span class="line">        x = self.blk4(x)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;after conv:&quot;</span>,x.shape)</span><br><span class="line">        <span class="comment"># x = F.adaptive_max_pool2d(x,[1,1])</span></span><br><span class="line">        <span class="comment"># print(&quot;after pool,&quot;,x.shape)</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.outlayer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    blk = ResBlk(<span class="number">64</span>,<span class="number">128</span>)</span><br><span class="line">    tmp = torch.rand(<span class="number">2</span>,<span class="number">64</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    out = blk(tmp)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;block&#x27;</span>,out.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    x  = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    model = ResNet18(<span class="number">5</span>)</span><br><span class="line">    out = model(x)</span><br><span class="line">    <span class="built_in">print</span>(out.shape)</span><br><span class="line"></span><br><span class="line">    p = <span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span>  p:p.numel(),model.parameters()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;parameters size:&#x27;</span>,p)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Train-and-test"><a href="#Train-and-test" class="headerlink" title="Train and test"></a>Train and test</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    train(train_db)</span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        val_acc = evaluate(val_db)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> val_loss <span class="keyword">is</span> the best:</span><br><span class="line">            save_ckpt()</span><br><span class="line">        <span class="keyword">if</span> out_of_patience():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">load_ckpt()<span class="comment"># checkpoint model</span></span><br><span class="line">test_acc = evaluate(test_db)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#train_scratch.py</span></span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim,nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pokeman <span class="keyword">import</span> Pokemon</span><br><span class="line"><span class="keyword">from</span> Resnet <span class="keyword">import</span> ResNet18</span><br><span class="line"></span><br><span class="line">batchsz = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1234</span>)<span class="comment">##随机种子</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">val_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">test_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(train_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>)</span><br><span class="line">val_loader = DataLoader(val_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">test_loader = DataLoader(test_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model,loader</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">len</span>(loader.dataset)</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> loader:</span><br><span class="line">        x,y = x.to(device),y.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(x)</span><br><span class="line">            pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct += torch.eq(pred,y).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">    <span class="keyword">return</span> correct/total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    model = ResNet18(<span class="number">5</span>).to(device)</span><br><span class="line">    optimizer = optim.Adam(model.parameters(),lr=lr)</span><br><span class="line">    criteon = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    best_acc,best_epoch=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    global_step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> step,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># x:[b,3,224,224], y:[5]</span></span><br><span class="line">            img,label = img.to(device),label.to(device)</span><br><span class="line"></span><br><span class="line">            logits = model(img)</span><br><span class="line">            loss = criteon(logits,label)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">          </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            val_acc = evaluate(model,val_loader)</span><br><span class="line">            <span class="keyword">if</span> val_acc&gt;best_acc:</span><br><span class="line">                best_epoch = epoch</span><br><span class="line">                best_acc = val_acc</span><br><span class="line"></span><br><span class="line">                torch.save(model.state_dict(),<span class="string">&#x27;best.mdl&#x27;</span>)</span><br><span class="line">            viz.line([val_acc], [epoch], win=<span class="string">&#x27;val_acc&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;best acc:&#x27;</span>,best_acc,<span class="string">&#x27;best epoch&#x27;</span>,best_epoch)</span><br><span class="line"></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;best.mdl&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;loaded from checkpoint!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    test_acc = evaluate(model,test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;test acc&#x27;</span>,test_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>best acc: 0.8583690987124464 best epoch 5</p>
<p>test acc 0.8497854077253219</p>
<h1 id="optional-迁移学习"><a href="#optional-迁移学习" class="headerlink" title="optional: 迁移学习"></a>optional: 迁移学习</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim,nn</span><br><span class="line"><span class="keyword">import</span>  visdom</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pokeman <span class="keyword">import</span> Pokemon</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18 <span class="comment">##从网络获取模型</span></span><br><span class="line"></span><br><span class="line">batchsz = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1234</span>)<span class="comment">##随机种子</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">val_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">test_db = Pokemon(<span class="string">&#x27;pokeman&#x27;</span>,<span class="number">224</span>,mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(train_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">4</span>)</span><br><span class="line">val_loader = DataLoader(val_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">test_loader = DataLoader(test_db,batch_size=batchsz,shuffle=<span class="literal">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">viz = visdom.Visdom()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model,loader</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">len</span>(loader.dataset)</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> loader:</span><br><span class="line">        x,y = x.to(device),y.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(x)</span><br><span class="line">            pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">        correct = torch.eq(pred,y).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">    <span class="keyword">return</span> correct/total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># model = ResNet18(5).to(device)</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------------------------</span></span><br><span class="line">    trained_model = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">                <span class="comment">#*用于迭代取出list中的内容</span></span><br><span class="line">    model = nn.Sequential(*<span class="built_in">list</span>(trained_model.children())[:-<span class="number">1</span>],<span class="comment">#[b,512,1,1]</span></span><br><span class="line">                          nn.Flatten(),<span class="comment">#[b,512,1,1]=&gt;[b,512]</span></span><br><span class="line">                          nn.Linear(<span class="number">512</span>,<span class="number">5</span>)</span><br><span class="line">                          ).to(device)</span><br><span class="line">    <span class="comment"># x = torch.rand(2,3,224,224)</span></span><br><span class="line">    <span class="comment"># print(model(x).shape)</span></span><br><span class="line">    <span class="comment">#---------------------------------------------------------------------------------------</span></span><br><span class="line">    optimizer = optim.Adam(model.parameters(),lr=lr)</span><br><span class="line">    criteon = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    best_acc,best_epoch=<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    viz.line([<span class="number">0</span>],[-<span class="number">1</span>],win=<span class="string">&#x27;loss&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;loss&#x27;</span>))</span><br><span class="line">    viz.line([<span class="number">0</span>],[-<span class="number">1</span>],win=<span class="string">&#x27;val_acc&#x27;</span>,opts=<span class="built_in">dict</span>(title=<span class="string">&#x27;val_acc&#x27;</span>))</span><br><span class="line">    global_step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> step,(img,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># x:[b,3,224,224], y:[5]</span></span><br><span class="line">            img,label = img.to(device),label.to(device)</span><br><span class="line"></span><br><span class="line">            logits = model(img)</span><br><span class="line">            loss = criteon(logits,label)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            viz.line([loss.item()], [global_step], win=<span class="string">&#x27;loss&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">            global_step+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">1</span> ==<span class="number">0</span>:</span><br><span class="line">            val_acc = evaluate(model,val_loader)</span><br><span class="line">            <span class="keyword">if</span> val_acc&gt;best_acc:</span><br><span class="line">                best_epoch = epoch</span><br><span class="line">                best_acc = val_acc</span><br><span class="line"></span><br><span class="line">                torch.save(model.state_dict(),<span class="string">&#x27;best.mdl&#x27;</span>)</span><br><span class="line">            viz.line([val_acc], [epochs], win=<span class="string">&#x27;val_acc&#x27;</span>, update=<span class="string">&#x27;append&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;best acc:&#x27;</span>,best_acc,<span class="string">&#x27;best epoch&#x27;</span>,best_epoch)</span><br><span class="line"></span><br><span class="line">    model.load_state_dict(torch.load(<span class="string">&#x27;best.mdl&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;loaded from checkpoint!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    test_acc = evaluate(model,test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;test acc&#x27;</span>,test_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>best acc: 0.8412017167381974 best epoch 8</p>
<p>test acc 0.8025751072961373</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>【pytorch learning】(一)自定义数据集预处理和加载</title>
    <url>/posts/a0ca199b/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="通用实现"><a href="#通用实现" class="headerlink" title="通用实现"></a>通用实现</h1><p>关键库：Dataset和 DataLoader</p>
<p><code>from torch.utils.data import  Dataset,DataLoader</code></p>
<p>代码使用数据集：<a href="https://github.com/Xandra298/Pytorchlearning/tree/master/pokeman">宝可梦</a></p>
<span id="more"></span>
<p>该数据集目录格式为：</p>
<p> root dir:</p>
<ul>
<li>dir1(name is the class)<ul>
<li>pic1</li>
<li>pic2</li>
<li>…</li>
</ul>
</li>
<li>dir2(name is the class)<ul>
<li>…</li>
</ul>
</li>
</ul>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>继承Dataset类的实现</p>
<p>需要重载方法：</p>
<ul>
<li>__len__:返回数据集长度（数据数量）</li>
<li>__get_item__：获取数据集的item</li>
</ul>
<p>关键思路：具体见代码及代码注释</p>
<p>自定义方法load_csv:</p>
<ol>
<li>遍历目录，将image_path-label存储到csv文件中：</li>
</ol>
<ul>
<li>用<code>glob.glob</code>获取具体路径的数据路径</li>
<li><code>csv.writer(f)</code>将image_path,label写入csv文件</li>
</ul>
<ol>
<li>读取csv文件，获得image_path-label</li>
</ol>
<ul>
<li>reader = <code>csv.reader(f)</code>，for row in reader:…</li>
</ul>
<p>len方法：</p>
<ul>
<li>返回数据集长度</li>
</ul>
<p>get_item方法：</p>
<ul>
<li><p>传入index,从我们全局的列表中获得对应的数据</p>
</li>
<li><p>通过读取csv文件，传入index, 可以获得对应的image_path - label对。</p>
<p>目标：载入image_path，处理图片，返回符合要求的图片数据和label对</p>
</li>
<li><p>处理从路径上读取的数据，返回指定格式。如使用<code>torchvision.transform</code>，最后处理完的格式是tensor</p>
</li>
<li><p>返回数据和label对</p>
</li>
</ul>
<p>关于mode，可以通过判断需要训练集或者测试集这样子，返回切分后的数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os,glob</span><br><span class="line"><span class="keyword">import</span> random,csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pokemen</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root,resize,mode</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param root: root dir of dataset</span></span><br><span class="line"><span class="string">                    root dir:</span></span><br><span class="line"><span class="string">                        - dir1(name is the class)</span></span><br><span class="line"><span class="string">                            - pic1</span></span><br><span class="line"><span class="string">                            - pic2</span></span><br><span class="line"><span class="string">                            - ...</span></span><br><span class="line"><span class="string">                        - dir2(name is the class)</span></span><br><span class="line"><span class="string">                        - ...</span></span><br><span class="line"><span class="string">        :param resize:</span></span><br><span class="line"><span class="string">        :param mode: train\test\val</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Pokemen, self).__init__()</span><br><span class="line">        self.root = root</span><br><span class="line">        self.resize = resize</span><br><span class="line"></span><br><span class="line">        self.name2label = &#123;&#125;<span class="comment">#  save the dict &#123;name:int&#125; </span></span><br><span class="line">        <span class="comment">#list the dir name under the root dir</span></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(os.path.join(root))): <span class="comment"># sorted to ensure every time to be the same</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root,name)):</span><br><span class="line">                <span class="comment"># not a dir</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># get the name:int following the order</span></span><br><span class="line">            self.name2label[name] = <span class="built_in">len</span>(self.name2label.keys())</span><br><span class="line">        <span class="built_in">print</span>(self.name2label)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># read from csv: image_path-label；</span></span><br><span class="line">        <span class="comment"># function load_csv：save the image_path-label to csv and then read from csv</span></span><br><span class="line">        self.images,self.labels = self.load_csv(<span class="string">&quot;image.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#split dataset</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>: <span class="comment">#60%</span></span><br><span class="line">            self.images = self.images[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[:<span class="built_in">int</span>(<span class="number">0.6</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;val&#x27;</span>: <span class="comment">#20%</span></span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.images)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.images))]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.6</span> * <span class="built_in">len</span>(self.labels)):<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(self.labels))]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.images = self.images[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.images)):]</span><br><span class="line">            self.labels = self.labels[<span class="built_in">int</span>(<span class="number">0.8</span> * <span class="built_in">len</span>(self.labels)):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_csv</span>(<span class="params">self,filename</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        save image_path-label to csv(if csv exits,just read from it) ，and then read from it</span></span><br><span class="line"><span class="string">        :param filename: filepath of the csv to save and read</span></span><br><span class="line"><span class="string">        :return: images,labels==&gt; images_path,labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        savepath = os.path.join(self.root,filename)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(savepath):</span><br><span class="line">            images = []</span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> self.name2label.keys():</span><br><span class="line">                <span class="comment">#grop the pic, save to list</span></span><br><span class="line">                images += glob.glob(os.path.join(self.root,name,<span class="string">&#x27;*.png&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line">                images += glob.glob(os.path.join(self.root, name, <span class="string">&#x27;*.gif&#x27;</span>))</span><br><span class="line">            <span class="comment">#print(images)</span></span><br><span class="line">            <span class="comment">#&#x27;./pokeman/squirtle\\00000073.png&#x27;</span></span><br><span class="line">            random.shuffle(images) <span class="comment">#shuffle</span></span><br><span class="line">            <span class="comment">#write into csv</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(savepath,mode=<span class="string">&#x27;w&#x27;</span>,newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                writer = csv.writer(f)</span><br><span class="line">                <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">                    name = img.split(os.sep)[-<span class="number">2</span>]</span><br><span class="line">                    label = self.name2label[name]</span><br><span class="line">                    writer.writerow([img,label])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;written into csv file:&#x27;</span>,savepath)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#read from csv</span></span><br><span class="line">        images,labels = [],[]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(savepath) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">                img,label = row</span><br><span class="line">                label = <span class="built_in">int</span>(label)</span><br><span class="line">                images.append(img)</span><br><span class="line">                labels.append(label)</span><br><span class="line">        <span class="keyword">assert</span>  <span class="built_in">len</span>(images) == <span class="built_in">len</span>(labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>  images,labels</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :return: len of dataset</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param item: range in [0,len(images)]</span></span><br><span class="line"><span class="string">        :return: self.images,self.labels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        img,label = self.images[item],self.labels[item]</span><br><span class="line"></span><br><span class="line">        tf = transforms.Compose(</span><br><span class="line">            [<span class="keyword">lambda</span> x:Image.<span class="built_in">open</span>(x).convert(<span class="string">&#x27;RGB&#x27;</span>), <span class="comment"># open image and convert to RGB</span></span><br><span class="line">             transforms.Resize((<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>),<span class="built_in">int</span>(self.resize*<span class="number">1.25</span>))), <span class="comment"># resize</span></span><br><span class="line">             transforms.RandomRotation(<span class="number">15</span>), <span class="comment"># rotate</span></span><br><span class="line">             transforms.CenterCrop(self.resize), <span class="comment">#center crop</span></span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize(mean=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>]),<span class="comment">#values computed from ImageNet，we could use it in other dataset</span></span><br><span class="line"></span><br><span class="line">             ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        img = tf(img)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">denormalize</span>(<span class="params">self,x_hat</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        x_hat = (x - mean)/std</span></span><br><span class="line"><span class="string">        x = x_hat * std + mean</span></span><br><span class="line"><span class="string">        :param x_hat: shape[3,self.resize,self.resize]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">        std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        mean = torch.tensor(mean).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        std = torch.tensor(std).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = x_hat*std+mean</span><br><span class="line">        <span class="keyword">return</span>  x</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># dataset</span></span><br><span class="line">    db_train = Pokemen(root=<span class="string">&#x27;pokeman&#x27;</span>,resize=<span class="number">224</span>,mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    <span class="comment"># dataloader</span></span><br><span class="line">    dl_train = DataLoader(dataset=db_train,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line">    x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(dl_train))</span><br><span class="line">    <span class="built_in">print</span>(x.shape,y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;.ipynb_checkpoints&#39;: 0, &#39;bulbasaur&#39;: 1, &#39;charmander&#39;: 2, &#39;mewtwo&#39;: 3, &#39;pikachu&#39;: 4, &#39;squirtle&#39;: 5&#125;
written into csv file: pokeman\image.csv
torch.Size([32, 3, 224, 224]) torch.Size([32])
</code></pre><h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p>传入数据集，处理为batch。主要参数：batch_size</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dl_train = DataLoader(dataset=db_train,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>其他常用参数：</p>
<ul>
<li>num_workers ( int, optional): how many subprocesses to use for data loading. <code>0</code> means that the data will be loaded in the main process. (default: <code>0</code>)</li>
<li>drop_last (bool, optional): set to <code>True</code> to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If <code>False</code> and  the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: <code>False</code>)</li>
</ul>
<p>官方文档：<a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">torch.utils.data — PyTorch 1.13 documentation</a></p>
<p>dl_train返回的参数对应dataset get_item的return 参数</p>
<ul>
<li><p><code>x,y = next(iter(dataset))</code></p>
</li>
<li><p><code>X,Y = next(iter(dataloader))</code></p>
</li>
</ul>
<p>X.shape == (batchsize,x.shape)</p>
<p><strong>进行训练时的一般模式：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> idx,(x,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl_train):</span><br><span class="line">	x,label = x.to(device),y.to(device)</span><br><span class="line">	pred = model(x)</span><br><span class="line">	loss = lossFunction(pred,label)</span><br><span class="line">	optimizer.zero_grad()</span><br><span class="line">	loss.backward()</span><br><span class="line">	loss.step()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="特殊便捷方式数据集加载"><a href="#特殊便捷方式数据集加载" class="headerlink" title="特殊便捷方式数据集加载"></a>特殊便捷方式数据集加载</h1><p>使用函数<code>datasets.ImageFolder</code> </p>
<p>使用场景：适用于将数据集分文件夹存储，文件夹名称为对应的label</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf  = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>,<span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"><span class="comment">##适用于将数据集分文件夹存储，文件夹名称为对应的label</span></span><br><span class="line">db = torchvision.datasets.ImageFolder(root=<span class="string">&#x27;./pokeman/&#x27;</span>,transform=tf)</span><br><span class="line">loader = DataLoader(db,batch_size=<span class="number">32</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(db.class_to_idx)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorchlearning</title>
    <url>/posts/643f7c73/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="pytorch-学习记录"><a href="#pytorch-学习记录" class="headerlink" title="pytorch 学习记录"></a>pytorch 学习记录</h1><span id="more"></span>
<p>视频学习笔记github存储仓库：（@ljh）</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning">Xandra298/Pytorchlearning (github.com)</a></p>
<ul>
<li><p>torch基础操作</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning/blob/all/3.pytorch基础操作.ipynb">Pytorchlearning/3.pytorch基础操作.ipynb at all · Xandra298/Pytorchlearning (github.com)</a></p>
</li>
<li><p>自定义数据集预处理与加载</p>
<p><a href="https://xandra298.github.io/posts/a0ca199b/">【pytorch learning】(一)自定义数据集预处理和加载</a></p>
</li>
<li><p>完整模型搭建、训练、测试</p>
<p><a href="https://xandra298.github.io/posts/13fc6476/">【pytorch-learning】(二) 模型搭建-训练-测试 </a></p>
</li>
<li><p>可视化</p>
<p><a href="https://xandra298.github.io/posts/f19419c5/">【pytorch-learning】(三) 可视化 </a></p>
</li>
<li><p>【理论】随机梯度下降</p>
<p>包括损失函数等:  <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/4.随机梯度下降.ipynb">笔记</a></p>
</li>
<li><p>过拟合及优化trick</p>
<p><a href="https://github.com/Xandra298/Pytorchlearning/blob/all/7. 过拟合及优化trick.ipynb">Pytorchlearning/过拟合及优化trick</a></p>
</li>
<li><p>卷积神经网络: <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/8.卷积神经网络.ipynb">笔记</a></p>
</li>
<li><p>循环神经网络: <a href="https://github.com/Xandra298/Pytorchlearning/blob/all/9.循环神经网络.ipynb">笔记</a></p>
</li>
<li><p>自编码器: <a href="https://github.com/Xandra298/Pytorchlearning/blob/master/10.自编码器.ipynb">笔记</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>邻接矩阵表示成PyG需要的edge_index并进行带边权的网络构建</title>
    <url>/posts/35a1541/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="邻接矩阵-to-pyg需要的edge-index格式"><a href="#邻接矩阵-to-pyg需要的edge-index格式" class="headerlink" title="邻接矩阵 to pyg需要的edge_index格式"></a>邻接矩阵 to pyg需要的edge_index格式</h1><span id="more"></span>
<h2 id="scipy"><a href="#scipy" class="headerlink" title="scipy"></a>scipy</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">A = torch.rand([<span class="number">10</span>,<span class="number">10</span>]) <span class="comment"># 10*10的邻接矩阵A，带有权值，而非0/1</span></span><br><span class="line">A</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.8253, 0.2458, 0.9340, 0.4631, 0.5114, 0.3248, 0.8528, 0.6354, 0.2988,
         0.1087],
        [0.0190, 0.5693, 0.4843, 0.9588, 0.6011, 0.5755, 0.4621, 0.7694, 0.0637,
         0.9790],
        [0.6978, 0.9686, 0.9701, 0.2234, 0.5633, 0.9978, 0.9766, 0.3365, 0.3512,
         0.2396],
        [0.3582, 0.9965, 0.7739, 0.5641, 0.7275, 0.3078, 0.1826, 0.5449, 0.6566,
         0.1949],
        [0.8194, 0.7996, 0.9177, 0.3419, 0.5239, 0.7048, 0.4503, 0.0758, 0.2244,
         0.0659],
        [0.6131, 0.3546, 0.0789, 0.2735, 0.0781, 0.8000, 0.0587, 0.6644, 0.2678,
         0.6351],
        [0.7244, 0.0463, 0.9280, 0.6456, 0.6837, 0.0763, 0.0759, 0.0440, 0.1849,
         0.8942],
        [0.3589, 0.6925, 0.2334, 0.3476, 0.6695, 0.1048, 0.1470, 0.5548, 0.4736,
         0.6934],
        [0.0356, 0.8016, 0.6176, 0.2867, 0.1340, 0.7196, 0.0562, 0.5548, 0.7376,
         0.2841],
        [0.9301, 0.1725, 0.4012, 0.3893, 0.8366, 0.1587, 0.3342, 0.7945, 0.8123,
         0.8724]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">adj  = sp.coo_matrix(A) <span class="comment">#转换成coo_matrix矩阵</span></span><br><span class="line">values = adj.data</span><br><span class="line">values,adj.row,adj.col</span><br></pre></td></tr></table></figure>
<pre><code>(array([0.825252  , 0.24581629, 0.9340454 , 0.4631123 , 0.51142365,
        0.32479858, 0.85282457, 0.63537604, 0.29877287, 0.10873711,
        0.01895636, 0.5693259 , 0.48427123, 0.9587981 , 0.6010562 ,
        0.57548887, 0.46208388, 0.7693816 , 0.06371653, 0.97895676,
        0.6978117 , 0.9685761 , 0.97011906, 0.22341514, 0.56326205,
        0.9978037 , 0.97661865, 0.33654213, 0.35123014, 0.23959029,
        0.358207  , 0.99651885, 0.7739324 , 0.5641022 , 0.72754997,
        0.3077591 , 0.18257308, 0.5449101 , 0.65663534, 0.1949212 ,
        0.8193548 , 0.79964596, 0.9176568 , 0.34189552, 0.5239384 ,
        0.70477635, 0.4503097 , 0.07584941, 0.22442049, 0.06589556,
        0.6130815 , 0.35458   , 0.07890564, 0.27350843, 0.07805085,
        0.79995   , 0.05868119, 0.66441715, 0.267847  , 0.6351336 ,
        0.72437716, 0.04632962, 0.92803836, 0.645646  , 0.6836786 ,
        0.07632524, 0.07594979, 0.04397732, 0.18492383, 0.89419115,
        0.3588807 , 0.6925135 , 0.23337674, 0.34763372, 0.66951907,
        0.10478634, 0.14702266, 0.55476344, 0.47362745, 0.69343317,
        0.03562325, 0.80160064, 0.6175768 , 0.2867241 , 0.13401723,
        0.719559  , 0.05618161, 0.55481714, 0.7375902 , 0.28414857,
        0.9300911 , 0.17248052, 0.4012187 , 0.38931435, 0.83664143,
        0.15867668, 0.3341686 , 0.7945494 , 0.81226593, 0.8724434 ],
       dtype=float32),
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,
        6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int32),
 array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
        2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
        6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">indices = np.vstack((adj.row,adj.col)) <span class="comment"># 我们需要的coo形式的edge_index</span></span><br><span class="line">edge_index = torch.LongTensor(indices)<span class="comment">#PyG需要的edge_index</span></span><br><span class="line">edge_index,edge_index.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 torch.Size([2, 100]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edge_attr = adj.data <span class="comment">#边权值</span></span><br><span class="line">edge_attr = torch.FloatTensor(edge_attr)<span class="comment">#to float tensor</span></span><br><span class="line">edge_attr,edge_attr.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([0.8253, 0.2458, 0.9340, 0.4631, 0.5114, 0.3248, 0.8528, 0.6354, 0.2988,
         0.1087, 0.0190, 0.5693, 0.4843, 0.9588, 0.6011, 0.5755, 0.4621, 0.7694,
         0.0637, 0.9790, 0.6978, 0.9686, 0.9701, 0.2234, 0.5633, 0.9978, 0.9766,
         0.3365, 0.3512, 0.2396, 0.3582, 0.9965, 0.7739, 0.5641, 0.7275, 0.3078,
         0.1826, 0.5449, 0.6566, 0.1949, 0.8194, 0.7996, 0.9177, 0.3419, 0.5239,
         0.7048, 0.4503, 0.0758, 0.2244, 0.0659, 0.6131, 0.3546, 0.0789, 0.2735,
         0.0781, 0.8000, 0.0587, 0.6644, 0.2678, 0.6351, 0.7244, 0.0463, 0.9280,
         0.6456, 0.6837, 0.0763, 0.0759, 0.0440, 0.1849, 0.8942, 0.3589, 0.6925,
         0.2334, 0.3476, 0.6695, 0.1048, 0.1470, 0.5548, 0.4736, 0.6934, 0.0356,
         0.8016, 0.6176, 0.2867, 0.1340, 0.7196, 0.0562, 0.5548, 0.7376, 0.2841,
         0.9301, 0.1725, 0.4012, 0.3893, 0.8366, 0.1587, 0.3342, 0.7945, 0.8123,
         0.8724]),
 torch.Size([100]))
</code></pre><h2 id="torch"><a href="#torch" class="headerlink" title="torch**"></a>torch<em>**</em></h2><p>使用前面的方法，当传入cuda的输入然后进行转换时，前面的方法只能在cpu上执行，因为cuda不支持numpy(),需要进行cpu和cuda的转换。（一直以为是因为数据传输等方面可能的影响导致我的速度变慢，但是似乎影响更大的是因为后续模型加载非成batch)）</p>
<p>torch的方法不需要</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">A = torch.rand([<span class="number">10</span>,<span class="number">10</span>]) <span class="comment"># 10*10的邻接矩阵A，带有权值，而非0/1</span></span><br><span class="line">A</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227],
        [0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706, 0.1307,
         0.3265],
        [0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413, 0.7737, 0.8839,
         0.9673],
        [0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640, 0.2160, 0.1306, 0.4602,
         0.9815],
        [0.8076, 0.4725, 0.8042, 0.3854, 0.4384, 0.9577, 0.5992, 0.5335, 0.9595,
         0.1808],
        [0.3166, 0.5219, 0.1348, 0.2726, 0.6527, 0.7875, 0.2952, 0.6067, 0.5722,
         0.0738],
        [0.2799, 0.3344, 0.2588, 0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913,
         0.5702],
        [0.5489, 0.5952, 0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059,
         0.1255],
        [0.3011, 0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226,
         0.9818],
        [0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adj = A.to_sparse()</span><br><span class="line">adj, adj.indices(),adj.values()</span><br></pre></td></tr></table></figure>
<pre><code>(tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                         1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
                         3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,
                         5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
                         7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9,
                         9, 9, 9, 9, 9],
                        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,
                         9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
                         8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6,
                         7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
                         6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,
                         5, 6, 7, 8, 9]]),
        values=tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526,
                       0.6831, 0.0242, 0.3227, 0.8430, 0.0125, 0.0166, 0.2306,
                       0.6767, 0.7800, 0.3947, 0.5706, 0.1307, 0.3265, 0.8983,
                       0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413, 0.7737,
                       0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316,
                       0.1640, 0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725,
                       0.8042, 0.3854, 0.4384, 0.9577, 0.5992, 0.5335, 0.9595,
                       0.1808, 0.3166, 0.5219, 0.1348, 0.2726, 0.6527, 0.7875,
                       0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
                       0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702,
                       0.5489, 0.5952, 0.3463, 0.6634, 0.1480, 0.4949, 0.3449,
                       0.6737, 0.5059, 0.1255, 0.3011, 0.6796, 0.9407, 0.1118,
                       0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818, 0.7948,
                       0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893,
                       0.2553, 0.4072]),
        size=(10, 10), nnz=100, layout=torch.sparse_coo),
 tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227, 0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706,
         0.1307, 0.3265, 0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413,
         0.7737, 0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640,
         0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725, 0.8042, 0.3854, 0.4384,
         0.9577, 0.5992, 0.5335, 0.9595, 0.1808, 0.3166, 0.5219, 0.1348, 0.2726,
         0.6527, 0.7875, 0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
         0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702, 0.5489, 0.5952,
         0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059, 0.1255, 0.3011,
         0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818,
         0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">indices = adj.indices() <span class="comment"># 我们需要的coo形式的edge_index</span></span><br><span class="line">edge_index = indices<span class="comment">#PyG需要的edge_index</span></span><br><span class="line">edge_index,edge_index.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
          2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
          4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
          7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,
          9, 9, 9, 9],
         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,
          4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,
          8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,
          2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,
          6, 7, 8, 9]]),
 torch.Size([2, 100]))
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edge_attr = adj.values()</span><br><span class="line">edge_attr,edge_attr.shape</span><br></pre></td></tr></table></figure>
<pre><code>(tensor([0.8176, 0.2545, 0.6473, 0.2937, 0.9869, 0.0929, 0.6526, 0.6831, 0.0242,
         0.3227, 0.8430, 0.0125, 0.0166, 0.2306, 0.6767, 0.7800, 0.3947, 0.5706,
         0.1307, 0.3265, 0.8983, 0.5701, 0.0590, 0.0370, 0.1142, 0.9176, 0.0413,
         0.7737, 0.8839, 0.9673, 0.2120, 0.0877, 0.8496, 0.2748, 0.2316, 0.1640,
         0.2160, 0.1306, 0.4602, 0.9815, 0.8076, 0.4725, 0.8042, 0.3854, 0.4384,
         0.9577, 0.5992, 0.5335, 0.9595, 0.1808, 0.3166, 0.5219, 0.1348, 0.2726,
         0.6527, 0.7875, 0.2952, 0.6067, 0.5722, 0.0738, 0.2799, 0.3344, 0.2588,
         0.3888, 0.6586, 0.3389, 0.3849, 0.0184, 0.8913, 0.5702, 0.5489, 0.5952,
         0.3463, 0.6634, 0.1480, 0.4949, 0.3449, 0.6737, 0.5059, 0.1255, 0.3011,
         0.6796, 0.9407, 0.1118, 0.2194, 0.9374, 0.2392, 0.1681, 0.4226, 0.9818,
         0.7948, 0.4114, 0.2621, 0.5588, 0.2609, 0.7126, 0.6315, 0.7893, 0.2553,
         0.4072]),
 torch.Size([100]))
</code></pre><h1 id="edge-index-to-邻接矩阵"><a href="#edge-index-to-邻接矩阵" class="headerlink" title="edge_index to 邻接矩阵"></a>edge_index to 邻接矩阵</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> sparse_coo_tensor</span><br><span class="line">adj = sparse_coo_tensor(edge_index,edge_attr,[<span class="number">10</span>,<span class="number">10</span>])</span><br><span class="line">adj.to_dense()</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[4.5977e-01, 6.6455e-01, 4.3946e-01, 3.8642e-01, 1.2331e-01, 2.9945e-01,
         2.5433e-01, 9.7476e-01, 4.5961e-04, 5.9594e-02],
        [2.2455e-01, 9.7698e-01, 8.7531e-01, 2.8142e-01, 7.0980e-01, 6.2595e-01,
         2.3625e-01, 5.7737e-01, 4.4227e-01, 6.5420e-01],
        [5.4512e-01, 2.4614e-01, 6.9270e-01, 6.8005e-01, 1.3384e-01, 5.9974e-01,
         9.2275e-01, 3.6578e-01, 3.5667e-01, 5.8081e-01],
        [9.6142e-02, 8.5471e-01, 5.9899e-02, 3.0163e-01, 2.9641e-01, 2.8706e-01,
         4.8757e-01, 8.8466e-01, 3.4357e-01, 9.9034e-01],
        [4.5909e-01, 7.2475e-01, 2.4294e-01, 7.3560e-01, 3.2247e-01, 7.6749e-01,
         3.6008e-01, 3.0816e-01, 7.4665e-01, 6.7713e-01],
        [6.6836e-01, 8.9111e-01, 8.0428e-01, 7.9984e-01, 6.5296e-01, 8.1743e-01,
         8.8702e-01, 3.6678e-01, 4.2774e-01, 2.3170e-02],
        [8.1350e-01, 1.6834e-01, 7.7933e-02, 3.8021e-01, 9.7750e-01, 5.6143e-01,
         7.9341e-01, 3.7514e-01, 9.3114e-01, 5.6821e-01],
        [8.4002e-01, 9.2273e-01, 5.6649e-01, 7.5386e-01, 9.1587e-01, 3.9596e-02,
         8.9435e-01, 5.6476e-01, 2.3289e-01, 1.9653e-01],
        [2.1682e-01, 2.8950e-01, 7.5310e-01, 6.7648e-01, 5.1057e-02, 1.6519e-01,
         5.8807e-01, 9.4542e-02, 6.3111e-01, 2.9049e-01],
        [5.7742e-02, 3.1503e-01, 5.6936e-01, 2.2748e-01, 4.8668e-01, 6.4949e-01,
         6.1752e-01, 3.9269e-01, 2.7897e-01, 5.5806e-01]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adj = sp.coo_matrix((edge_attr,(edge_index[<span class="number">0</span>],edge_index[<span class="number">1</span>])),shape=[<span class="number">10</span>,<span class="number">10</span>])</span><br><span class="line">adj.toarray()</span><br></pre></td></tr></table></figure>
<pre><code>array([[4.5977378e-01, 6.6455245e-01, 4.3945801e-01, 3.8642406e-01,
        1.2331247e-01, 2.9944807e-01, 2.5433010e-01, 9.7475851e-01,
        4.5961142e-04, 5.9593856e-02],
       [2.2454953e-01, 9.7697508e-01, 8.7531334e-01, 2.8141612e-01,
        7.0980257e-01, 6.2595367e-01, 2.3624879e-01, 5.7737088e-01,
        4.4226754e-01, 6.5420014e-01],
       [5.4512197e-01, 2.4613553e-01, 6.9269532e-01, 6.8004644e-01,
        1.3383734e-01, 5.9973723e-01, 9.2274553e-01, 3.6578351e-01,
        3.5666680e-01, 5.8080733e-01],
       [9.6142113e-02, 8.5471165e-01, 5.9899449e-02, 3.0162632e-01,
        2.9641372e-01, 2.8705674e-01, 4.8757398e-01, 8.8466209e-01,
        3.4356719e-01, 9.9034435e-01],
       [4.5909441e-01, 7.2474545e-01, 2.4293584e-01, 7.3560286e-01,
        3.2246715e-01, 7.6749289e-01, 3.6007798e-01, 3.0815858e-01,
        7.4665487e-01, 6.7713338e-01],
       [6.6836429e-01, 8.9111018e-01, 8.0427557e-01, 7.9984426e-01,
        6.5295666e-01, 8.1743485e-01, 8.8702154e-01, 3.6678237e-01,
        4.2774427e-01, 2.3170471e-02],
       [8.1350172e-01, 1.6834372e-01, 7.7932715e-02, 3.8021082e-01,
        9.7749555e-01, 5.6143039e-01, 7.9341477e-01, 3.7514049e-01,
        9.3114382e-01, 5.6820768e-01],
       [8.4002483e-01, 9.2273450e-01, 5.6649190e-01, 7.5385606e-01,
        9.1587120e-01, 3.9596200e-02, 8.9435184e-01, 5.6475997e-01,
        2.3288828e-01, 1.9652534e-01],
       [2.1682233e-01, 2.8950059e-01, 7.5310403e-01, 6.7648250e-01,
        5.1056564e-02, 1.6518539e-01, 5.8806950e-01, 9.4541669e-02,
        6.3110876e-01, 2.9048622e-01],
       [5.7742238e-02, 3.1502587e-01, 5.6935811e-01, 2.2748303e-01,
        4.8667991e-01, 6.4949030e-01, 6.1752105e-01, 3.9268762e-01,
        2.7897447e-01, 5.5806071e-01]], dtype=float32)
</code></pre><h1 id="构建自定义边权重的GNN"><a href="#构建自定义边权重的GNN" class="headerlink" title="构建自定义边权重的GNN"></a>构建自定义边权重的GNN</h1><p>胡乱定值的<br>代码修改自：<a href="https://zhuanlan.zhihu.com/p/426907570">https://zhuanlan.zhihu.com/p/426907570</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = GCNConv(data.num_features, <span class="number">16</span>, cached=<span class="literal">True</span>,</span><br><span class="line">                             normalize=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#         self.conv1 = GATConv(data.num_features, 16)</span></span><br><span class="line">        <span class="comment">#self.conv2 = GCNConv(16, data.num_classes, cached=True,</span></span><br><span class="line">        self.conv2 = GCNConv(<span class="number">16</span>, <span class="number">2</span>, cached=<span class="literal">True</span>,</span><br><span class="line">                            normalize=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#         self.conv2 = GATConv(16, 2)</span></span><br><span class="line">        <span class="comment"># self.conv1 = ChebConv(data.num_features, 16, K=2)</span></span><br><span class="line">        <span class="comment"># self.conv2 = ChebConv(16, data.num_features, K=2)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self</span>):</span><br><span class="line">        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr</span><br><span class="line">        x = F.relu(self.conv1(x, edge_index, edge_weight))</span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        x = self.conv2(x, edge_index, edge_weight)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv, ChebConv  <span class="comment"># noqa</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> data <span class="keyword">as</span> D</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> dataset</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>],[<span class="number">5</span>],[<span class="number">6</span>],[<span class="number">7</span>],[<span class="number">8</span>],[<span class="number">9</span>],[<span class="number">10</span>]], dtype=torch.<span class="built_in">float</span>)   <span class="comment"># N x emb(in)</span></span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line">x = torch.ones(<span class="number">10</span>,dtype=torch.<span class="built_in">float</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#print(x.shape)</span></span><br><span class="line">y = torch.randint(<span class="number">0</span>,<span class="number">2</span>,[<span class="number">10</span>])</span><br><span class="line">train_mask = torch.tensor([<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">True</span>], dtype=torch.<span class="built_in">bool</span>)</span><br><span class="line">val_mask=train_mask</span><br><span class="line">test_mask=train_mask</span><br><span class="line">data=D.Data()</span><br><span class="line">data.x,data.y,data.edge_index,data.edge_attr,data.train_mask,data.val_mask,data.test_mask \</span><br><span class="line">    = x,y,edge_index,edge_attr,train_mask,val_mask,test_mask</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([10, 1])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model, data = Net().to(device), data.to(device)</span><br><span class="line">optimizer = torch.optim.Adam([</span><br><span class="line">    <span class="built_in">dict</span>(params=model.conv1.parameters(), weight_decay=<span class="number">5e-4</span>),</span><br><span class="line">    <span class="built_in">dict</span>(params=model.conv2.parameters(), weight_decay=<span class="number">0</span>)</span><br><span class="line">], lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    model.train()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()</span><br><span class="line">    <span class="comment">#F.nll_loss(model()[data], data.y).backward() #不行！</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    logits, accs = model(), []</span><br><span class="line">    <span class="keyword">for</span> _, mask <span class="keyword">in</span> data(<span class="string">&#x27;train_mask&#x27;</span>, <span class="string">&#x27;val_mask&#x27;</span>, <span class="string">&#x27;test_mask&#x27;</span>):</span><br><span class="line">        pred = logits[mask].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        acc = pred.eq(data.y[mask]).<span class="built_in">sum</span>().item() / mask.<span class="built_in">sum</span>().item()</span><br><span class="line">        accs.append(acc)</span><br><span class="line">    <span class="keyword">return</span> accs</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_val_acc = test_acc = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">    train()</span><br><span class="line">    train_acc, val_acc, tmp_test_acc = test()</span><br><span class="line">    <span class="keyword">if</span> val_acc &gt; best_val_acc:</span><br><span class="line">        best_val_acc = val_acc</span><br><span class="line">        test_acc = tmp_test_acc</span><br><span class="line">    log = <span class="string">&#x27;Epoch: &#123;:03d&#125;, Train: &#123;:.4f&#125;, Val: &#123;:.4f&#125;, Test: &#123;:.4f&#125;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(log.<span class="built_in">format</span>(epoch, train_acc, best_val_acc, test_acc))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch: 001, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 002, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 003, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 004, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 005, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 006, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 007, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 008, Train: 0.5000, Val: 0.5000, Test: 0.5000
Epoch: 009, Train: 0.5000, Val: 0.5000, Test: 0.5000
</code></pre><h1 id="批量"><a href="#批量" class="headerlink" title="批量"></a>批量</h1><h2 id="单独传入，stack结果"><a href="#单独传入，stack结果" class="headerlink" title="单独传入，stack结果"></a>单独传入，stack结果</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">16</span>)</span><br><span class="line">        self.layer2 = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x,edg_index</span>):</span><br><span class="line">        output = torch.stack([self.layer(graph, edge_index=edge_indexi) <span class="keyword">for</span> graph,edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edg_index)], dim=<span class="number">0</span>)</span><br><span class="line">        output = torch.stack([self.layer2(graph, edge_index=edge_indexi) <span class="keyword">for</span> graph,edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(output,edg_index)], dim=<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#output = torch.sigmoid(output)</span></span><br><span class="line">        <span class="comment">#print(output.shape)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="comment">#print(edge_index.shape)</span></span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#print(edge_index.shape)</span></span><br><span class="line">model = Net()</span><br><span class="line">optimizer = torch.optim.Adam(params=model.parameters(),lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">s = time.time()</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = model(x,edge_index)</span><br><span class="line">    <span class="comment">#print(out.shape)</span></span><br><span class="line">    <span class="comment">#print(y.shape)</span></span><br><span class="line">    loss = F.mse_loss(out, y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(loss.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;time:&quot;</span>,time.time()-s)</span><br></pre></td></tr></table></figure>
<pre><code>0.7729121446609497
0.41821303963661194
0.384408563375473
time: 0.09303927421569824
</code></pre><h2 id="Batch-Data"><a href="#Batch-Data" class="headerlink" title="Batch+Data"></a>Batch+Data</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">16</span>)</span><br><span class="line">        self.layer2 = GATConv(in_channels=<span class="number">16</span>,out_channels=<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x,edge_index</span>):</span><br><span class="line"><span class="comment">#         print(&quot;input:&quot;,x.shape)</span></span><br><span class="line">        data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edge_index)] </span><br><span class="line">        </span><br><span class="line">        batch = Batch.from_data_list(data_list)</span><br><span class="line">        output = self.layer(batch.x, edge_index=batch.edge_index)</span><br><span class="line"><span class="comment">#         print(&quot;output:&quot;,output.shape)</span></span><br><span class="line">        output = self.dropout(output)</span><br><span class="line">        data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(torch.split(output,x.shape[<span class="number">1</span>]),edge_index)] </span><br><span class="line">        batch = Batch.from_data_list(data_list)</span><br><span class="line">        output = self.layer2(batch.x,batch.edge_index)</span><br><span class="line">        output = self.dropout(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">optimizer = torch.optim.Adam(params=model.parameters(),lr=<span class="number">0.01</span>)  <span class="comment"># Only perform weight-decay on first convolution.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line">s = time.time()</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    result = model(x,edge_index)</span><br><span class="line"><span class="comment">#     print(result.shape)</span></span><br><span class="line"><span class="comment">#     print(&quot;output of model&quot;,result.shape)</span></span><br><span class="line"><span class="comment">#     print(y.shape)</span></span><br><span class="line">    result = torch.stack(torch.split(result,x.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;reshape the output:&quot;</span>,result.shape)</span><br><span class="line">    loss = F.mse_loss(result, y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(loss.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;time:&quot;</span>,time.time()-s)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 1200])
torch.Size([8, 2, 1200])
reshape the output: torch.Size([8, 207, 1])
2.3954498767852783
reshape the output: torch.Size([8, 207, 1])
1.1830278635025024
reshape the output: torch.Size([8, 207, 1])
0.9167585372924805
time: 0.05799269676208496
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x = torch.randn((<span class="number">8</span>, <span class="number">207</span>, <span class="number">16</span>))</span><br><span class="line">y = torch.rand([<span class="number">8</span>,<span class="number">207</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">edge_index = torch.randint(high=<span class="number">206</span>, size=(<span class="number">2</span>, <span class="number">1200</span>))</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">edge_index = edge_index.repeat(<span class="number">8</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(edge_index.shape)</span><br><span class="line"></span><br><span class="line">data_list = [Data(x=x_, edge_index=edge_indexi) <span class="keyword">for</span> x_ , edge_indexi <span class="keyword">in</span> <span class="built_in">zip</span>(x,edge_index)] </span><br><span class="line">batch = Batch.from_data_list(data_list)</span><br><span class="line">layer = GATConv(in_channels=<span class="number">16</span>, out_channels=<span class="number">2</span>)</span><br><span class="line">result = layer(batch.x, edge_index=batch.edge_index)</span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 1200])
torch.Size([8, 2, 1200])
torch.Size([1656, 2])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand([<span class="number">2</span>, <span class="number">2</span>, <span class="number">40000</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    <span class="built_in">print</span>(i.shape)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 40000])
torch.Size([2, 40000])
</code></pre><h1 id="批量邻接矩阵转换"><a href="#批量邻接矩阵转换" class="headerlink" title="批量邻接矩阵转换"></a>批量邻接矩阵转换</h1><h2 id="转换实现"><a href="#转换实现" class="headerlink" title="转换实现"></a>转换实现</h2><h3 id="转换完stack"><a href="#转换完stack" class="headerlink" title="转换完stack"></a>转换完stack</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj2coo</span>(<span class="params">self,Ab</span>):</span><br><span class="line">        <span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">        <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">        adj = sp.coo_matrix(Ab)  <span class="comment"># 转换成coo_matrix矩阵</span></span><br><span class="line">        edge_attr = adj.data  <span class="comment"># 边权值</span></span><br><span class="line">        indices = np.vstack((adj.row, adj.col))  <span class="comment"># 我们需要的coo形式的edge_index</span></span><br><span class="line">        edge_index = torch.LongTensor(indices)  <span class="comment"># PyG需要的edge_index</span></span><br><span class="line"></span><br><span class="line">        edge_attr = torch.FloatTensor(edge_attr)  <span class="comment"># to float tensor</span></span><br><span class="line">        <span class="built_in">print</span>(edge_index.shape,edge_attr.shape)</span><br><span class="line">        <span class="keyword">return</span> edge_index,edge_attr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">edg_indexH, edge_attrH = torch.stack([self.adj2coo(i)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> scoadj], dim=<span class="number">0</span>), torch.stack(</span><br><span class="line">            [self.adj2coo(i)[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> adj], dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="一次性解决"><a href="#一次性解决" class="headerlink" title="一次性解决"></a>一次性解决</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">adj2edge_index</span>(<span class="params">self,A</span>):</span><br><span class="line">       <span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line">       <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">       edg_indexAll = torch.zeros(<span class="number">0</span>,dtype=torch.int64)</span><br><span class="line">       edg_attrAll = torch.zeros(<span class="number">0</span>,dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> b <span class="keyword">in</span> A:</span><br><span class="line">           adj = sp.coo_matrix(b)  <span class="comment"># 转换成coo_matrix矩阵</span></span><br><span class="line">           edge_attr = adj.data  <span class="comment"># 边权值</span></span><br><span class="line">           indices = np.vstack((adj.row, adj.col))  <span class="comment"># 我们需要的coo形式的edge_index</span></span><br><span class="line">           edge_index = torch.LongTensor(indices)  <span class="comment"># PyG需要的edge_index</span></span><br><span class="line"></span><br><span class="line">           edge_attr = torch.FloatTensor(edge_attr)  <span class="comment"># to float tensor</span></span><br><span class="line">           edg_indexAll = torch.cat((edg_indexAll, edge_index))</span><br><span class="line">           edg_attrAll = torch.cat((edg_attrAll, edge_attr))</span><br><span class="line"></span><br><span class="line">       <span class="comment">#print(&quot;edg&quot;,edg_indexAll.view(A.shape[0],2,-1).shape)</span></span><br><span class="line">       <span class="comment">#print(edg_attrAll.view(A.shape[0],-1).shape)</span></span><br><span class="line">       <span class="keyword">return</span> edg_indexAll.view(A.shape[<span class="number">0</span>],<span class="number">2</span>,-<span class="number">1</span>),edg_attrAll.view(A.shape[<span class="number">0</span>],-<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="应用到模型"><a href="#应用到模型" class="headerlink" title="应用到模型"></a>应用到模型</h2><h3 id="模型中传参"><a href="#模型中传参" class="headerlink" title="模型中传参"></a>模型中传参</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x3 = self.relu(</span><br><span class="line">            torch.stack(</span><br><span class="line">                [self.gc6(graph, edge_index=self.adj2coo(edge)[<span class="number">0</span>], edge_attr=self.adj2coo(edge)[<span class="number">1</span>]) <span class="keyword">for</span> graph, edge <span class="keyword">in</span></span><br><span class="line">                 <span class="built_in">zip</span>(x3_h,A)],</span><br><span class="line">                dim=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h3 id="Batch-Data-1"><a href="#Batch-Data-1" class="headerlink" title="Batch+Data"></a>Batch+Data</h3><p><strong>效率更高，如一个epoch前面是280s,后面是90s</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data,Batch</span><br><span class="line">data_list = [Data(x = x_,edge_ index=self.adj2coo(edge)[<span class="number">0</span>] ,edge_attr=self.adj2coo(edge)[<span class="number">1</span>]) <span class="keyword">for</span></span><br><span class="line">x_ ,edge <span class="keyword">in</span> <span class="built_in">zip</span>(x, A) ]</span><br><span class="line">batchH = Batch.from_data_list(data_listata_list)</span><br><span class="line">x1_h = self. relu(self. gc1(batchH.x， edge_index=batchH. edge_indexedge_attr=batchH.edge_attr ))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>GNN</tag>
        <tag>PyG</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning Multimodal Violence Detection under Weak Supervision</title>
    <url>/posts/undefined/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Not-only-look-but-also-listen-Learning-multimodal-violence-detection-under-weak-supervision"><a href="#Not-only-look-but-also-listen-Learning-multimodal-violence-detection-under-weak-supervision" class="headerlink" title="Not only look, but also listen: Learning multimodal violence detection under weak supervision"></a>Not only look, but also listen: Learning multimodal violence detection under weak supervision</h1><p><a href="https://arxiv.org/pdf/2007.04687.pdf">paper</a> ，<a href="https://roc-ng.github.io/XD-Violence/">code and dataset</a></p>
<p>暴力视频检测方向论文</p>
<blockquote>
<p> 💡 We introduce a HL-Net to simultaneously capture <strong>long-range relations</strong> and<br><strong>local distance relations</strong>, of which these two relations are based on similarity prior and proximity prior, respectively</p>
<p>三个并行的branch捕捉视频片段和集成的特征之间的不同联系:</p>
<ul>
<li>holistic branch captures long-range dependencies using similarity prior,</li>
<li>localized branch captures local positional relation using proximity prior,</li>
<li>score branch dynamically captures the closeness of predicted score.</li>
</ul>
</blockquote>
<span id="more"></span>
<p>相关工作，其中attention部分可以后面看下；</p>
<p>一些工作将图神经网络(GCNs)[20,39]在图上建立不同节点之间的关系模型，并学习计算机视觉的强大表示。例如，GCN被用于时间性动作定位[50]、视频分类[37,41]、异常检测[51]。基于骨架的动作识别[33,45]，点云语义分割[21]，图像说明[46]等等。除了GCN，时间关系网络[52]，旨在学习和推理视频帧之间的时间依赖关系，被提出来用于解决视频分类。最近，自我注意网络[40,47,5,18]已被成功应用于视觉问题。注意力操作可以通过聚合一组元素的信息来影响单个元素，其中聚合的权重是自动学习的。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="总体框架图"><a href="#总体框架图" class="headerlink" title="总体框架图"></a>总体框架图</h2><p><img src="/posts/undefined/Untitled.png" alt></p>
<ul>
<li><p>特征提取：using the sliding window mechanism 提取 视频特征和声音特征，合并成融合特征（融合部分不予关注。滑动窗口机制待看）</p>
<blockquote>
<p>Visual features: utilize two mainstream networks-C3D and I3D networks. we extract fc6 features from C3D that is pretrained on the Sports-1M dataset, and extract global_pool features from I3D pre-trained on Kinetics-200 dataset.</p>
</blockquote>
</li>
</ul>
<h2 id="Holistic-and-Localized-Networks"><a href="#Holistic-and-Localized-Networks" class="headerlink" title="Holistic and Localized Networks"></a>Holistic and Localized Networks</h2><h3 id="Holistic-特征相似性"><a href="#Holistic-特征相似性" class="headerlink" title="Holistic - 特征相似性"></a><strong>Holistic - 特征相似性</strong></h3><hr>
<p>通用的图卷积表示可以看为：</p>
<script type="math/tex; mode=display">
X_l+1 = Update(Aggregate(X_l,W_l^{agg},W_l^{update}))</script><ul>
<li><strong>GCN范式：</strong><script type="math/tex; mode=display">
X^H_{l+1} = Dropout(ReLU(A^HX^H_lW^H_l))</script></li>
</ul>
<p>注：$X^H_0 = X^S_0 = X^L_0 = X^F$</p>
<p><strong>特征相似性的邻接矩阵表示:</strong></p>
<script type="math/tex; mode=display">
A^H_{ij} = g(f(x_i,x_j))</script><p>$A^H_{ij}$衡量第i个和第j个特征的特征相似性；g是归一化函数，f函数计算一对特征的相似性；附录部分还讨论了一下其他版本的。本文定义如下</p>
<ul>
<li>f 定义为：</li>
</ul>
<script type="math/tex; mode=display">
f(x_i,x_j) = \frac{x_i^Tx_j}{||x_i||_{2} \\ . \\ ||x_j||_2}</script><ul>
<li>thresholding操作（$\tau$是threshod，f将相似性限制在（0,1]之间）：</li>
</ul>
<script type="math/tex; mode=display">
f(x_i,x_j) = \begin{cases} f(x_i,x_j)  & f(x_i,x_j) > \tau \\ 0 & f(x_i,x_j)\leq \tau\end{cases}</script><ul>
<li><p>使用softmax作为归一化函数g，使得A的每一行的和都为1。</p>
<script type="math/tex; mode=display">
A^H_{ij} = \frac{exp(A^H_{ij})}{\sum ^{T'}_{k=1} exp(A^H_{ij})}</script></li>
</ul>
<h3 id="localized-branch-proximity-prior-和时间一致性类似）"><a href="#localized-branch-proximity-prior-和时间一致性类似）" class="headerlink" title="localized branch -proximity prior (和时间一致性类似）"></a><strong>localized branch -proximity prior (和时间一致性类似）</strong></h3><hr>
<script type="math/tex; mode=display">
A^L_{ij} = exp(\frac{-|i-j|^r}{\sigma })</script><h2 id="Online-detection-amp-score-branch"><a href="#Online-detection-amp-score-branch" class="headerlink" title="Online detection &amp; score branch"></a>Online detection &amp; score branch</h2><p>正如我们提到的，暴力检测系统不仅适用于离线检测（互联网录像机），也适用于在线检测（监控系统）。然而，<strong>上述HL-Net</strong>的在线检测受到了一个主要障碍的阻碍：<strong>HL-Net需要整个视频来获得长距离的依赖关系</strong>。为了跳出这个困境，我们提出了一个HLC近似器，只把以前的视频片段作为输入，在HL-Net的指导下产生精确的预测。两个堆叠的FC层和ReLU以及一个一维因果卷积层构成了HLC近似器。一维因果卷积层的核大小为5，跨度为1，在时间上滑动卷积滤波器。一维因果卷积层也充当分类器，其输出是形状为 T’ 的暴力激活表示为$C^S$。更妙的是，这个操作引入了一个额外的分支，名为<strong>动态得分分支(dynamic score branch)</strong>，以扩展HL-Net，它取决于$C^S$。</p>
<h3 id="score-branch"><a href="#score-branch" class="headerlink" title="score branch"></a>score branch</h3><p>用于online detection, 解决需要将整个视频作为输入（以获得长距离依赖）的问题。</p>
<p>该分支的主要作用是将一个位置的响应计算为所有位置特征的加权和，其中权重取决于分数的接近程度。与整体和局部分支的关系矩阵不同，分数分支的关系矩阵在每次迭代中都会更新，并且取决于预测的分数而不是先验。从形式上看，分数分支的关系矩阵设计如下：</p>
<script type="math/tex; mode=display">
A^S_{ij} = \rho(1 - |s(C^S_i) - s(C^S_j)|)</script><p>s是 sigmoid, 函数ρ用于加强（和削弱）得分接近度大于（和小于）0.5的配对关系，softmax也用于归一化。</p>
<script type="math/tex; mode=display">
\rho (x) = \frac{1}{1+exp(-\frac{x-0.5}{0.1})}</script><h2 id="training-based-on-MIL"><a href="#training-based-on-MIL" class="headerlink" title="training based on MIL"></a>training based on MIL</h2><script type="math/tex; mode=display">
C^P = (X^H||X^L||X^S)W</script><p>所有输出($C^P 和 C^S$)在时间维度上的K-max取平均作为输出，以得到$y^P$ 和$y^S$。K定义为T‘ 除以q加一后向下取整。</p>
<p>补充： top-k策略（Weakly-supervised video anomaly detection with robust temporal feature magnitude learning）</p>
<ul>
<li>loss结合三个branch</li>
</ul>
<blockquote>
<p>The instances corresponding to the K-max activation in the positive bag is most likely to be true positive instances (violence). The instances corresponding to the K-max activation in the negative bag is hard instances. We expect these two types of instances to be as far as possible.</p>
</blockquote>
<p>L_BCE（binary crossentropy) 和L_BCE2分别对应为$y^p 和 y^s$ 与 ground truth y之间的loss。L_DISTILL为知识蒸馏损失。</p>
<script type="math/tex; mode=display">
L_{TOTAL}  = L_{BCE} + L_{BCE2} +\lambda L_{DISTILL}</script><script type="math/tex; mode=display">
L_{DISTILL} = \sum \limits^N_{j=1} (- \sum \limits_i s(C^P_i) log (s(C_i^S)))</script><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>方法支持线上和离线的检测。sigmoid函数作为$C^P$和$C^S$的激活函数，并最后生成在[0,1]之间的暴力置信得分。注：在线上预测中，只有HLC近似器工作，HL-NET可以移除。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="评估标准"><a href="#评估标准" class="headerlink" title="评估标准"></a>评估标准</h2><p>we utilize the frame-level <strong>precision-recall curve</strong> (PRC) and corresponding area under the curve <strong>(average precision, AP)</strong> [30] rather than receiver operating characteristic curve (ROC) and corresponding area under the curve (AUC) [44,43]<br><strong>since AUC usually shows an optimistic result when dealing with class-imbalanced data, and PRC and AP focus on positive samples (violence)</strong></p>
<ul>
<li>Precision and Recall (PR曲线)：用于稀有事件检测，如目标检测、信息检索、推荐系统。负样本很多的时候，??? = FP⁄(FP+TN）很小，比较TPR和FPR没有太大意义（ROC）</li>
</ul>
<h2 id="性能表现"><a href="#性能表现" class="headerlink" title="性能表现"></a>性能表现</h2><p><img src="/posts/undefined/Untitled 1.png" alt></p>
<p>优于当前最先进的方法（20年的文章）</p>
<p>我们观察到，在我们的暴力检测任务中，C3D比I3D差了很大一截。</p>
<h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><ul>
<li>五种模态AP对比</li>
</ul>
<p><img src="/posts/undefined/Untitled 2.png" alt="Untitled"></p>
<p>（该文证明声音和视觉的融合检测效果更好，且视觉模态的作用优于声音）</p>
<ul>
<li><p>三个分支的对比（holistic, localized and score branches）</p>
<ul>
<li>三个分支单独的情况表现相似</li>
<li>移除任何一个分支都会使得表现变差</li>
<li>HL-NET在这三个分支一起作用的时候表现最好，因此证明三个分支都不可替代。</li>
</ul>
<p><img src="/posts/undefined/Untitled 3.png" alt></p>
</li>
<li><p>online vs offline</p>
<p><img src="/posts/undefined/Untitled 4.png" alt></p>
</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h3 id="光流"><a href="#光流" class="headerlink" title="光流"></a>光流</h3><blockquote>
<p>光流（optical flow）是空间运动物体在观察成像平面上的像素运动的瞬时速度。<br>光流法是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。<br>通常将二维图像平面特定坐标点上的灰度瞬时变化率定义为光流矢量。</p>
</blockquote>
<p>作者在《On the Integration of Optical Flow and Action Recognition》这篇文章[1]中深入讨论了光流与行为识别的结合，并通过实验观察到如下结论：<br>（1）光流对于行为识别是有用的，因为它的外观不变性；<br>（2）光流法采用最小化端点误差（EPE，end-point-error）来优化，但是当前EPE方法与动作识别性能没有很好的相关性；<br>（3）对于测试过的光流方法，在边界上和小位移上的精度与动作识别性能最相关；<br>（4）采用最小化分类误差（而非EPE）来训练光流可以提高识别性能；<br>（5）用于行为识别任务的光流不同于传统的光流，特别是在人体内部和身体边界处。<br>原文链接：<a href="https://blog.csdn.net/zhang_can/article/details/80259946">https://blog.csdn.net/zhang_can/article/details/80259946</a></p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>弱监督学习</tag>
        <tag>暴力视频检测</tag>
      </tags>
  </entry>
  <entry>
    <title>第一次搭建hexo博客</title>
    <url>/posts/83682157/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="hexo-deploy-到github失败"><a href="#hexo-deploy-到github失败" class="headerlink" title="hexo deploy 到github失败"></a>hexo deploy 到github失败</h2><p>使用deploy之后要求输入账户和密码，密码正确但是显示验证失败。</p>
<span id="more"></span>
<ul>
<li><p>失败原因：</p>
<p>github 21年取消了密码验证</p>
<p><img src="/posts/83682157/image-20221117162546351.png" alt></p>
</li>
</ul>
<ul>
<li><p>解决方式</p>
<p>在_config.yml的deploy中，repo对应的填写为github仓库的ssh地址，可以避免进行密码验证（前提：git配置完成，github上有设置公钥）</p>
</li>
</ul>
<h2 id="完成的配置"><a href="#完成的配置" class="headerlink" title="完成的配置"></a>完成的配置</h2><ul>
<li><p>使用hexo主题</p>
<p><a href="https://github.com/probberechts/hexo-theme-cactus">hexo-theme-cactus</a></p>
<ul>
<li><a href="https://github.com/theme-next/hexo-theme-next">theme-next/hexo-theme-next: Elegant and powerful theme for Hexo. (github.com)</a></li>
</ul>
</li>
<li><p>主题配置 tags 和 categories</p>
</li>
<li><p>配置baidu_analytics</p>
</li>
<li><p>comment</p>
<ul>
<li>使用utterances设置comment</li>
<li>来必力</li>
</ul>
</li>
<li><p>不蒜子统计</p>
</li>
<li><p>使用主题的search</p>
<ul>
<li>不成功-&gt;解决：发现是npm install的时候没有在博客根目录导致的问题</li>
</ul>
</li>
<li><p>解决图片路径问题</p>
<ul>
<li><p>sources/images目录下存引图片</p>
</li>
<li><p>setup那篇post使用post_asset_folder: true的方式（需要安装hexo插件），将资源放在对应目录下</p>
<ul>
<li><p>本地成功但是服务器显示无效，重新安装插件成功：</p>
<p><code>npm install https://github.com/7ym0n/hexo-asset-image --save</code></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>hexo new post失败</p>
<ul>
<li>使用 hexo new ‘[post]’ “postname”</li>
</ul>
</li>
<li><p>数学公式渲染</p>
<ul>
<li><a href="https://blog.csdn.net/qq_38496329/article/details/104065659">https://blog.csdn.net/qq_38496329/article/details/104065659</a></li>
<li>注意在文章中front 部分设置mathjax: true</li>
</ul>
</li>
</ul>
<h3 id="音乐"><a href="#音乐" class="headerlink" title="音乐"></a>音乐</h3><ul>
<li><strong>获取网易云外链的iframe代码</strong></li>
</ul>
<p>打开网易云<a href="https://music.163.com/">官网</a>，选择喜欢的歌单或者歌曲，可以自己创建歌单。</p>
<p>限制：有些歌曲有版权保护，无法生成外链</p>
<p><img src="/posts/83682157/image-20221125133318434.png" alt style="zoom:50%;"></p>
<p><img src="/posts/83682157/image-20221125133225148.png" alt style="zoom: 50%;"></p>
<p>[博客根目录]\themes\next\layout_macro\sidebar.swig，在class为siderbar-inner的div内添加iframe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% macro render(display_toc) %&#125;</span><br><span class="line">  &lt;div class=&quot;toggle sidebar-toggle&quot;&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-first&quot;&gt;&lt;/span&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-middle&quot;&gt;&lt;/span&gt;</span><br><span class="line">    &lt;span class=&quot;toggle-line toggle-line-last&quot;&gt;&lt;/span&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">  &lt;aside class=&quot;sidebar&quot;&gt;</span><br><span class="line">    &lt;div class=&quot;sidebar-inner&quot;&gt;</span><br></pre></td></tr></table></figure>
<h3 id="图标"><a href="#图标" class="headerlink" title="图标"></a>图标</h3><p>【next主题下】</p>
<ul>
<li>免费图标下载网站：</li>
</ul>
<p><a href="https://icons8.com/">https://icons8.com/</a></p>
<p><a href="https://findicons.com/icon/558960/cursor">Cursor icon PNG, ICO or ICNS | Free vector icons (findicons.com)</a></p>
<ul>
<li>站点图标</li>
</ul>
<p>next主题默认是黑色的N</p>
<p>修改： next主题的配置文件中有一项配置 favicon，将配置下的图片目录更改为想换的图片即可</p>
<ul>
<li><p>鼠标烟花特效</p>
<p><a href="https://siriusq.top/Next升级-Mac迁移.html#鼠标点击特效">Next 升级 + Mac 迁移 | Sirius (siriusq.top)</a></p>
</li>
</ul>
<p>​                注意将主题配置文件中将body-end.swig对应的部分移除注释</p>
<ul>
<li><p>鼠标样式修改</p>
<p>hexo\source_data\styles.styl中添加</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// 鼠标样式</span><br><span class="line">  * &#123;</span><br><span class="line">      <span class="attribute">cursor</span>: <span class="built_in">url</span>(<span class="string">&quot;image url&quot;</span>),auto<span class="meta">!important</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="selector-pseudo">:active</span> &#123;</span><br><span class="line">      <span class="attribute">cursor</span>: <span class="built_in">url</span>(<span class="string">&quot;image url&quot;</span>),auto<span class="meta">!important</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注意主题配置文件中custom_file_path: style: source/_data/styles.styl移除注释</p>
</li>
</ul>
]]></content>
      <categories>
        <category>hexo配置</category>
      </categories>
  </entry>
  <entry>
    <title>hexo Hello World</title>
    <url>/posts/1e44dbaf/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>hexo配置</category>
      </categories>
  </entry>
</search>
